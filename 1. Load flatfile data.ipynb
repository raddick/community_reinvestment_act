{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/idies/workspace/Temporary/raddick/cra_scratch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import urllib\n",
    "import pandas\n",
    "import zipfile\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 2016 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the files from ffiec.gov and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading master datafile...\n",
      "Starting to download 96exp_discl.zip...\n",
      "Starting to download 97exp_discl.zip...\n",
      "Starting to download 98exp_discl.zip...\n",
      "Starting to download 99exp_discl.zip...\n",
      "Starting to download 00exp_discl.zip...\n",
      "Starting to download 01exp_discl.zip...\n",
      "Starting to download 02exp_discl.zip...\n",
      "Starting to download 03exp_discl.zip...\n",
      "Starting to download 04exp_discl.zip...\n",
      "Starting to download 05exp_discl.zip...\n",
      "Starting to download 06exp_discl.zip...\n",
      "Starting to download 07exp_discl.zip...\n",
      "Starting to download 08exp_discl.zip...\n",
      "Starting to download 09exp_discl.zip...\n",
      "Starting to download 10exp_discl.zip...\n",
      "Starting to download 11exp_discl.zip...\n",
      "Starting to download 12exp_discl.zip...\n",
      "Starting to download 13exp_discl.zip...\n",
      "Starting to download 14exp_discl.zip...\n",
      "Starting to download 15exp_discl.zip...\n",
      "Starting to download 16exp_discl.zip...\n",
      "Unzipping individual datafiles...\n",
      "Extracting 96exp_discl.zip...\n",
      "Extracting 97exp_discl.zip...\n",
      "Extracting 98exp_discl.zip...\n",
      "Extracting 99exp_discl.zip...\n",
      "Extracting 00exp_discl.zip...\n",
      "Extracting 01exp_discl.zip...\n",
      "Extracting 02exp_discl.zip...\n",
      "Extracting 03exp_discl.zip...\n",
      "Extracting 04exp_discl.zip...\n",
      "Extracting 05exp_discl.zip...\n",
      "Extracting 06exp_discl.zip...\n",
      "Extracting 07exp_discl.zip...\n",
      "Extracting 08exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 09exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 10exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 11exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 12exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 13exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 14exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 15exp_discl.zip...\n",
      "Renaming...\n",
      "Extracting 16exp_discl.zip...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get oroginal datafiles from ffiec.gov\n",
    "print('Downloading master datafile...')\n",
    "thatpath = 'https://www.ffiec.gov/cra/xls/'\n",
    "theyears = list(range(96,100))\n",
    "theyears += list(range(0,17))\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for i in theyears:\n",
    "    filenames.append('{:02d}exp_discl.zip'.format(i))\n",
    "#filenames\n",
    "\n",
    "for thisfile in filenames:\n",
    "    print('Starting to download {:}...'.format(thisfile))\n",
    "    with urllib.request.urlopen(thatpath+thisfile) as response:    \n",
    "        it = response.read()\n",
    "        with open(thisfile, 'wb') as f:\n",
    "            f.write(it)\n",
    "print('Unzipping individual datafiles...')\n",
    "\n",
    "allfiles = os.listdir()\n",
    "allfiles_df = pandas.DataFrame(allfiles)\n",
    "\n",
    "allfiles_df.columns = ['filename']\n",
    "\n",
    "allfiles_df['file_extension'] = allfiles_df['filename'][\n",
    "    allfiles_df['filename'].apply(lambda x: \n",
    "                                      (len(str(x).split('.')) > 1)\n",
    "                                 )\n",
    "].apply(lambda x: str(x).split('.')[1])\n",
    "\n",
    "zipfiles_df = allfiles_df[allfiles_df['file_extension'] == 'zip'].sort_values('filename')\n",
    "zipfiles_df['yearstring'] = zipfiles_df['filename'].apply(lambda x: x[0:2])\n",
    "zipfiles_df['thisyear'] = pandas.to_numeric(zipfiles_df['yearstring'])\n",
    "\n",
    "zipfiles_df = zipfiles_df.set_index('thisyear')\n",
    "zipfiles_df\n",
    "sortorder = [96, 97, 98, 99, 0, 1, 2, 3]\n",
    "sortorder += [4, 5, 6, 7, 8, 9, 10, 11]\n",
    "sortorder += [12, 13, 14, 15, 16]\n",
    "newindex = pandas.Index(sortorder)\n",
    "zipfiles_df = zipfiles_df.reindex(newindex)\n",
    "\n",
    "zipfiles_df['needs_rename'] = zipfiles_df.index.map(lambda x: (x >= 8) & (x <= 15))\n",
    "zipfiles_df = zipfiles_df.drop(['file_extension', 'yearstring'], axis=1)\n",
    "zipfiles_df\n",
    "for idx, thisrow in zipfiles_df.iterrows():\n",
    "    print('Extracting {:}...'.format(thisrow['filename']))\n",
    "    thezipfile = zipfile.ZipFile(thisrow['filename'])\n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    if (thisrow['needs_rename']):\n",
    "        print('Renaming...')\n",
    "        os.rename('exp_discl.dat', '{:02d}exp_discl.dat'.format(idx))\n",
    "\n",
    "# Delete the zipfiles, we don't need them anymore\n",
    "for idx, thisrow in zipfiles_df.iterrows():\n",
    "    os.remove(thisrow['filename'])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the single rawdata string into separate columns of strings\n",
    "\n",
    "Using the guides on their website (https://www.ffiec.gov/cra/pdf/16FlatDiscSpecs.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file cra2016_Discl_D11.dat...\n",
      "Reading file cra2016_Discl_D12.dat...\n",
      "Reading file cra2016_Discl_D21.dat...\n",
      "Reading file cra2016_Discl_D22.dat...\n",
      "Reading file cra2016_Discl_D3.dat...\n",
      "Reading file cra2016_Discl_D4.dat...\n",
      "Reading file cra2016_Discl_D5.dat...\n",
      "Reading file cra2016_Discl_D6.dat...\n",
      "\n",
      "\n",
      "Read 2016 data: 3,593,829 rows in 13 seconds.\n"
     ]
    }
   ],
   "source": [
    "rdf = pandas.DataFrame()\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for i in range(1,3):\n",
    "    for j in range(1,3):\n",
    "        #\n",
    "        thisfile = 'cra2016_Discl_D{0:.0f}{1:.0f}.dat'.format(i,j)\n",
    "        print('Reading file {:}...'.format(thisfile))\n",
    "        rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "\n",
    "for k in range(3,7):\n",
    "    thisfile = 'cra2016_Discl_D{0:.0f}.dat'.format(k)\n",
    "    print('Reading file {:}...'.format(thisfile))\n",
    "    rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print('\\n')\n",
    "print('Read 2016 data: {0:,.0f} rows in {1:,.0f} seconds.'.format(len(rdf), e-s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files for 2004 to 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filenames!\n",
      "Reading file 04exp_discl_new.dat...\n",
      "Reading file 05exp_discl_new.dat...\n",
      "Reading file 06exp_discl_new.dat...\n",
      "Reading file 07exp_discl.dat...\n",
      "Reading file 08exp_discl.dat...\n",
      "Reading file 09exp_discl.dat...\n",
      "Reading file 10exp_discl.dat...\n",
      "Reading file 11exp_discl.dat...\n",
      "Reading file 12exp_discl.dat...\n",
      "Reading file 13exp_discl.dat...\n",
      "Reading file 14exp_discl.dat...\n",
      "Reading file 15exp_discl.dat...\n",
      "\n",
      "\n",
      "Read 2004-2015 data: 39,019,524 rows in 148 seconds.\n",
      "\n",
      "\n",
      "made backup\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "filelist = []\n",
    "for i in range(4,16):\n",
    "    thisfile = '{:02d}exp_discl'.format(i)\n",
    "    if i in [4,5,6]:\n",
    "        thisfile = thisfile + '_new.dat'\n",
    "    else:\n",
    "        thisfile = thisfile + '.dat'\n",
    "    filelist.append(thisfile)\n",
    "print('Found filenames!')\n",
    "\n",
    "for thisfile in filelist:\n",
    "    print('Reading file {:}...'.format(thisfile))\n",
    "    rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "\n",
    "e = time.time()\n",
    "print('\\n')\n",
    "print('Read 2004-2015 data: {0:,.0f} rows in {1:,.0f} seconds.'.format(len(rdf), e-s))\n",
    "\n",
    "rdf_bk = rdf\n",
    "print('\\n')\n",
    "print('made backup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing empty dataframe...\n",
      "Took 15 seconds\n",
      "\n",
      "parsing long-ass string data into columns...\n",
      "tableID...\n",
      "respondentID...\n",
      "agency_code...\n",
      "activity_year...\n",
      "Converted 39,019,524 rows in 157 seconds.\n",
      "\n",
      "Trimming strings in columns...\n",
      "tableID...\n",
      "respondentID...\n",
      "agency_code...\n",
      "activity_year...\n",
      "Trimmed 39,019,524 rows in 99 seconds.\n",
      "\n",
      "Coverting to numeric...\n",
      "respondentID...\n",
      "agency_code...\n",
      "activity_year...\n",
      "Converted columns in 165 seconds.\n",
      "backing up...\n",
      "Done! Total time: 337 seconds.\n"
     ]
    }
   ],
   "source": [
    "rdf = rdf_bk\n",
    "rdf.columns = ['thestring']\n",
    "rdf.index.name = 'rownumber'\n",
    "\n",
    "cols = ['tableID', 'respondentID', 'agency_code', 'activity_year']\n",
    "\n",
    "c = 0\n",
    "s = time.time()\n",
    "print('constructing empty dataframe...')\n",
    "df = pandas.DataFrame(data=None, columns=cols, index=rdf.index)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Took {0:,.0f} seconds\\n'.format(e-s))\n",
    "\n",
    "print('parsing long-ass string data into columns...')\n",
    "s = time.time()\n",
    "\n",
    "print('tableID...')\n",
    "df['tableID'] = rdf['thestring'].apply(lambda x: x[0:5])\n",
    "print('respondentID...')\n",
    "df['respondentID'] = rdf['thestring'].apply(lambda x: x[5:15])\n",
    "print('agency_code...')\n",
    "df['agency_code'] = rdf['thestring'].apply(lambda x: x[15])\n",
    "print('activity_year...')\n",
    "df['activity_year'] = rdf['thestring'].apply(lambda x: x[16:20])\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Converted {0:,.0f} rows in {1:,.0f} seconds.'.format(len(df), e-s))\n",
    "\n",
    "print('\\nTrimming strings in columns...')\n",
    "s = time.time()\n",
    "for thiscol in df.columns:\n",
    "    print('{:}...'.format(thiscol))\n",
    "    df[thiscol] = df[thiscol].apply(lambda x: x.strip())\n",
    "e = time.time()\n",
    "print('Trimmed {0:,.0f} rows in {1:,.0f} seconds.'.format(len(df), e-s))\n",
    "\n",
    "s = time.time()\n",
    "print('\\nCoverting to numeric...')\n",
    "print('respondentID...')\n",
    "df['respondentID'] = pandas.to_numeric(df['respondentID'], errors='coerce')\n",
    "print('agency_code...')\n",
    "df['agency_code'] = pandas.to_numeric(df['agency_code'], errors='coerce')\n",
    "print('activity_year...')\n",
    "df['activity_year'] = pandas.to_numeric(df['activity_year'], errors='coerce')\n",
    "e = time.time()\n",
    "print('Converted columns in {:,.0f} seconds.'.format(e-s))\n",
    "c = c + (e-s)\n",
    "\n",
    "print('backing up...')\n",
    "df_bk = df\n",
    "\n",
    "print('Done! Total time: {:,.0f} seconds.'.format(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_bk\n",
    "\n",
    "theloans = ['D1-1', 'D1-2', 'D2-1', 'D2-2']\n",
    "theactivities = ['D3-0', 'D4-0']\n",
    "thecras = ['D5-0']\n",
    "thetracts = ['D6-0']\n",
    "\n",
    "c = 0\n",
    "s = time.time()\n",
    "print('Assigning new columns to False...')\n",
    "df = df.assign(isloan=False)\n",
    "df = df.assign(isactivity=False)\n",
    "df = df.assign(iscra=False)\n",
    "df = df.assign(istract=False)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Assigned, took {0:,.0f} seconds.'.format(e-s))\n",
    "\n",
    "s = time.time()\n",
    "df.loc[df['tableID'].isin(theloans), 'isloan'] = True\n",
    "df.loc[df['tableID'].isin(theactivities), 'isactivity'] = True\n",
    "df.loc[df['tableID'].isin(thecras), 'iscra'] = True\n",
    "df.loc[df['tableID'].isin(thetracts), 'istract'] = True\n",
    "e = time.time()\n",
    "\n",
    "print('Loans/activities/cras/tracts data: processed {0:,.0f} rows to True in {1:,.0f} seconds.'.format(len(df), e-s))\n",
    "c = c + (e-s)\n",
    "\n",
    "s = time.time()\n",
    "df_bk = df\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('backed up in {0:,.0f} seconds\\n'.format(e-s))\n",
    "print('Done! Took {0:,.0f} seconds total.'.format(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Creating empty dataframe...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "loans_df = pandas.DataFrame(data=None, columns=df.columns, index=df.index)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Dataframe created in {0:,.0f} seconds.\\n'.format(e-s))\n",
    "\n",
    "print('Getting data on loans (tables D1-1/D1-2/D2-1/D2-2) into loans_df...')\n",
    "s = time.time()\n",
    "#loans_df = loans_df.append(df[df['isloan'] == True])\n",
    "loans_df = df[df['isloan'] == True]\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('Loans data: copied {0:,.0f} rows in {1:,.0f} seconds.\\n'.format(len(loans_df), e-s))\n",
    "\n",
    "print('backing up')\n",
    "loans_df_bk = loans_df\n",
    "\n",
    "print('Done in {0:,.0f} seconds!'.format(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('Retrieving backup...')\n",
    "loans_df = loans_df_bk\n",
    "print('Creating new columns...')\n",
    "\n",
    "print('loan_type...')\n",
    "loans_df = loans_df.assign(loan_type = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[20]))\n",
    "print('action_taken_type...')\n",
    "loans_df = loans_df.assign(action_taken_type = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[21]))\n",
    "print('state...')\n",
    "loans_df = loans_df.assign(state = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[22:24]))\n",
    "print('county...')\n",
    "loans_df = loans_df.assign(county = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[24:27]))\n",
    "print('msa...')\n",
    "loans_df = loans_df.assign(msa = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[27:32]))\n",
    "print('assessment_area_number...')\n",
    "loans_df = loans_df.assign(assessment_area_number = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[33:36]))\n",
    "print('partial_county_indicator...')\n",
    "loans_df = loans_df.assign(partial_county_indicator = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[36]))\n",
    "print('split_county_indicator...')\n",
    "loans_df = loans_df.assign(split_county_indicator = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[37]))\n",
    "print('population_classification...')\n",
    "loans_df = loans_df.assign(population_classification = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[38]))\n",
    "print('income_group_total...')\n",
    "loans_df = loans_df.assign(income_group_total = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[39:42]))\n",
    "print('report_level...')\n",
    "loans_df = loans_df.assign(report_level = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[42:45]))\n",
    "print('nLoans1...')\n",
    "loans_df = loans_df.assign(nLoans1 = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[45:55]))\n",
    "print('amtLoans1...')\n",
    "loans_df = loans_df.assign(amtLoans1 = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[55:65]))\n",
    "print('nLoans100k...')\n",
    "loans_df = loans_df.assign(nLoans100k = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[65:75]))\n",
    "print('amtLoans100k...')\n",
    "loans_df = loans_df.assign(amtLoans100k = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[75:85]))\n",
    "print('nLoans250k...')\n",
    "loans_df = loans_df.assign(nLoans250k = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[85:95]))\n",
    "print('amtLoans250k...')\n",
    "loans_df = loans_df.assign(amtLoans250k = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[95:105]))\n",
    "print('nLoansToSmallest...')\n",
    "loans_df = loans_df.assign(nLoansToSmallest = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[105:115]))\n",
    "print('amtLoansToSmallest...')\n",
    "loans_df = loans_df.assign(amtLoansToSmallest = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[115:125]))\n",
    "print('nLoansAff...')\n",
    "loans_df = loans_df.assign(nLoansAff = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[125:135]))\n",
    "print('amtLoansAff..\\n')\n",
    "loans_df = loans_df.assign(amtLoansAff = rdf['thestring'][df['isloan'] == True].apply(lambda x: x[135:145]))\n",
    "\n",
    "print('Keep only lowest level of aggregation to avoid double-counting...')\n",
    "loans_df = loans_df[loans_df['report_level'] == '   ']\n",
    "\n",
    "print('Drop columns we do not need...')\n",
    "loans_df = loans_df.drop(['isloan', 'isactivity', 'iscra', 'istract'], axis=1)\n",
    "loans_df = loans_df.drop(['tableID','report_level'], axis=1)\n",
    "\n",
    "print('backing up...')\n",
    "loans_df_bk = loans_df\n",
    "e = time.time()\n",
    "\n",
    "print('Parsed all columns for {0:,.0f} rows in {1:,.0f} seconds'.format(len(loans_df), e-s))\n",
    "\n",
    "print('Writing outfile...')\n",
    "s = time.time()\n",
    "loans_df.to_csv('loans_df.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "print('{0:,.0f} rows written in {1:,.0f} seconds.'.format(len(loans_df), e-s))\n",
    "print('ok')\n",
    "#os.getcwd()\n",
    "\n",
    "#loans_df.sample(3).T\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['isactivity'] == True].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Creating empty dataframe...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "activities_df = pandas.DataFrame(data=None, columns=df.columns, index=df.index)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Dataframe created in {0:,.0f} seconds.\\n'.format(e-s))\n",
    "\n",
    "print('Getting data on activities (tables D3/D4) into activities_df...')\n",
    "s = time.time()\n",
    "activities_df = df[df['isactivity'] == True]\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('Activities data: copied {0:,.0f} rows in {1:,.0f} seconds.\\n'.format(len(activities_df), e-s))\n",
    "\n",
    "print('backing up')\n",
    "activities_df_bk = activities_df\n",
    "\n",
    "print('Done in {0:,.0f} seconds!'.format(c))\n",
    "#activities_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('Retrieving backup...')\n",
    "activities_df = activities_df_bk\n",
    "\n",
    "print('Creating new columns...')\n",
    "\n",
    "print('state...')\n",
    "activities_df = activities_df.assign(state = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[21:23]))\n",
    "print('county...')\n",
    "activities_df = activities_df.assign(county = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[23:26]))\n",
    "print('msa...')\n",
    "activities_df = activities_df.assign(msa = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[26:31]))\n",
    "print('assessment_area_number...')\n",
    "activities_df = activities_df.assign(assessment_area_number = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[31:35]))\n",
    "print('partial_county_indicator...')\n",
    "activities_df = activities_df.assign(partial_county_indicator = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[35]))\n",
    "print('split_county_indicator...')\n",
    "activities_df = activities_df.assign(split_county_indicator = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[36]))\n",
    "print('report_level...')\n",
    "activities_df = activities_df.assign(report_level = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[37:39]))\n",
    "print('nLoansAll...')\n",
    "activities_df = activities_df.assign(nLoansAll = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[39:49]))\n",
    "print('amtLoansAll...')\n",
    "activities_df = activities_df.assign(amtLoansAll = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[49:59]))\n",
    "print('nLoans1Mbiz...')\n",
    "activities_df = activities_df.assign(nLoans1Mbiz = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[59:69]))\n",
    "print('amtLoans1Mbiz...')\n",
    "activities_df = activities_df.assign(amtLoans1Mbiz = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[69:79]))\n",
    "print('nLoanssmallbiz...')\n",
    "activities_df = activities_df.assign(nLoanssmallbiz = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[79:89]))\n",
    "print('amtLoanssmallbiz...')\n",
    "activities_df = activities_df.assign(amtLoanssmallbiz = rdf['thestring'][df['isactivity'] == True].apply(lambda x: x[89:99]))\n",
    "\n",
    "print('dropping columns no longer needed')\n",
    "activities_df = activities_df.drop(['isloan', 'isactivity', 'iscra', 'istract'], axis=1)\n",
    "activities_df = activities_df.drop(['tableID', 'report_level'], axis=1)\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print('Parsed all columns for {0:,.0f} rows in {1:,.0f} seconds'.format(len(activities_df), e-s))\n",
    "\n",
    "print('Saving file...')\n",
    "activities_df.to_csv('activities_df.csv', encoding='utf-8')\n",
    "#activities_df.sample(3).T\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Creating empty dataframe...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "cra_df = pandas.DataFrame(data=None, columns=df.columns, index=df.index)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Dataframe created in {0:,.0f} seconds.\\n'.format(e-s))\n",
    "\n",
    "print('Getting data on activities (tables D3/D4) into activities_df...')\n",
    "s = time.time()\n",
    "cra_df = df[df['iscra'] == True]\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('CRA data: copied {0:,.0f} rows in {1:,.0f} seconds.\\n'.format(len(cra_df), e-s))\n",
    "\n",
    "print('backing up')\n",
    "cra_df_bk = cra_df\n",
    "\n",
    "print('Done in {0:,.0f} seconds!'.format(c))\n",
    "#cra_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('Retrieving backup...')\n",
    "cra_df = cra_df_bk\n",
    "print('Creating new columns...')\n",
    "\n",
    "print('nLoansAll...')\n",
    "cra_df = cra_df.assign(nLoansAll = rdf['thestring'][df['iscra'] == True].apply(lambda x: x[21:31]))\n",
    "print('amtLoansAll...')\n",
    "cra_df = cra_df.assign(amtLoansAll = rdf['thestring'][df['iscra'] == True].apply(lambda x: x[31:41]))\n",
    "print('nLoansAff...')\n",
    "cra_df = cra_df.assign(nLoansAll = rdf['thestring'][df['iscra'] == True].apply(lambda x: x[41:51]))\n",
    "print('amtLoansAff...')\n",
    "cra_df = cra_df.assign(amtLoansAll = rdf['thestring'][df['iscra'] == True].apply(lambda x: x[51:61]))\n",
    "print('action_taken_type...')\n",
    "cra_df = cra_df.assign(amtLoansAll = rdf['thestring'][df['iscra'] == True].apply(lambda x: x[61]))\n",
    "\n",
    "print('backing up...')\n",
    "cra_df_bk = cra_df\n",
    "e = time.time()\n",
    "\n",
    "print('Parsed all columns for {0:,.0f} rows in {1:,.0f} seconds'.format(len(cra_df), e-s))\n",
    "\n",
    "print('dropping columns no longer needed')\n",
    "cra_df = cra_df.drop(['tableID', 'isloan', 'isactivity', 'iscra', 'istract'], axis=1)\n",
    "\n",
    "print('Saving file...')\n",
    "cra_df.to_csv('cra_df.csv', encoding='utf-8')\n",
    "#cra_df.sample(3).T\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 6: Assessment area(s) by tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Creating empty dataframe...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "tracts_df = pandas.DataFrame(data=None, columns=df.columns, index=df.index)\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Dataframe created in {0:,.0f} seconds.\\n'.format(e-s))\n",
    "\n",
    "print('Getting data on tracts (table D6) into tracts_df...')\n",
    "s = time.time()\n",
    "tracts_df = df[df['istract'] == True]\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('Tracts data: copied {0:,.0f} rows in {1:,.0f} seconds.\\n'.format(len(tracts_df), e-s))\n",
    "\n",
    "print('backing up')\n",
    "tracts_df_bk = tracts_df\n",
    "\n",
    "print('Done in {0:,.0f} seconds!'.format(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('Retrieving backup...')\n",
    "tracts_df = tracts_df_bk\n",
    "print('Creating new columns...')\n",
    "\n",
    "print('state...')\n",
    "tracts_df = tracts_df.assign(state = rdf['thestring'][df['istract'] == True].apply(lambda x: x[20:22]))\n",
    "print('county...')\n",
    "tracts_df = tracts_df.assign(county = rdf['thestring'][df['istract'] == True].apply(lambda x: x[22:25]))\n",
    "print('msa...')\n",
    "tracts_df = tracts_df.assign(msa = rdf['thestring'][df['istract'] == True].apply(lambda x: x[25:30]))\n",
    "print('census tract...')\n",
    "tracts_df = tracts_df.assign(census_tract = rdf['thestring'][df['istract'] == True].apply(lambda x: x[30:37]))\n",
    "print('assessment_area_number...')\n",
    "tracts_df = tracts_df.assign(assessment_area_number = rdf['thestring'][df['istract'] == True].apply(lambda x: x[37:41]))\n",
    "print('partial_county_indicator...')\n",
    "tracts_df = tracts_df.assign(partial_county_indicator = rdf['thestring'][df['istract'] == True].apply(lambda x: x[41]))\n",
    "print('split_county_indicator...')\n",
    "tracts_df = tracts_df.assign(split_county_indicator = rdf['thestring'][df['istract'] == True].apply(lambda x: x[42]))\n",
    "print('population_classification...')\n",
    "tracts_df = tracts_df.assign(population_classification = rdf['thestring'][df['istract'] == True].apply(lambda x: x[43]))\n",
    "print('income_group_total...')\n",
    "tracts_df = tracts_df.assign(income_group_total = rdf['thestring'][df['istract'] == True].apply(lambda x: x[44:47]))\n",
    "print('loan_indicator...')\n",
    "tracts_df = tracts_df.assign(loan_indicator = rdf['thestring'][df['istract'] == True].apply(lambda x: x[47]))\n",
    "\n",
    "print('dropping columns no longer needed')\n",
    "tracts_df = tracts_df.drop(['tableID', 'isloan', 'isactivity', 'iscra', 'istract'], axis=1)\n",
    "\n",
    "e = time.time()\n",
    "\n",
    "print('Parsed all columns for {0:,.0f} rows in {1:,.0f} seconds'.format(len(tracts_df), e-s))\n",
    "\n",
    "print('Saving file...')\n",
    "tracts_df.to_csv('tracts_df.csv', encoding='utf-8')\n",
    "#tracts_df.sample(3).T\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLDER: Add historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for i in range(4,16):\n",
    "    thisfile = '{:02d}exp_discl'.format(i)\n",
    "    if i in [4,5,6]:\n",
    "        thisfile = thisfile + '_new.dat'\n",
    "    else:\n",
    "        thisfile = thisfile + '.dat'\n",
    "    filelist.append(thisfile)\n",
    "        \n",
    "print('Got list of data files from 2004 to 2015!')\n",
    "print('\\n')\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for thisfile in filelist:\n",
    "    print('Reading {0:}exp_discl.dat...'.format(thisfile))\n",
    "    thisyear_df = pandas.read_csv(thisfile, low_memory=False, header=None)\n",
    "    print('Appending...')\n",
    "    df = df.append(thisyear_df)\n",
    "    #print('\\n')\n",
    "history_df.columns = ['thestring']\n",
    "history_df.index.name = 'rownumber'\n",
    "#history_df.head(1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'{:,.0f}'.format(len(history_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.listdir()\n",
    "# Original file is one huge giant string. Read that string.\n",
    "print('Reading table D1-1...')\n",
    "bizorig = pandas.read_csv('cra2016_Discl_D11.dat', header=None)\n",
    "bizorig.name = 'bizorig'\n",
    "bizorig.columns = ['thestring']\n",
    "\n",
    "# Now parse the strings into individual values, following the data guide in the PDF\n",
    "print('Parsing strings...')\n",
    "bizorig['tableID'] = bizorig['thestring'].apply(lambda x: x[0:5])\n",
    "bizorig['respondentID'] = bizorig['thestring'].apply(lambda x: x[5:15])\n",
    "bizorig['agency_code'] = bizorig['thestring'].apply(lambda x: x[15])\n",
    "bizorig['activity_year'] = bizorig['thestring'].apply(lambda x: x[16:20])\n",
    "bizorig['loan_type'] = bizorig['thestring'].apply(lambda x: x[20])\n",
    "bizorig['action_taken_type'] = bizorig['thestring'].apply(lambda x: x[21])\n",
    "bizorig['state'] = bizorig['thestring'].apply(lambda x: x[22:24])\n",
    "bizorig['county'] = bizorig['thestring'].apply(lambda x: x[24:27])\n",
    "bizorig['msa'] = bizorig['thestring'].apply(lambda x: x[27:32])\n",
    "bizorig['assessment_area_number'] = bizorig['thestring'].apply(lambda x: x[33:36])\n",
    "bizorig['partial_county_indicator'] = bizorig['thestring'].apply(lambda x: x[36])\n",
    "bizorig['split_county_indicator'] = bizorig['thestring'].apply(lambda x: x[37])\n",
    "bizorig['population_classification'] = bizorig['thestring'].apply(lambda x: x[38])\n",
    "bizorig['income_group_total'] = bizorig['thestring'].apply(lambda x: x[39:42])\n",
    "bizorig['report_level'] = bizorig['thestring'].apply(lambda x: x[42:45])\n",
    "\n",
    "bizorig['nLoans1'] = bizorig['thestring'].apply(lambda x: x[45:55])\n",
    "bizorig['amtLoans1'] = bizorig['thestring'].apply(lambda x: x[55:65])\n",
    "bizorig['nLoans100k'] = bizorig['thestring'].apply(lambda x: x[65:75])\n",
    "bizorig['amtLoans100k'] = bizorig['thestring'].apply(lambda x: x[75:85])\n",
    "bizorig['nLoans250k'] = bizorig['thestring'].apply(lambda x: x[85:95])\n",
    "bizorig['amtLoans250k'] = bizorig['thestring'].apply(lambda x: x[95:105])\n",
    "bizorig['nLoansTotal'] = bizorig['thestring'].apply(lambda x: x[105:115])\n",
    "bizorig['amtLoansTotal'] = bizorig['thestring'].apply(lambda x: x[115:125])\n",
    "bizorig['nLoansAff'] = bizorig['thestring'].apply(lambda x: x[125:135])\n",
    "bizorig['amtLoansAff'] = bizorig['thestring'].apply(lambda x: x[135:145])\n",
    "\n",
    "bizorig = bizorig.drop('thestring', axis=1)\n",
    "\n",
    "print(bizorig.groupby('loan_type').size())\n",
    "\n",
    "bizorig.sample(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_bk\n",
    "\n",
    "print('Converting data to numeric...')\n",
    "\n",
    "df['respondentID'] = pandas.to_numeric(df['respondentID'], errors='coerce')\n",
    "df['agency_code'] = pandas.to_numeric(df['agency_code'], errors='coerce')\n",
    "df['activity_year'] = pandas.to_numeric(df['activity_year'], errors='coerce')\n",
    "df['loan_type'] = pandas.to_numeric(df['loan_type'], errors='coerce')\n",
    "df['action_taken_type'] = pandas.to_numeric(df['action_taken_type'], errors='coerce')\n",
    "df['state'] = pandas.to_numeric(df['state'], errors='coerce')\n",
    "df['county'] = pandas.to_numeric(df['county'], errors='coerce')\n",
    "df['msa'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['income_group_total'] = pandas.to_numeric(df['income_group_total'], errors='coerce')\n",
    "\n",
    "df['nLoans1'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['amtLoans1'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['nLoans100k'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['amtLoans100k'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['nLoans250k'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['amtLoans250k'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['nLoansTotal'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['amtLoansTotal'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['nLoansAff'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "df['amtLoansAff'] = pandas.to_numeric(df['msa'], errors='coerce')\n",
    "\n",
    "print('Assigning codes...')\n",
    "\n",
    "df = df.rename(columns={'loan_type': 'loan_type_code'})\n",
    "df = df.assign(loan_type = '')\n",
    "\n",
    "#df.loc[df['loan_type_code'] == '4', 'loan_type'] = 'Small business'\n",
    "#df.loc[df['loan_type_code'] == '5', 'loan_type'] = 'Small farm'\n",
    "#df.loc[df['loan_type_code'] == 6, 'loan_type'] = 'Community Development'\n",
    "#df.loc[df['loan_type_code'] == 7, 'loan_type'] = 'Consortium/Third-Party'\n",
    "\n",
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('loan_type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert raw data columns to numbers and codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Looking up data codes...')\n",
    "df['agency'] = ''\n",
    "df.loc[tracts['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "df.loc[tracts['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "df.loc[tracts['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "df.loc[tracts['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tracts = tracts.drop('thestring', axis=1)\n",
    "\n",
    "\n",
    "#bizorig['assessment_area_number'] = pandas.to_numeric(bizorig['assessment_area_number'], downcast='integer', errors='coerce')\n",
    "\n",
    "print('Looking up insitution names from respondentIDs...')\n",
    "respondents = pandas.read_csv('respondentid.csv', index_col='respondentID')\n",
    "tracts = tracts.join(respondents, how='left', on='respondentID')#[['respondentID', 'institution_name']].drop_duplicates()\n",
    "\n",
    "\n",
    "tracts.index.name = 'row_number'\n",
    "\n",
    "tracts_bk = tracts\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bizorig = bizorig_bk\n",
    "\n",
    "print('Converting geography codes...')\n",
    "bizorig['respondentID'] = pandas.to_numeric(bizorig['respondentID'], downcast='integer', errors='coerce')\n",
    "bizorig['agency_code'] = pandas.to_numeric(bizorig['agency_code'], downcast='integer', errors='coerce')\n",
    "bizorig['activity_year'] = pandas.to_numeric(bizorig['activity_year'], downcast='integer', errors='coerce')\n",
    "bizorig['loan_type'] = pandas.to_numeric(bizorig['loan_type'], downcast='integer', errors='coerce')\n",
    "bizorig['action_taken_type'] = pandas.to_numeric(bizorig['action_taken_type'], downcast='integer', errors='coerce')\n",
    "bizorig['state'] = pandas.to_numeric(bizorig['state'], downcast='integer', errors='coerce')\n",
    "bizorig['county'] = pandas.to_numeric(bizorig['county'], downcast='integer', errors='coerce')\n",
    "bizorig['msa'] = pandas.to_numeric(bizorig['msa'], downcast='integer', errors='coerce')\n",
    "#bizorig['assessment_area_number'] = pandas.to_numeric(bizorig['assessment_area_number'], downcast='integer', errors='coerce')\n",
    "\n",
    "print('Converting numbers...')\n",
    "bizorig['nBizLoans1'] = pandas.to_numeric(bizorig['nBizLoans1'])\n",
    "bizorig['amtBizLoans1'] = pandas.to_numeric(bizorig['amtBizLoans1']) * 1000\n",
    "bizorig['nBizLoans100k'] = pandas.to_numeric(bizorig['nBizLoans100k'])\n",
    "bizorig['amtBizLoans100k'] = pandas.to_numeric(bizorig['amtBizLoans100k']) * 1000\n",
    "bizorig['nBizLoans250k'] = pandas.to_numeric(bizorig['nBizLoans250k'])\n",
    "bizorig['amtBizLoans250k'] = pandas.to_numeric(bizorig['amtBizLoans250k']) * 1000\n",
    "bizorig['nBizLoans1M'] = pandas.to_numeric(bizorig['nBizLoans1M'])\n",
    "bizorig['amtBizLoans1M'] = pandas.to_numeric(bizorig['amtBizLoans1M']) * 1000\n",
    "bizorig['nBizLoansAff'] = pandas.to_numeric(bizorig['nBizLoansAff'])\n",
    "bizorig['amtBizLoansAff'] = pandas.to_numeric(bizorig['amtBizLoansAff']) * 1000\n",
    "\n",
    "bizorig_bk = bizorig\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bizorig = bizorig_bk\n",
    "\n",
    "print('Looking up data codes...')\n",
    "# agency code\n",
    "bizorig['agency'] = ''\n",
    "bizorig.loc[bizorig['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "bizorig.loc[bizorig['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "bizorig.loc[bizorig['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "bizorig.loc[bizorig['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "\n",
    "# income group code\n",
    "bizorig['income_group'] = 'xxx'\n",
    "bizorig.loc[bizorig['income_group_total'] == '001', 'income_group'] = '< 10% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '002', 'income_group'] = '10-20% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '003', 'income_group'] = '20-30% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '004', 'income_group'] = '30-40% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '005', 'income_group'] = '40-50% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '006', 'income_group'] = '50-60% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '007', 'income_group'] = '60-70% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '008', 'income_group'] = '70-80% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '009', 'income_group'] = '80-90% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '010', 'income_group'] = '90-100% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '011', 'income_group'] = '100-110% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '012', 'income_group'] = '110-120% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '013', 'income_group'] = '> 120% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '013', 'income_group'] = '> 120% MFI'\n",
    "bizorig.loc[bizorig['income_group_total'] == '014', 'income_group'] = 'MFI not known'\n",
    "bizorig.loc[bizorig['income_group_total'] == '015', 'income_group'] = 'Tract not known'\n",
    "bizorig.loc[bizorig['income_group_total'] == '101', 'income_group'] = 'Low income'\n",
    "bizorig.loc[bizorig['income_group_total'] == '102', 'income_group'] = 'Moderate income'\n",
    "bizorig.loc[bizorig['income_group_total'] == '103', 'income_group'] = 'Middle income'\n",
    "bizorig.loc[bizorig['income_group_total'] == '104', 'income_group'] = 'Upper income'\n",
    "bizorig.loc[bizorig['income_group_total'] == '105', 'income_group'] = 'Income not known'\n",
    "bizorig.loc[bizorig['income_group_total'] == '106', 'income_group'] = 'Tract not known (via cra level)'\n",
    "\n",
    "# Find institution names by respondent IDs\n",
    "respondents = pandas.read_csv('respondentid.csv', index_col='respondentID')\n",
    "bizorig = bizorig.join(respondents, how='left', on='respondentID')\n",
    "\n",
    "print('Summing numbers...')\n",
    "bizorig['nBizLoans'] = bizorig['nBizLoans1'\n",
    "                              ] + bizorig['nBizLoans100k'\n",
    "                                         ] + bizorig['nBizLoans250k'\n",
    "                                                    ] #+ bizorig['nBizLoans1M'\n",
    "                                                        #]# + bizorig['nBizLoansAff']\n",
    "bizorig['amtBizLoans'] = bizorig['amtBizLoans1'\n",
    "                                ] + bizorig['amtBizLoans100k'\n",
    "                                           ] + bizorig['amtBizLoans250k'\n",
    "                                                      ] #+ bizorig['amtBizLoans1M'\n",
    "                                                            #]# + bizorig['amtBizLoansAff']\n",
    "bizorig.index.name = 'row_number'\n",
    "\n",
    "# Remove county totals (blank income group) so we don't double-count\n",
    "bizorig = bizorig[(bizorig['income_group'] != 'xxx')]\n",
    "\n",
    "#bizorig.groupby('income_group').size()\n",
    "\n",
    "#baltimore_originators  = baltimore_originators.join(respondents, on='respondentID')\n",
    "bizorig_bk = bizorig\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baltimore_originators = bizorig[(bizorig['state'] == 24) & (bizorig['county'] == 510)]\n",
    "\n",
    "htmlstring = '<table>'\n",
    "htmlstring += '<tr><th>Institution</th><th>Amount</th>'\n",
    "for idx, amt in baltimore_originators[baltimore_originators['income_group_total'] != '   '].groupby('institution_name')['amtBizLoans'].sum().sort_values(ascending=False).iteritems():\n",
    "    htmlstring += '<tr><td>{0:}</td><td>${1:,.0f}</td></tr>'.format(idx, amt)\n",
    "\n",
    "#display(HTML(htmlstring))\n",
    "\n",
    "#print(len(baltimore_originators))\n",
    "\n",
    "baltimore_originators = baltimore_originators.assign(cra_level = '')\n",
    "\n",
    "#baltimore_originators.add(pandas.Series(data=baltimore_originators['income_group'].values[0], name='cra_level'))#['income_group']\n",
    "#baltimore_originators['cra_level']\n",
    "#baltimore_originators.columns\n",
    "\n",
    "baltimore_originators.loc[(baltimore_originators['income_group_total'].apply(lambda x: x in ['001', '002', '003', '004', '005'])), 'cra_level'] = 'low'\n",
    "baltimore_originators.loc[(baltimore_originators['income_group_total'].apply(lambda x: x in ['006', '007', '008'])), 'cra_level'] = 'moderate'\n",
    "baltimore_originators.loc[(baltimore_originators['income_group_total'].apply(lambda x: x in ['009', '010', '011', '012'])), 'cra_level'] = 'middle'\n",
    "baltimore_originators.loc[(baltimore_originators['income_group_total'].apply(lambda x: x in ['013'])), 'cra_level'] = 'upper'\n",
    "baltimore_originators.loc[(baltimore_originators['income_group_total'].apply(lambda x: x in ['014', '015'])), 'cra_level'] = 'unknown'\n",
    "\n",
    "#neworder = \n",
    "\n",
    "#baltimore_originators = baltimore_originators.reindex(neworder)\n",
    "\n",
    "baltimore_originators.groupby('cra_level').size().reindex(['low', 'moderate', 'middle', 'upper', 'unknown'])\n",
    "\n",
    "#baltimore_originators[baltimore_originators['cra_level'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total lending in Baltimore City by institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htmlstring = '<table>'\n",
    "htmlstring += '<tr><th>Institution</th><th>Amount</th>'\n",
    "for idx, amt in baltimore_originators[baltimore_originators['income_group_total'] != '   '].groupby('institution_name')['amtBizLoans'].sum().sort_values(ascending=False).iteritems():\n",
    "    htmlstring += '<tr><td>{0:}</td><td>${1:,.0f}</td></tr>'.format(idx, amt)\n",
    "\n",
    "display(HTML(htmlstring))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortorderlist = baltimore_originators.groupby('institution_name')['amtBizLoans'].sum().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "sortorder = pandas.Index(sortorderlist)\n",
    "\n",
    "lending = baltimore_originators.groupby(['institution_name', 'cra_level'])[['nBizLoans', 'amtBizLoans']].sum().unstack('cra_level').reindex(sortorder)#.sort_values(by=['amtBizLoans'], ascending=False)\n",
    "\n",
    "lending.to_csv('lendingtable.csv', encoding='utf-8')\n",
    "lending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add neighborhoods (from census tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baltimore_tracts[baltimore_tracts['loan_indicator'] == 'Y'].groupby(['census_tract', 'institution_name']).size().sort_index()\n",
    "\n",
    "tracts = tracts_bk\n",
    "\n",
    "baltimore_tracts = tracts[(tracts['state'] == 24) & (tracts['county'] == 510)]\n",
    "\n",
    "#baltimore_tracts['census_tract'].head(10)\n",
    "tracts_to_neighborhoods = pandas.read_csv('neighborhoods/census_tract_to_neighborhood.csv')\n",
    "tracts_to_neighborhoods = tracts_to_neighborhoods.set_index('NAME10')\n",
    "#tracts_to_neighborhoods\n",
    "\n",
    "baltimore_tracts = baltimore_tracts.join(tracts_to_neighborhoods, how='left', on='census_tract')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans_by_neighborhood = pandas.Series(data=baltimore_tracts[baltimore_tracts['loan_indicator'] == 'Y'].groupby(['CSA2010', 'institution_name']).size(), name='nLoans')\n",
    "\n",
    "loans_by_neighborhood.to_csv('loans_by_neighborhood.csv', index=True, header=True)\n",
    "print('ok')\n",
    "#loans_by_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for i in range(4,16):\n",
    "    thisfile = '{:02d}exp_discl'.format(i)\n",
    "    if i in [4,5,6]:\n",
    "        thisfile = thisfile + '_new.dat'\n",
    "    else:\n",
    "        thisfile = thisfile + '.dat'\n",
    "    filelist.append(thisfile)\n",
    "        \n",
    "for thisfile in filelist:\n",
    "    print('Reading {0:}exp_discl.dat...'.format(thisfile))\n",
    "    thisyear_df = pandas.read_csv(thisfile, low_memory=False, header=None)\n",
    "thisyear_df.head(1)\n",
    "\n",
    "#os.getcwd()\n",
    "\n",
    "#print('\\n')\n",
    "#print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('read 2015 dat file...')\n",
    "df.columns = ['thestring']\n",
    "\n",
    "# Now parse the strings into individual values, following the data guide in the PDF\n",
    "print('Parsing strings...')\n",
    "df['tableID'] = df['thestring'].apply(lambda x: x[0:5].strip())\n",
    "\n",
    "df['type'] = ''\n",
    "df['respondentID'] = ''\n",
    "df['agency_code'] = ''\n",
    "df['activity_year'] = ''\n",
    "df['loan_type'] = ''\n",
    "df['action_taken_type'] = ''\n",
    "df['state'] = ''\n",
    "df['county'] = ''\n",
    "df['msa'] = ''\n",
    "df['assessment_area_number'] = ''\n",
    "df['partial_county_indicator'] = ''\n",
    "df['split_county_indicator'] = ''\n",
    "df['population_classification'] = ''\n",
    "df['income_group_total'] = ''\n",
    "df['report_level'] = ''\n",
    "\n",
    "df['nBizLoans1'] = ''\n",
    "df['amtBizLoans1'] = ''\n",
    "df['nBizLoans100k'] = ''\n",
    "df['amtBizLoans100k'] = ''\n",
    "df['nBizLoans250k'] = ''\n",
    "df['amtBizLoans250k'] = ''\n",
    "df['nBizLoans1M'] = ''\n",
    "df['amtBizLoans1M'] = ''\n",
    "df['nBizLoansAff'] = ''\n",
    "df['amtBizLoansAff'] = ''\n",
    "\n",
    "print('Total number of rows: {:,.0f}'.format(len(df)))\n",
    "\n",
    "# Parse table D1-1 (business loan originators)\n",
    "print('Parsing table D1-1 (business loan originators...)')\n",
    "df.loc[df['tableID'] == 'D1-1', 'type'] = 'originator'\n",
    "df.loc[df['tableID'] == 'D1-1', 'respondentID'] = df['thestring'].apply(lambda x: x[5:15])\n",
    "df.loc[df['tableID'] == 'D1-1', 'agency_code'] = df['thestring'].apply(lambda x: x[15])\n",
    "df.loc[df['tableID'] == 'D1-1', 'activity_year'] = df['thestring'].apply(lambda x: x[16:20])\n",
    "df.loc[df['tableID'] == 'D1-1', 'agency_code'] = df['thestring'].apply(lambda x: x[20])\n",
    "df.loc[df['tableID'] == 'D1-1', 'action_taken_type'] = df['thestring'].apply(lambda x: x[21])\n",
    "df.loc[df['tableID'] == 'D1-1', 'state'] = df['thestring'].apply(lambda x: x[22:24])\n",
    "df.loc[df['tableID'] == 'D1-1', 'county'] = df['thestring'].apply(lambda x: x[24:27])\n",
    "df.loc[df['tableID'] == 'D1-1', 'msa'] = df['thestring'].apply(lambda x: x[27:32])\n",
    "df.loc[df['tableID'] == 'D1-1', 'assessment_area_number'] = df['thestring'].apply(lambda x: x[33:36])\n",
    "df.loc[df['tableID'] == 'D1-1', 'partial_county_indicator'] = df['thestring'].apply(lambda x: x[36])\n",
    "df.loc[df['tableID'] == 'D1-1', 'split_county_indicator'] = df['thestring'].apply(lambda x: x[37])\n",
    "df.loc[df['tableID'] == 'D1-1', 'population_classification'] = df['thestring'].apply(lambda x: x[38])\n",
    "df.loc[df['tableID'] == 'D1-1', 'income_group_total'] = df['thestring'].apply(lambda x: x[39:42])\n",
    "df.loc[df['tableID'] == 'D1-1', 'report_level'] = df['thestring'].apply(lambda x: x[42:45])\n",
    "df.loc[df['tableID'] == 'D1-1', 'nBizLoans1'] = df['thestring'].apply(lambda x: x[45:55])\n",
    "df.loc[df['tableID'] == 'D1-1', 'amtBizLoans1'] = df['thestring'].apply(lambda x: x[55:65])\n",
    "df.loc[df['tableID'] == 'D1-1', 'nBizLoans100k'] = df['thestring'].apply(lambda x: x[65:75])\n",
    "df.loc[df['tableID'] == 'D1-1', 'amtBizLoans100k'] = df['thestring'].apply(lambda x: x[75:85])\n",
    "df.loc[df['tableID'] == 'D1-1', 'nBizLoans250k'] = df['thestring'].apply(lambda x: x[85:95])\n",
    "df.loc[df['tableID'] == 'D1-1', 'amtBizLoans250k'] = df['thestring'].apply(lambda x: x[95:105])\n",
    "df.loc[df['tableID'] == 'D1-1', 'nBizLoans1M'] = df['thestring'].apply(lambda x: x[105:115])\n",
    "df.loc[df['tableID'] == 'D1-1', 'amtBizLoans1M'] = df['thestring'].apply(lambda x: x[115:125])\n",
    "df.loc[df['tableID'] == 'D1-1', 'nBizLoansAff'] = df['thestring'].apply(lambda x: x[125:135])\n",
    "df.loc[df['tableID'] == 'D1-1', 'amtBizLoansAff'] = df['thestring'].apply(lambda x: x[135:145])\n",
    "#df[df['tableID'] == 'D1-1'].sample(1).T\n",
    "\n",
    "# Parse table D1-2 (business loan purchasers)\n",
    "print('Parsing table D1-2 (business loan purchasers...)')\n",
    "df.loc[df['tableID'] == 'D1-2', 'type'] = 'purchaser'\n",
    "df.loc[df['tableID'] == 'D1-2', 'respondentID'] = df['thestring'].apply(lambda x: x[5:15])\n",
    "df.loc[df['tableID'] == 'D1-2', 'agency_code'] = df['thestring'].apply(lambda x: x[15])\n",
    "df.loc[df['tableID'] == 'D1-2', 'activity_year'] = df['thestring'].apply(lambda x: x[16:20])\n",
    "df.loc[df['tableID'] == 'D1-2', 'agency_code'] = df['thestring'].apply(lambda x: x[20])\n",
    "df.loc[df['tableID'] == 'D1-2', 'action_taken_type'] = df['thestring'].apply(lambda x: x[21])\n",
    "df.loc[df['tableID'] == 'D1-2', 'state'] = df['thestring'].apply(lambda x: x[22:24])\n",
    "df.loc[df['tableID'] == 'D1-2', 'county'] = df['thestring'].apply(lambda x: x[24:27])\n",
    "df.loc[df['tableID'] == 'D1-2', 'msa'] = df['thestring'].apply(lambda x: x[27:32])\n",
    "df.loc[df['tableID'] == 'D1-2', 'assessment_area_number'] = df['thestring'].apply(lambda x: x[33:36])\n",
    "df.loc[df['tableID'] == 'D1-2', 'partial_county_indicator'] = df['thestring'].apply(lambda x: x[36])\n",
    "df.loc[df['tableID'] == 'D1-2', 'split_county_indicator'] = df['thestring'].apply(lambda x: x[37])\n",
    "df.loc[df['tableID'] == 'D1-2', 'population_classification'] = df['thestring'].apply(lambda x: x[38])\n",
    "df.loc[df['tableID'] == 'D1-2', 'income_group_total'] = df['thestring'].apply(lambda x: x[39:42])\n",
    "df.loc[df['tableID'] == 'D1-2', 'report_level'] = df['thestring'].apply(lambda x: x[42:45])\n",
    "df.loc[df['tableID'] == 'D1-2', 'nBizLoans1'] = df['thestring'].apply(lambda x: x[45:55])\n",
    "df.loc[df['tableID'] == 'D1-2', 'amtBizLoans1'] = df['thestring'].apply(lambda x: x[55:65])\n",
    "df.loc[df['tableID'] == 'D1-2', 'nBizLoans100k'] = df['thestring'].apply(lambda x: x[65:75])\n",
    "df.loc[df['tableID'] == 'D1-2', 'amtBizLoans100k'] = df['thestring'].apply(lambda x: x[75:85])\n",
    "df.loc[df['tableID'] == 'D1-2', 'nBizLoans250k'] = df['thestring'].apply(lambda x: x[85:95])\n",
    "df.loc[df['tableID'] == 'D1-2', 'amtBizLoans250k'] = df['thestring'].apply(lambda x: x[95:105])\n",
    "df.loc[df['tableID'] == 'D1-2', 'nBizLoans1M'] = df['thestring'].apply(lambda x: x[105:115])\n",
    "df.loc[df['tableID'] == 'D1-2', 'amtBizLoans1M'] = df['thestring'].apply(lambda x: x[115:125])\n",
    "df.loc[df['tableID'] == 'D1-2', 'nBizLoansAff'] = df['thestring'].apply(lambda x: x[125:135])\n",
    "df.loc[df['tableID'] == 'D1-2', 'amtBizLoansAff'] = df['thestring'].apply(lambda x: x[135:145])\n",
    "#df[df['tableID'] == 'D1-2'].sample(1).T\n",
    "\n",
    "# Parse table D6 (tracts)\n",
    "print('Parsing table D6 (tracts...)')\n",
    "df.loc[df['tableID'] == 'D6-0', 'type'] = 'tract'\n",
    "df.loc[df['tableID'] == 'D6-0', 'respondentID'] = df['thestring'].apply(lambda x: x[5:15])\n",
    "df.loc[df['tableID'] == 'D6-0', 'agency_code'] = df['thestring'].apply(lambda x: x[15])\n",
    "df.loc[df['tableID'] == 'D6-0', 'activity_year'] = df['thestring'].apply(lambda x: x[16:20])\n",
    "df.loc[df['tableID'] == 'D6-0', 'state'] = df['thestring'].apply(lambda x: x[20:22])\n",
    "df.loc[df['tableID'] == 'D6-0', 'county'] = df['thestring'].apply(lambda x: x[22:25])\n",
    "df.loc[df['tableID'] == 'D6-0', 'msa'] = df['thestring'].apply(lambda x: x[25:30])\n",
    "df.loc[df['tableID'] == 'D6-0', 'census_tract'] = df['thestring'].apply(lambda x: x[30:37])\n",
    "df.loc[df['tableID'] == 'D6-0', 'assessment_area_number'] = df['thestring'].apply(lambda x: x[37:41])\n",
    "df.loc[df['tableID'] == 'D6-0', 'partial_county_indicator'] = df['thestring'].apply(lambda x: x[41])\n",
    "df.loc[df['tableID'] == 'D6-0', 'split_county_indicator'] = df['thestring'].apply(lambda x: x[42])\n",
    "df.loc[df['tableID'] == 'D6-0', 'population_classification'] = df['thestring'].apply(lambda x: x[43])\n",
    "df.loc[df['tableID'] == 'D6-0', 'income_group_total'] = df['thestring'].apply(lambda x: x[44:47])\n",
    "df.loc[df['tableID'] == 'D6-0', 'loan_indicator'] = df['thestring'].apply(lambda x: x[47])\n",
    "df.loc[df['tableID'] == 'D6-0', 'filter'] = df['thestring'].apply(lambda x: x[48:145])\n",
    "#df[df['tableID'] == 'D6-0'].sample(1).T\n",
    "\n",
    "print('Converting numbers...')\n",
    "df['nBizLoans1'] = pandas.to_numeric(df['nBizLoans1'])\n",
    "df['amtBizLoans1'] = pandas.to_numeric(df['amtBizLoans1']) * 1000\n",
    "df['nBizLoans100k'] = pandas.to_numeric(df['nBizLoans100k'])\n",
    "df['amtBizLoans100k'] = pandas.to_numeric(df['amtBizLoans100k']) * 1000\n",
    "df['nBizLoans250k'] = pandas.to_numeric(df['nBizLoans250k'])\n",
    "df['amtBizLoans250k'] = pandas.to_numeric(df['amtBizLoans250k']) * 1000\n",
    "df['nBizLoans1M'] = pandas.to_numeric(df['nBizLoans1M'])\n",
    "df['amtBizLoans1M'] = pandas.to_numeric(df['amtBizLoans1M']) * 1000\n",
    "df['nBizLoansAff'] = pandas.to_numeric(df['nBizLoansAff'])\n",
    "df['amtBizLoansAff'] = pandas.to_numeric(df['amtBizLoansAff']) * 1000\n",
    "df['respondentID'] = pandas.to_numeric(df['respondentID'], downcast='integer', errors='coerce')\n",
    "df['agency_code'] = pandas.to_numeric(df['agency_code'], downcast='integer', errors='coerce')\n",
    "df['activity_year'] = pandas.to_numeric(df['activity_year'], downcast='integer', errors='coerce')\n",
    "\n",
    "print('Looking up data codes...')\n",
    "df['agency'] = ''\n",
    "df.loc[df['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "df.loc[df['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "df.loc[df['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "df.loc[df['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "\n",
    "print('Summing numbers...')\n",
    "df['nBizLoans'] = df['nBizLoans1'] + df['nBizLoans100k'] + df['nBizLoans250k'] + df['nBizLoans1M'] + df['nBizLoansAff']\n",
    "df['amtBizLoans'] = df['amtBizLoans1'] + df['amtBizLoans100k'] + df['amtBizLoans250k'] + df['amtBizLoans1M'] + df['amtBizLoansAff']\n",
    "\n",
    "print('Converting geography codes...')\n",
    "df['state'] = pandas.to_numeric(df['state'], downcast='integer', errors='coerce')\n",
    "df['county'] = pandas.to_numeric(df['county'], downcast='integer', errors='coerce')\n",
    "df['msa'] = pandas.to_numeric(df['msa'], downcast='integer', errors='coerce')\n",
    "df['census_tract'] = pandas.to_numeric(df['census_tract'], downcast='integer', errors='coerce')\n",
    "\n",
    "print('Looking up insitution names from respondentIDs...')\n",
    "respondents = pandas.read_csv('respondentid.csv', index_col='respondentID')\n",
    "df = df.join(respondents, how='left', on='respondentID')#[['respondentID', 'institution_name']].drop_duplicates()\n",
    "\n",
    "print('Dropping raw string variable, no longer needed...')\n",
    "df = df.drop('thestring', axis=1)\n",
    "\n",
    "print('Keeping only tables D1-1, D1-2, and D6-0.')\n",
    "df = df[df['type'] != '']\n",
    "\n",
    "df.index.name = 'rownumber'\n",
    "\n",
    "print('done')\n",
    "df.sample(1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(df.groupby('type').size())\n",
    "#os.chdir('/home/idies/workspace/Storage/raddick/persistent/cra/')\n",
    "os.chdir('/home/idies/workspace/Temporary/raddick/cra_scratch/')\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "df.to_csv('2015all.csv', encoding='utf-8')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv('2015all.csv', encoding='utf-8', low_memory=False)\n",
    "df = df.set_index('rownumber')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baltimore_2015_df = df[(df['state'] == 24) & (df['county'] == 510)]\n",
    "\n",
    "print('Keeping {:,.0f} rows from Baltimore!'.format(len(baltimore_2015_df)))\n",
    "\n",
    "showcols = ['type', 'institution_name', 'activity_year', 'agency', 'assessment_area_number']\n",
    "showcols += ['census_tract', 'income_group_total', 'report_level']\n",
    "showcols += ['filter', 'nBizLoans', 'amtBizLoans']\n",
    "baltimore_2015_df[showcols].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add neighborhood info (from census tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baltimore_2015_tracts = baltimore_2015_df[baltimore_2015_df['type'] == 'tract']\n",
    "\n",
    "#baltimore_tracts['census_tract'].head(10)\n",
    "tracts_to_neighborhoods = pandas.read_csv('neighborhoods/census_tract_to_neighborhood.csv')\n",
    "tracts_to_neighborhoods = tracts_to_neighborhoods.set_index('NAME10')\n",
    "#tracts_to_neighborhoods\n",
    "\n",
    "baltimore_2015_tracts = baltimore_2015_tracts.join(tracts_to_neighborhoods, how='left', on='census_tract')\n",
    "print('ok')\n",
    "baltimore_2015_tracts.groupby('CSA2010').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baltimore_originators_2015 = baltimore_2015_df[baltimore_2015_df['type']=='originator']\n",
    "\n",
    "baltimore_originators_2015 = baltimore_originators_2015.assign(cra_level = '')\n",
    "\n",
    "baltimore_originators_2015.loc[(baltimore_originators_2015['income_group_total'].apply(lambda x: x in ['001', '002', '003', '004', '005'])), 'cra_level'] = 'low'\n",
    "baltimore_originators_2015.loc[(baltimore_originators_2015['income_group_total'].apply(lambda x: x in ['006', '007', '008'])), 'cra_level'] = 'moderate'\n",
    "baltimore_originators_2015.loc[(baltimore_originators_2015['income_group_total'].apply(lambda x: x in ['009', '010', '011', '012'])), 'cra_level'] = 'middle'\n",
    "baltimore_originators_2015.loc[(baltimore_originators_2015['income_group_total'].apply(lambda x: x in ['013'])), 'cra_level'] = 'upper'\n",
    "baltimore_originators_2015.loc[(baltimore_originators_2015['income_group_total'].apply(lambda x: x in ['014', '015'])), 'cra_level'] = 'unknown'\n",
    "\n",
    "baltimore_originators_2015.groupby('cra_level').size().reindex(['low', 'moderate', 'middle', 'upper', 'unknown'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total lending in Baltimore City by institution in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htmlstring = '<table>'\n",
    "htmlstring += '<tr><th>Institution</th><th>Amount</th>'\n",
    "for idx, amt in baltimore_originators_2015[baltimore_originators_2015['income_group_total'] != '   '].groupby('institution_name')['amtBizLoans'].sum().sort_values(ascending=False).iteritems():\n",
    "    htmlstring += '<tr><td>{0:}</td><td>${1:,.0f}</td></tr>'.format(idx, amt)\n",
    "\n",
    "display(HTML(htmlstring))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[(df['type'] == 'originator') &\n",
    "   (df['state'] == 24) &\n",
    "   (df['county'] == 510)\n",
    "  ].to_csv('baltimore_cra2015_Discl_D11.csv', encoding='utf-8')\n",
    "\n",
    "df[(df['type'] == 'tract') &\n",
    "   (df['state'] == 24) &\n",
    "   (df['county'] == 510)\n",
    "  ].to_csv('baltimore_cra2015_Discl_D6.csv', encoding='utf-8')\n",
    "print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
