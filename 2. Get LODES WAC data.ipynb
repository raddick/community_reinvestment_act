{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup \n",
    "import time\n",
    "#import zipfile\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "#import io\n",
    "data_dir = '/home/idies/workspace/21cc/Data/'\n",
    "jobs_dir = data_dir + 'LODES8/'\n",
    "baltimore_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/code_guide_lookups/'\n",
    "\n",
    "os.chdir(jobs_dir)\n",
    "this_state = 'wy'\n",
    "\n",
    "g = 0\n",
    "print('Done!')\n",
    "\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.006 seconds!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LODESTechDoc8.1.pdf',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'ar',\n",
       " 'az',\n",
       " 'ca',\n",
       " 'co',\n",
       " 'ct',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'fl',\n",
       " 'ga',\n",
       " 'hi',\n",
       " 'ia',\n",
       " 'id',\n",
       " 'il',\n",
       " 'in',\n",
       " 'ks',\n",
       " 'ky',\n",
       " 'la',\n",
       " 'ma',\n",
       " 'md',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mn',\n",
       " 'mo',\n",
       " 'ms',\n",
       " 'mt',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'nh',\n",
       " 'nj',\n",
       " 'nm',\n",
       " 'ny',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'or',\n",
       " 'pa',\n",
       " 'ri',\n",
       " 'sc',\n",
       " 'sd',\n",
       " 'tn',\n",
       " 'tx',\n",
       " 'ut',\n",
       " 'va',\n",
       " 'vt',\n",
       " 'wa',\n",
       " 'wi',\n",
       " 'wv',\n",
       " 'wy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "y = os.listdir(data_dir)\n",
    "hasdir = [x for x in y if x=='LODES8']\n",
    "if (len(hasdir) == 0):\n",
    "    os.mkdir(jobs_dir)\n",
    "if ('{0:}'.format(this_state) not in [x for x in os.listdir(jobs_dir) if x[-4:] != '.pdf']):\n",
    "    os.mkdir(jobs_dir+'{0:}'.format(this_state))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.3f} seconds!'.format(e-s))\n",
    "sorted(os.listdir(jobs_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LODES data from census.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating directory structure...\n",
      "creating directory structure...\n",
      "creating directory structure...\n",
      "https://lehd.ces.census.gov/data/lodes/LODES8/wy\n",
      "\tgetting version and crosswalk...\n",
      "\tgetting origin-destination data...\n",
      "\t\tDownloading file 0 of 208...\n",
      "\t\tDownloading file 50 of 208...\n",
      "\t\tDownloading file 100 of 208...\n",
      "\t\tDownloading file 150 of 208...\n",
      "\t\tDownloading file 200 of 208...\n",
      "\tgetting workplace area data...\n",
      "\t\tDownloading file 0 of 1,012...\n",
      "\t\tDownloading file 100 of 1,012...\n",
      "\t\tDownloading file 200 of 1,012...\n",
      "\t\tDownloading file 300 of 1,012...\n",
      "\t\tDownloading file 400 of 1,012...\n",
      "\t\tDownloading file 500 of 1,012...\n",
      "\t\tDownloading file 600 of 1,012...\n",
      "\t\tDownloading file 700 of 1,012...\n",
      "\t\tDownloading file 800 of 1,012...\n",
      "\t\tDownloading file 900 of 1,012...\n",
      "\t\tDownloading file 1,000 of 1,012...\n",
      "unzipping OD files...\n",
      "\tUnzipping file 0 of 208...\n",
      "\tUnzipping file 50 of 208...\n",
      "\tUnzipping file 100 of 208...\n",
      "\tUnzipping file 150 of 208...\n",
      "\tUnzipping file 200 of 208...\n",
      "unzipping WAC files...\n",
      "\tUnzipping file 0 of 1,012...\n",
      "\tUnzipping file 100 of 1,012...\n",
      "\tUnzipping file 200 of 1,012...\n",
      "\tUnzipping file 300 of 1,012...\n",
      "\tUnzipping file 400 of 1,012...\n",
      "\tUnzipping file 500 of 1,012...\n",
      "\tUnzipping file 600 of 1,012...\n",
      "\tUnzipping file 700 of 1,012...\n",
      "\tUnzipping file 800 of 1,012...\n",
      "\tUnzipping file 900 of 1,012...\n",
      "\tUnzipping file 1,000 of 1,012...\n",
      "Done in 5 minutes 32 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "theurl = 'https://lehd.ces.census.gov/data/lodes/LODES8/'\n",
    "#print(theurl)\n",
    "#print('getting documentation as unopenable PDF...')\n",
    "indexpage = request.urlopen(theurl)\n",
    "soup = BeautifulSoup(indexpage, 'html.parser')\n",
    "indexpage.close()\n",
    "\n",
    "bigtable = soup.find('table')\n",
    "latest_pdf_file_name = [x for x in bigtable.findAll('tr') if '.pdf' in x.get_text()][-1].find('a').get('href')\n",
    "latest_pdf_url = theurl + latest_pdf_file_name\n",
    "pdfobj = request.urlopen(latest_pdf_url).read()\n",
    "\n",
    "with open(jobs_dir+latest_pdf_file_name, 'wb') as f:\n",
    "    f.write(pdfobj)\n",
    "\n",
    "# #print('getting state data...')\n",
    "# allstaterows = bigtable.findAll('tr')\n",
    "\n",
    "# for i in range(0, len(allstaterows)):\n",
    "#     if (allstaterows[i].get_text()[:allstaterows[i].get_text().find('/')] == this_state):\n",
    "#         print(allstaterows[i].get_text())\n",
    "#state_url = 'https://lehd.ces.census.gov/data/lodes/LODES7/{0:}/'.format(this_state)\n",
    "#print(state_url)\n",
    "\n",
    "for thisdirtype in ['od', 'rac', 'wac']:\n",
    "    if (thisdirtype not in os.listdir(jobs_dir+this_state)):\n",
    "        print('creating directory structure...')\n",
    "        os.mkdir(jobs_dir+this_state+'/'+thisdirtype)\n",
    "#allstatecells = allstaterows[i].findAll('td')\n",
    "version_text_file = request.urlopen('{0:}{1:}/version.txt'.format(theurl, this_state)).read()\n",
    "print('{0:}{1:}'.format(theurl,this_state))\n",
    "\n",
    "print('\\tgetting version and crosswalk...')\n",
    "\n",
    "crosswalk_zipfile_name = '{0:}_xwalk.csv.gz'.format(this_state)\n",
    "crosswalk_zipfile = request.urlopen('{0:}{1:}/{2:}'.format(theurl,this_state,crosswalk_zipfile_name)).read()\n",
    "\n",
    "with open('{0:}{1:}/{2}'.format(jobs_dir, this_state, crosswalk_zipfile_name), 'wb') as f:\n",
    "    f.write(crosswalk_zipfile)\n",
    "\n",
    "csvfilename = '{0:}{1:}/{2}'.format(jobs_dir, this_state, crosswalk_zipfile_name)[:-3]\n",
    "with gzip.open('{0:}{1:}/{2}'.format(jobs_dir, this_state, crosswalk_zipfile_name), 'rb') as f:\n",
    "    file_content = f.read()\n",
    "with open(csvfilename, 'wb') as f:\n",
    "    f.write(file_content)\n",
    "os.remove('{0:}{1:}/{2}'.format(jobs_dir, this_state, crosswalk_zipfile_name))\n",
    "\n",
    "print('\\tgetting origin-destination data...')\n",
    "odurl = '{0:}{1:}/od/'.format(theurl, this_state)\n",
    "odpage = request.urlopen(odurl)\n",
    "\n",
    "odsoup = BeautifulSoup(odpage, 'html.parser')\n",
    "odtable = odsoup.find('table')\n",
    "odrows = odtable.findAll('tr')\n",
    "od_zipfile_list = [x.find('a').get('href') for x in odrows[3:-1]]# if 'JT00' in x.find('a').get('href')]\n",
    "cnt = 0\n",
    "for this_file in od_zipfile_list:\n",
    "    if (np.mod(cnt, 50) == 0):\n",
    "        print('\\t\\tDownloading file {0:,.0f} of {1:,.0f}...'.format(cnt, len(od_zipfile_list)))\n",
    "    with open(jobs_dir+this_state+'/od/'+this_file, 'wb') as f:\n",
    "        f.write(request.urlopen(odurl+this_file).read())\n",
    "    cnt += 1\n",
    "\n",
    "\n",
    "print('\\tgetting workplace area data...')\n",
    "wacurl = '{0:}{1:}/wac/'.format(theurl, this_state)\n",
    "wacpage = request.urlopen(wacurl).read()\n",
    "wacsoup = BeautifulSoup(wacpage, 'html.parser')\n",
    "wactable = wacsoup.find('table')\n",
    "\n",
    "wacrows = wactable.findAll('tr')\n",
    "wac_zipfile_list = [x.find('a').get('href') for x in wacrows[3:-1]]# if 'S000_JT00' in x.find('a').get('href')]\n",
    "\n",
    "cnt = 0\n",
    "for this_file in wac_zipfile_list:\n",
    "    if (np.mod(cnt, 100) == 0):\n",
    "        print('\\t\\tDownloading file {0:,.0f} of {1:,.0f}...'.format(cnt, len(wac_zipfile_list)))\n",
    "    with open(jobs_dir+this_state+'/wac/'+this_file, 'wb') as f:\n",
    "        f.write(request.urlopen(wacurl+this_file).read())\n",
    "    cnt += 1\n",
    "\n",
    "print('unzipping OD files...')\n",
    "od_csvfile_list = [jobs_dir+this_state+'/od/'+x for x in os.listdir(jobs_dir+this_state+'/od/') if x[-3:] == '.gz']\n",
    "cnt = 0\n",
    "for this_file_name in od_csvfile_list:\n",
    "    if (np.mod(cnt, 50) == 0):\n",
    "        print('\\tUnzipping file {0:,.0f} of {1:,.0f}...'.format(cnt, len(od_csvfile_list)))\n",
    "    csvfilename = this_file_name[:-3]\n",
    "    with gzip.open(this_file_name, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "    with open(csvfilename, 'wb') as f:\n",
    "        f.write(file_content)\n",
    "    os.remove(this_file_name)\n",
    "    cnt +=1 \n",
    "\n",
    "wac_csvfile_list = [jobs_dir+this_state+'/wac/'+x for x in os.listdir(jobs_dir+this_state+'/wac/') if x[-3:] == '.gz']\n",
    "\n",
    "print('unzipping WAC files...')\n",
    "cnt = 0\n",
    "for this_file_name in wac_csvfile_list:\n",
    "    if (np.mod(cnt, 100) == 0):\n",
    "        print('\\tUnzipping file {0:,.0f} of {1:,.0f}...'.format(cnt, len(wac_csvfile_list)))\n",
    "    csvfilename = this_file_name[:-3]\n",
    "    with gzip.open(this_file_name, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "    with open(csvfilename, 'wb') as f:\n",
    "        f.write(file_content)\n",
    "    os.remove(this_file_name)\n",
    "    cnt +=1         \n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor((g)/60), np.floor((g)%60)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AK: Done in 0:03:50\n",
    "# AL: Done in 0:15:39\n",
    "# AR: Done in 0:09:10\n",
    "# AZ: Done in 0:16:43\n",
    "# CA: Done in 1:31:45\n",
    "# CO: Done in 0:16:15\n",
    "# CT: Done in 0:12:44\n",
    "# DC: Done in 0:04:18\n",
    "# DE: Done in 0:06:00\n",
    "# FL: Done in 0:49:53\n",
    "# GA: Done in 0:27:01\n",
    "# HI: Done in 0:06:03\n",
    "# IA: Done in 0:12:38\n",
    "# ID: Done in 0:07:39\n",
    "# IL: Done in 0:36:15\n",
    "# IN: Done in 0:19:28\n",
    "# KS: Done in 0:11:53\n",
    "# KY: Done in 0:14:04\n",
    "# LA: Done in 0:15:31\n",
    "# MA: Done in 0:14:36\n",
    "# MD: Done in 0:18:05\n",
    "# ME: Done in 0:07:05\n",
    "# MI: Done in 0:27:11\n",
    "# MN: Done in 0:18:19\n",
    "# MO: Done in 0:20:20\n",
    "# MS: Done in 0:07:45\n",
    "# MT: Done in 0:06:40\n",
    "# NC: Done in 0:28:15\n",
    "# ND: Done in 0:06:13\n",
    "# NE: Done in 0:11:07\n",
    "# NH: Done in 0:06:55\n",
    "# NJ: Done in 0:26:25\n",
    "# NM: Done in 0:09:12\n",
    "# NY: Done in 0:51:37\n",
    "# OH: Done in 0:34:52\n",
    "# OK: Done in 0:13:49\n",
    "# OR: Done in 0:15:01\n",
    "# PA: Done in 0:39:05\n",
    "# RI: Done in 0:06:45\n",
    "# SC: Done in 0:16:42\n",
    "# SD: Done in 0:06:49\n",
    "# TN: Done in 0:27:11\n",
    "# TX: Done in 1:07:49\n",
    "# UT: Done in 0:11:28\n",
    "# VA: Done in 0:25:18\n",
    "# VT: Done in 0:05:50\n",
    "# WA: Done in 0:21:42\n",
    "# WI: Done in 0:19:52\n",
    "# WV: Done in 0:07:58\n",
    "# WY: Done in 0:05:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
