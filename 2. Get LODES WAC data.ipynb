{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup \n",
    "import time\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "#import io\n",
    "data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch/'\n",
    "jobs_dir = data_dir + 'lodes_wac/'\n",
    "baltimore_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/baltimore/'\n",
    "\n",
    "this_state = 'wy'\n",
    "this_state_i = 62\n",
    "\n",
    "\n",
    "g = 0\n",
    "print('Done!')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.002 seconds!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jobs_data_ak.csv',\n",
       " 'jobs_data_al.csv',\n",
       " 'jobs_data_ar.csv',\n",
       " 'jobs_data_dc.csv',\n",
       " 'jobs_data_az.csv',\n",
       " 'jobs_data_ca_0.csv',\n",
       " 'jobs_data_ca_1.csv',\n",
       " 'jobs_data_ca_2.csv',\n",
       " 'jobs_data_ca_3.csv',\n",
       " 'jobs_data_co.csv',\n",
       " 'jobs_data_ct.csv',\n",
       " 'jobs_data_de.csv',\n",
       " 'jobs_data_fl_0.csv',\n",
       " 'jobs_data_fl_1.csv',\n",
       " 'jobs_data_fl_2.csv',\n",
       " 'jobs_data_fl_3.csv',\n",
       " 'jobs_data_ga_0.csv',\n",
       " 'jobs_data_ga_1.csv',\n",
       " 'jobs_data_ga_2.csv',\n",
       " 'jobs_data_ga_3.csv',\n",
       " 'jobs_data_hi.csv',\n",
       " 'jobs_data_ia.csv',\n",
       " 'jobs_data_id.csv',\n",
       " 'jobs_data_il_0.csv',\n",
       " 'jobs_data_il_1.csv',\n",
       " 'jobs_data_il_2.csv',\n",
       " 'jobs_data_il_3.csv',\n",
       " 'jobs_data_in.csv',\n",
       " 'jobs_data_ks.csv',\n",
       " 'jobs_data_ky.csv',\n",
       " 'jobs_data_la.csv',\n",
       " 'jobs_data_ma.csv',\n",
       " 'jobs_data_md.csv',\n",
       " 'jobs_data_me.csv',\n",
       " 'jobs_data_mi.csv',\n",
       " 'jobs_data_mn.csv',\n",
       " 'jobs_data_mo.csv',\n",
       " 'jobs_data_ms.csv',\n",
       " 'jobs_data_mt.csv',\n",
       " 'jobs_data_nc.csv',\n",
       " 'jobs_data_nd.csv',\n",
       " 'jobs_data_ne.csv',\n",
       " 'jobs_data_nh.csv',\n",
       " 'jobs_data_nj.csv',\n",
       " 'jobs_data_nm.csv',\n",
       " 'jobs_data_nv.csv',\n",
       " 'jobs_data_ny_0.csv',\n",
       " 'jobs_data_ny_1.csv',\n",
       " 'jobs_data_ny_2.csv',\n",
       " 'jobs_data_ny_3.csv',\n",
       " 'jobs_data_oh.csv',\n",
       " 'jobs_data_ok.csv',\n",
       " 'jobs_data_or.csv',\n",
       " 'jobs_data_pa.csv',\n",
       " 'jobs_data_ri.csv',\n",
       " 'jobs_data_sc.csv',\n",
       " 'jobs_data_sd.csv',\n",
       " 'jobs_data_tn.csv',\n",
       " 'jobs_data_tx_0.csv',\n",
       " 'jobs_data_tx_1.csv',\n",
       " 'jobs_data_tx_2.csv',\n",
       " 'jobs_data_tx_3.csv',\n",
       " 'jobs_data_ut.csv',\n",
       " 'jobs_data_va_0.csv',\n",
       " 'jobs_data_va_1.csv',\n",
       " 'jobs_data_va_2.csv',\n",
       " 'jobs_data_va_3.csv',\n",
       " 'jobs_data_vt.csv',\n",
       " 'jobs_data_wa.csv',\n",
       " 'jobs_data_wi.csv',\n",
       " 'jobs_data_wv.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "y = os.listdir(data_dir)\n",
    "hasdir = [x for x in y if x=='lodes_wac']\n",
    "if (len(hasdir) == 0):\n",
    "    os.mkdir(jobs_dir)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.3f} seconds!'.format(e-s))\n",
    "#os.listdir(jobs_dir)\n",
    "os.listdir(jobs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get WAC data from census.gov and combine into one file per state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping data...\n",
      "Scraping from: https://lehd.ces.census.gov/data/lodes/LODES7/wy/wac/\n",
      "Parsing state 62 of 60... Getting 860 files...\n",
      "\tReading file 100 of 860...\n",
      "\tReading file 200 of 860...\n",
      "\tReading file 300 of 860...\n",
      "\tReading file 400 of 860...\n",
      "\tReading file 500 of 860...\n",
      "\tReading file 600 of 860...\n",
      "\tReading file 700 of 860...\n",
      "\tReading file 800 of 860...\n",
      "\tReading file 862 of 860...\n",
      "Scrapered data to create 860 files in 4 minutes 3 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "\n",
    "theurl = 'https://lehd.ces.census.gov/data/lodes/LODES7/'\n",
    "print('scraping data...')\n",
    "page = request.urlopen(theurl)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "page.close()\n",
    "\n",
    "bigtable = soup.find('table')\n",
    "allstaterows = bigtable.findAll('tr')\n",
    "\n",
    "#for i in range(9,10): # Alaska: wrote 1,975,372 rows to jobs_data_ak.csv in 24 minutes 40 seconds!\n",
    "#for i in range(10,11): # Alabama:\n",
    "#for i in range(11,12): # Arkansas: wrote 11,346,396 rows to jobs_data_ar.csv in 72 minutes 26 seconds!\n",
    "#for i in range(12,13): # Arizona: wrote 14,821,818 rows to jobs_data_az.csv in 90 minutes 31 seconds!\n",
    "\n",
    "#for i in range(13,14): # California 0, California 1\n",
    "# California 2: wrote 24,754,939 rows to jobs_data_ca_2.csv in 46 minutes 47 seconds!\n",
    "# California 3: Wrote 20,696,087 rows to jobs_data_ca_3.csv in 44 minutes 35 seconds!\n",
    "# Colorado: \n",
    "# Connecticut: wrote 11,443,174 rows to jobs_data_ct.csv in 79 minutes 1 seconds!\n",
    "# DC: wrote 824,450 rows to jobs_data_dc.csv in 5 minutes 21 seconds!\n",
    "# Delaware: wrote 2,963,580 rows to jobs_data_de.csv in 23 minutes 15 seconds!\n",
    "\n",
    "for i in range(this_state_i, this_state_i + 1):\n",
    "    allstatecells = allstaterows[i].findAll('td')\n",
    "    this_state_url = theurl + allstatecells[1].find('a').get('href')+'wac/'\n",
    "    print('Scraping from: {0:}'.format(this_state_url))\n",
    "    #print(this_state_url)\n",
    "    statepage = request.urlopen(this_state_url)\n",
    "    statesoup = BeautifulSoup(statepage, 'html.parser')\n",
    "    statepage.close()\n",
    "    statetable = statesoup.find('table')\n",
    "    filerows = statetable.findAll('tr')\n",
    "    print('Parsing state {0:,.0f} of {1:,.0f}... Getting {2:,.0f} files...'.format(i, 60, len(filerows)-4))\n",
    "    for j in range(3, len(filerows)-1):\n",
    "        if ((np.mod(j, 100) == 0) | (j == len(filerows)-2)):\n",
    "            print('\\tReading file {0:,.0f} of {1:,.0f}...'.format(j, len(filerows)-4))\n",
    "        filecells = filerows[j].findAll('td')\n",
    "        this_file_url = this_state_url + filecells[1].find('a').get('href')\n",
    "        this_file_name = jobs_dir + filecells[1].text\n",
    "        with open(this_file_name, 'wb') as f:\n",
    "            r = request.urlopen(this_file_url)\n",
    "            f.write(r.read())\n",
    "            r.close()\n",
    "nFiles = len([x for x in os.listdir(jobs_dir) if '.gz' in x])\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Scrapered data to create {0:,.0f} files in {1:,.0f} minutes {2:,.0f} seconds!'.format(nFiles, np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping files...\n",
      "Found 860 gzip files...\n",
      "\tUn-gzipping file 0 of 859...\n",
      "\tUn-gzipping file 100 of 859...\n",
      "\tUn-gzipping file 200 of 859...\n",
      "\tUn-gzipping file 300 of 859...\n",
      "\tUn-gzipping file 400 of 859...\n",
      "\tUn-gzipping file 500 of 859...\n",
      "\tUn-gzipping file 600 of 859...\n",
      "\tUn-gzipping file 700 of 859...\n",
      "\tUn-gzipping file 800 of 859...\n",
      "\tUn-gzipping file 859 of 859...\n",
      "Files unzipped in 0 minutes 36 seconds...\n",
      "Deleting zipfiles...\n",
      "Deleted all .gz files in 4 seconds...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('Unzipping files...')\n",
    "gzipfiles = [jobs_dir+x for x in os.listdir(jobs_dir) if ('{0:}_wac'.format(this_state) in x) and (x[-3:] == '.gz')]\n",
    "print('Found {0:,.0f} gzip files...'.format(len(gzipfiles)))\n",
    "\n",
    "for i in range(0, len(gzipfiles)):\n",
    "    if ((np.mod(i, 100) == 0) or (i == len(gzipfiles) - 1)):\n",
    "        print('\\tUn-gzipping file {0:.0f} of {1:.0f}...'.format(i, len(gzipfiles)-1))\n",
    "    csvfilename = gzipfiles[i][:-3]\n",
    "    with gzip.open(gzipfiles[i], 'rb') as f:\n",
    "        file_content = f.read()\n",
    "    with open(csvfilename, 'wb') as f:\n",
    "        f.write(file_content)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Files unzipped in {0:,.0f} minutes {1:,.0f} seconds...'.format(np.floor((e-s)/60), (e-s) % 60))\n",
    "\n",
    "s = time.time()\n",
    "print('Deleting zipfiles...')\n",
    "#os.listdir(jobs_dir)\n",
    "gzfiles = [jobs_dir+x for x in os.listdir(jobs_dir) if x[-3:] == '.gz']\n",
    "for y in gzfiles:\n",
    "    os.remove(y)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Deleted all .gz files in {0:,.0f} seconds...'.format(e-s))\n",
    "#print('Done in {0:,.0f} seconds!'.format(g))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining multiple files into a single CSV for wy...\n",
      "\tCombining file 0 of 859...\n",
      "\tCombining file 25 of 859...\n",
      "\tCombining file 50 of 859...\n",
      "\tCombining file 75 of 859...\n",
      "\tCombining file 100 of 859...\n",
      "\tCombining file 125 of 859...\n",
      "\tCombining file 150 of 859...\n",
      "\tCombining file 175 of 859...\n",
      "\tCombining file 200 of 859...\n",
      "\tCombining file 225 of 859...\n",
      "\tCombining file 250 of 859...\n",
      "\tCombining file 275 of 859...\n",
      "\tCombining file 300 of 859...\n",
      "\tCombining file 325 of 859...\n",
      "\tCombining file 350 of 859...\n",
      "\tCombining file 375 of 859...\n",
      "\tCombining file 400 of 859...\n",
      "\tCombining file 425 of 859...\n",
      "\tCombining file 450 of 859...\n",
      "\tCombining file 475 of 859...\n",
      "\tCombining file 500 of 859...\n",
      "\tCombining file 525 of 859...\n",
      "\tCombining file 550 of 859...\n",
      "\tCombining file 575 of 859...\n",
      "\tCombining file 600 of 859...\n",
      "\tCombining file 625 of 859...\n",
      "\tCombining file 650 of 859...\n",
      "\tCombining file 675 of 859...\n",
      "\tCombining file 700 of 859...\n",
      "\tCombining file 725 of 859...\n",
      "\tCombining file 750 of 859...\n",
      "\tCombining file 775 of 859...\n",
      "\tCombining file 800 of 859...\n",
      "\tCombining file 825 of 859...\n",
      "\tCombining file 850 of 859...\n",
      "\tCombining file 859 of 859...\n",
      "writing outfile...\n",
      "Done: wrote 3,899,680 rows to jobs_data_wy.csv in 28 minutes 17 seconds!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('Combining multiple files into a single CSV for {0:}...'.format(this_state))\n",
    "jobs_df = pandas.DataFrame()\n",
    "infiles = [jobs_dir+x for x in os.listdir(jobs_dir) if ('{0:}_wac'.format(this_state) in x) and (x[-4:] == '.csv')]\n",
    "outfiles = [jobs_dir+x for x in os.listdir(jobs_dir) if ('{0:}'.format(this_state) in x) and ('jobs_data_' in x)]\n",
    "\n",
    "noutputfiles = len(outfiles)\n",
    "#print(noutputfiles)\n",
    "\n",
    "if (this_state in ['ca', 'fl', 'ga', 'il', 'ny', 'tx', 'va']):   # ['ca','fl', 'il', 'ny', 'tx', 'va']\n",
    "    if (noutputfiles == 0):\n",
    "        startfile = 0\n",
    "        last_to_read = int(np.floor(len(infiles)/4))\n",
    "        indexer = 0\n",
    "    elif (noutputfiles == 1):\n",
    "        startfile = int(np.floor(len(infiles)/4))\n",
    "        last_to_read = int(np.floor(len(infiles)/2))\n",
    "        indexer = 1\n",
    "    elif (noutputfiles == 2):\n",
    "        startfile = int(np.floor(len(infiles)/2))\n",
    "        last_to_read = int(3*np.floor(len(infiles)/4))\n",
    "        indexer = 2\n",
    "    elif (noutputfiles == 3):\n",
    "        startfile = int(3*np.floor(len(infiles)/4))\n",
    "        last_to_read =len(infiles)\n",
    "        indexer = 3\n",
    "else:\n",
    "    startfile = 0\n",
    "    last_to_read = len(infiles)\n",
    "\n",
    "for i in range(startfile, last_to_read):\n",
    "    if ((np.mod(i, 25) == 0) or (i == len(infiles) - 1)):\n",
    "        print('\\tCombining file {0:,.0f} of {1:,.0f}...'.format(i, last_to_read-1))\n",
    "    thisyear = int(infiles[i][-8:-4])\n",
    "    #print(thisyear)\n",
    "    xdf = pandas.read_csv(infiles[i], low_memory=False)\n",
    "    xdf = xdf.assign(year = thisyear)     \n",
    "    jobs_df = jobs_df.append(xdf)\n",
    "jobs_df = jobs_df.reset_index(drop=True)\n",
    "jobs_df.index.name = 'rownumber'\n",
    "\n",
    "print('writing outfile...')\n",
    "\n",
    "if (this_state in ['ca', 'fl', 'ga', 'il', 'ny', 'tx', 'va']): \n",
    "    jobs_df.to_csv(jobs_dir+'jobs_data_{0:}_{1:.0f}.csv'.format(this_state, indexer), encoding='utf-8')\n",
    "else:\n",
    "    jobs_df.to_csv(jobs_dir+'jobs_data_{0:}.csv'.format(this_state), encoding='utf-8')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "if (this_state in ['ca', 'fl', 'ga', 'il', 'ny', 'tx', 'va']):  \n",
    "    print('Wrote {0:,.0f} rows to jobs_data_{1:}_{2:.0f}.csv in {3:,.0f} minutes {4:,.0f} seconds!\\n'.format(len(jobs_df), this_state, indexer, np.floor((e-s)/60), (e-s) % 60))\n",
    "else:\n",
    "    print('Done: wrote {0:,.0f} rows to jobs_data_{1:}.csv in {2:,.0f} minutes {3:,.0f} seconds!\\n'.format(len(jobs_df), this_state, np.floor((g)/60), (g) % 60))\n",
    "\n",
    "# FL 2: Wrote 15,389,748 rows to jobs_data_fl_1.csv in 24 minutes 11 seconds!\n",
    "# FL 3: Wrote 11,163,047 rows to jobs_data_fl_3.csv in 21 minutes 29 seconds!\n",
    "\n",
    "# GA 0: Wrote 9,466,819 rows to jobs_data_ga_0.csv in 14 minutes 9 seconds!\n",
    "# GA 1: Wrote 7,337,549 rows to jobs_data_ga_1.csv in 10 minutes 28 seconds!\n",
    "# GA 2: Wrote 7,115,544 rows to jobs_data_ga_2.csv in 10 minutes 59 seconds!\n",
    "# GA 3: Wrote 5,311,130 rows to jobs_data_ga_3.csv in 9 minutes 52 seconds!\n",
    "# ID: wrote 8,393,228 rows to jobs_data_id.csv in 61 minutes 56 seconds!\n",
    "# IL 0: Wrote 14,595,212 rows to jobs_data_il_0.csv in 21 minutes 52 seconds!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting component files that we combined...\n",
      "Found 72 state jobs files!\n",
      "Will delete 860 files...\n",
      "Deleting...\n",
      "Deleted files in 0 minutes 4 seconds!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Deleting component files that we combined...')\n",
    "s = time.time()\n",
    "jobs_files_list = sorted([x[-6:-4] for x in os.listdir(jobs_dir) if 'jobs_' in x])\n",
    "print('Found {0:.0f} state jobs files!'.format(len(jobs_files_list)))\n",
    "#pprint(jobs_files_list)\n",
    "files_to_delete = sorted([jobs_dir+y for y in os.listdir(jobs_dir) if ('.csv' in y) and ('jobs_' not in y)])\n",
    "print('Will delete {0:,.0f} files...'.format(len(files_to_delete)))\n",
    "print('Deleting...')\n",
    "for z in files_to_delete:\n",
    "    os.remove(z)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Deleted files in {0:,.0f} minutes {1:,.0f} seconds!\\n'.format(np.floor((e-s)/60), (e-s) % 60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2002    210104\n",
      "2003    218606\n",
      "2004    227410\n",
      "2005    234536\n",
      "2006    239228\n",
      "2007    244538\n",
      "2008    247924\n",
      "2009    252242\n",
      "2010    248086\n",
      "2011    200920\n",
      "2012    224184\n",
      "2013    226058\n",
      "2014    225258\n",
      "2015    227526\n",
      "2016    226116\n",
      "2017    222886\n",
      "2018    224058\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rownumber</th>\n",
       "      <th>1303379</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_geocode</th>\n",
       "      <td>560079676002823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C000</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA02</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE01</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE02</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE03</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS06</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS08</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS09</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS16</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS18</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNS20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR01</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT01</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD01</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD02</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD03</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS01</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS02</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFA01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFA02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFA03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFA04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFA05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdate</th>\n",
       "      <td>20190825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rownumber           1303379\n",
       "w_geocode   560079676002823\n",
       "C000                     24\n",
       "CA01                      0\n",
       "CA02                     24\n",
       "CA03                      0\n",
       "CE01                     12\n",
       "CE02                      6\n",
       "CE03                      6\n",
       "CNS01                     0\n",
       "CNS02                     0\n",
       "CNS03                     0\n",
       "CNS04                     0\n",
       "CNS05                     0\n",
       "CNS06                     0\n",
       "CNS07                     0\n",
       "CNS08                     2\n",
       "CNS09                     0\n",
       "CNS10                     0\n",
       "CNS11                     0\n",
       "CNS12                     0\n",
       "CNS13                     0\n",
       "CNS14                     0\n",
       "CNS15                     0\n",
       "CNS16                     8\n",
       "CNS17                     0\n",
       "CNS18                    14\n",
       "CNS19                     0\n",
       "CNS20                     0\n",
       "CR01                     24\n",
       "CR02                      0\n",
       "CR03                      0\n",
       "CR04                      0\n",
       "CR05                      0\n",
       "CR07                      0\n",
       "CT01                     24\n",
       "CT02                      0\n",
       "CD01                      2\n",
       "CD02                     11\n",
       "CD03                      7\n",
       "CD04                      4\n",
       "CS01                     12\n",
       "CS02                     12\n",
       "CFA01                     0\n",
       "CFA02                     0\n",
       "CFA03                     0\n",
       "CFA04                     0\n",
       "CFA05                     0\n",
       "CFS01                     0\n",
       "CFS02                     0\n",
       "CFS03                     0\n",
       "CFS04                     0\n",
       "CFS05                     0\n",
       "createdate         20190825\n",
       "year                   2014"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this_state = 'il'\n",
    "# i = 0\n",
    "df = pandas.read_csv(jobs_dir+'jobs_data_{0:}.csv'.format(this_state))#, low_memory=False, index_col='rownumber', keep_default_na=False)\n",
    "#df = pandas.read_csv(jobs_dir+'jobs_data_{0:}_{1:.0f}.csv'.format(this_state, i))#, low_memory=False, index_col='rownumber', keep_default_na=False)\n",
    "\n",
    "df = df.set_index('rownumber')\n",
    "#\n",
    "\n",
    "print(df.groupby('year').size().sort_index())\n",
    "\n",
    "df.sample(1).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Baltimore data and write it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = time.time()\n",
    "df = pandas.read_csv(jobs_dir+'jobs_data_{0:}.csv'.format(this_state), encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "#df = pandas.read_csv(jobs_dir+'jobs_data_{0:}.csv'.format(this_state), encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "#baltimore_df = df[df['w_geocode'].apply(lambda x: str(x)[0:5] == '24510')]\n",
    "#baltimore_df.to_csv(baltimore_dir+'wac_jobs_df.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:,.0f} rows in {1:,.0f} seconds!'.format(len(df), e-s))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "s = time.time()\n",
    "jobs_meta_df = pandas.read_csv(data_dir+'lodes_wac_codebook.csv', encoding='utf-8', low_memory=False, index_col='varnum')\n",
    "jobs_meta_df.to_csv(baltimore_dir+'wac_jobs_metadata.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Wrote metadata for {0:,.0f} variables in {1:,.0f} seconds!'.format(len(jobs_meta_df), e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
