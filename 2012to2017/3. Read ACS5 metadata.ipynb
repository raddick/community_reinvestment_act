{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install xlrd\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import time\n",
    "import pprint\n",
    "import geopandas\n",
    "import os\n",
    "import re\n",
    "#from SciServer import CasJobs\n",
    "#from pprint import pprint\n",
    "\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metadata for 2019...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 130...\n",
      "\treading metadata for sequence 140...\n",
      "\treading metadata for sequence 141...\n",
      "   writing outfile...\n",
      "Processing metadata for 2018...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 130...\n",
      "\treading metadata for sequence 140...\n",
      "\treading metadata for sequence 142...\n",
      "   writing outfile...\n",
      "Processing metadata for 2017...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 130...\n",
      "\treading metadata for sequence 133...\n",
      "   writing outfile...\n",
      "Processing metadata for 2016...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 122...\n",
      "   writing outfile...\n",
      "Processing metadata for 2015...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 122...\n",
      "   writing outfile...\n",
      "Processing metadata for 2014...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 121...\n",
      "   writing outfile...\n",
      "Processing metadata for 2013...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "\treading metadata for sequence 122...\n",
      "   writing outfile...\n",
      "Processing metadata for 2012...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 120...\n",
      "   writing outfile...\n",
      "Processing metadata for 2011...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 113...\n",
      "   writing outfile...\n",
      "Processing metadata for 2010...\n",
      "\treading metadata for sequence 10...\n",
      "\treading metadata for sequence 20...\n",
      "\treading metadata for sequence 30...\n",
      "\treading metadata for sequence 40...\n",
      "\treading metadata for sequence 50...\n",
      "\treading metadata for sequence 60...\n",
      "\treading metadata for sequence 70...\n",
      "\treading metadata for sequence 80...\n",
      "\treading metadata for sequence 90...\n",
      "\treading metadata for sequence 100...\n",
      "\treading metadata for sequence 110...\n",
      "\treading metadata for sequence 118...\n",
      "   writing outfile...\n",
      "Done in 104 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "debug = 1\n",
    "\n",
    "for thisyear in range(2019,2009,-1):\n",
    "    print('Processing metadata for {0:.0f}...'.format(thisyear))\n",
    "    basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "    yeardir = basedir + '{0:.0f}/'.format(thisyear)\n",
    "    rawdatadir = yeardir + 'rawdata/'\n",
    "\n",
    "    if (thisyear >= 2018):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "    elif (thisyear == 2017):\n",
    "        metadir = yeardir + 'metadata/xls_temp/'\n",
    "    elif (thisyear == 2016):\n",
    "        metadir = yeardir + 'metadata/templates/'\n",
    "    elif (thisyear == 2015):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "    elif (thisyear == 2014):\n",
    "        metadir = yeardir + 'metadata/seq/'\n",
    "    elif (thisyear == 2013):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "    elif (thisyear == 2012):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "    elif (thisyear == 2011):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "    elif (thisyear == 2010):\n",
    "        metadir = yeardir + 'metadata/'\n",
    "\n",
    "    vardir = yeardir + 'variables/'\n",
    "\n",
    "    for thisdir in [vardir]:#[datadir, errordir, vardir, geodir]:\n",
    "        #print(thisdir)\n",
    "        if not(os.path.exists(thisdir)):\n",
    "            os.makedirs(thisdir)\n",
    "\n",
    "    sequences = []\n",
    "\n",
    "    if (thisyear >= 2017):\n",
    "        sequences = ['seq'+str(y)+'.xlsx' for y in sorted([int(x[3:x.find('.')]) for x in os.listdir(metadir) if 'seq' in x])]\n",
    "    else:\n",
    "        sequences = ['Seq'+str(y)+'.xls' for y in sorted([int(x[3:x.find('.')]) for x in os.listdir(metadir) if 'Seq' in x])]\n",
    "\n",
    "    metadata_df = pandas.DataFrame()\n",
    "\n",
    "#    for i in range(1,5):\n",
    "    for i in range(1,len(sequences)+1):\n",
    "        if (debug >=1):\n",
    "            if ((np.mod(i, 10) == 0) | (i == len(sequences))):\n",
    "                print('\\treading metadata for sequence {0:.0f}...'.format(i))\n",
    "        if (thisyear >= 2017):\n",
    "            this_seq_metadata_filename = metadir + 'seq{0:.0f}.xlsx'.format(i)\n",
    "        elif (thisyear == 2011):\n",
    "            this_seq_metadata_filename = metadir + 'Seq{0:04d}.xls'.format(i)\n",
    "        else:\n",
    "            this_seq_metadata_filename = metadir + 'Seq{0:.0f}.xls'.format(i)\n",
    "\n",
    "        this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None)#, encoding='utf-8')    \n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "        \n",
    "        this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "        this_seq_metadata_df.columns = ['variable', 'description']    \n",
    "        this_seq_metadata_df = this_seq_metadata_df.assign(sequence_number = i)\n",
    "        if (i > 1):\n",
    "            this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO'], axis=0)\n",
    "        this_seq_metadata_df['sequence_number'] == i\n",
    "        if (debug >= 2):\n",
    "            print('\\t\\tMerging datasets...')\n",
    "        metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "\n",
    "    metadata_df = metadata_df.reset_index(drop=True)\n",
    "    metadata_df.index.name = 'rownumber'\n",
    "\n",
    "    print('   writing outfile...')\n",
    "    metadata_df.to_csv(vardir+'variables_acs_5yr_all.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "print('Done in {0:,.0f} seconds!'.format(e-s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which variables do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "# yeardir = basedir + '{0:.0f}/'.format(2018)\n",
    "# vardir = yeardir + 'variables/'\n",
    "\n",
    "# z = pandas.read_csv(vardir+'variables_acs_5yr_all.csv', encoding='utf-8', index_col='rownumber')#.loc[0:80]['description'].tolist()\n",
    "# # z[\n",
    "# #     z['variable'].apply(lambda x: 'B01001' in x)\n",
    "# #     #&  (z['description'].apply(lambda x: 'education' in str(x).lower()))\n",
    "# #     #& (z['description'].apply(lambda x: '25' in str(x).lower()))\n",
    "# #     #& (z['sequence_number'] \n",
    "# # ]#[46:]\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "\n",
    "# debug = 1\n",
    "\n",
    "# basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "# yeardir = basedir + '{0:.0f}/'.format(2018)\n",
    "# rawdatadir = yeardir + 'rawdata/'\n",
    "\n",
    "\n",
    "# metadata_df[\n",
    "#     (metadata_df['description'].apply(lambda x: 'education' in str(x).lower()))\n",
    "#     & (metadata_df['sequence_number'] < 43)\n",
    "# ]\n",
    "# #[0:20]\n",
    "# #metadata_df[metadata_df['variable'] == 'B01001_001']\n",
    "\n",
    "\n",
    "\n",
    "# # # SEQUENCE 4: RACE\n",
    "# # #['B02001_001', 'B02001_002', 'B02001_003', 'B02009_001'] \n",
    "# # # SEQUENCE 23: TRANSPORTATION\n",
    "# # # ['B08013_001']\n",
    "# # # SEQUENCE 36: HOUSEHOLDS\n",
    "# # #['B11001_001']\n",
    "# # # SEQUENCE 43: EDUCATION\n",
    "# # #['B15002_002' to 'B15002_035'; 'C15002A_002' to 'C15002A_011'; 'C15002B_002' to 'C15002B_011']\n",
    "# # # SEQUENCE 48: POVERTY\n",
    "# # # ['B17001_001', 'B17001_002', 'B17001A_001', 'B17001A_002', 'B17001B_001', 'B17001B_002']\n",
    "# # # SEQUENCE 59: INCOME\n",
    "# # #['B19013_001', 'B19013A_001', 'B19013B_001']\n",
    "# # # SEQUENCE 63: INCOME\n",
    "# # #['B19062_001']\n",
    "# # # SEQUENCE 112: HOUSING\n",
    "# # #['B25002_001', 'B25002_002', 'B25002_003', 'B25003_001', 'B25003_002', 'B25003_003', 'B25003A_001', 'B25003A_002', 'B25003A_003', 'B25003B_001', 'B25003B_002', 'B25003B_003']\n",
    "# # # SEQUENCE 115: HOUSING\n",
    "# # #['B25077_001']\n",
    "\n",
    "# # sequence_list = [4, 23, 43, 48, 59, 63, 112, 115]\n",
    "# # for_cra_analysis_mac_varlist = ['B02001_001', 'B02001_002', 'B02001_003', 'B02009_001']\n",
    "# # for_cra_analysis_mac_varlist += ['B08013_001']\n",
    "# # for i in range(2, 36):\n",
    "# #     for_cra_analysis_mac_varlist.append('B15002_{:03d}'.format(i))\n",
    "# # for i in range(2,12):\n",
    "# #     for_cra_analysis_mac_varlist.append('C15002A_{:03d}'.format(i))\n",
    "# # for i in range(2,12):\n",
    "# #     for_cra_analysis_mac_varlist.append('C15002B_{:03d}'.format(i))\n",
    "# # for_cra_analysis_mac_varlist += ['B17001_001', 'B17001_002', 'B17001A_001', 'B17001A_002', 'B17001B_001', 'B17001B_002']\n",
    "# # for_cra_analysis_mac_varlist += ['B19013_001', 'B19013A_001', 'B19013B_001']\n",
    "# # for_cra_analysis_mac_varlist += ['B19062_001']\n",
    "# # for_cra_analysis_mac_varlist += ['B25002_001', 'B25002_002', 'B25002_003', 'B25003_001', 'B25003_002', 'B25003_003', 'B25003A_001', 'B25003A_002', 'B25003A_003', 'B25003B_001', 'B25003B_002', 'B25003B_003']\n",
    "# # for_cra_analysis_mac_varlist += ['B25077_001']\n",
    "# # # metadata_df[\n",
    "# # #     (metadata_df['sequence_number'] == 115) & \n",
    "# # #     (metadata_df['description'].apply(lambda x: 'value' in x.lower())) & \n",
    "# # #     (metadata_df['description'].apply(lambda x: 'median' in x.lower()))\n",
    "# # # ]#[0:20]\n",
    "# # #for_cra_analysis_mac_varlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_variables4(mdf, tofindlist):\n",
    "#     # NEED TO REWRITE TO USE REGEX INSTEAD, because now only \"Male\" returns men; \"male\" returns women b/c feMALE\n",
    "# #    varlist = []\n",
    "#     if (len(tofindlist) == 0):\n",
    "#         print('CAUTION: No search phrases specified, returning every variable!')\n",
    "#     if (len(tofindlist) > 4):\n",
    "#         print('ERROR: list contains more than four search phrases, searching for only the first three')\n",
    "#     try:\n",
    "#         string1 = tofindlist[0]\n",
    "#     except IndexError:\n",
    "#         string1 = ''\n",
    "#     try:\n",
    "#         string2 = tofindlist[1]\n",
    "#     except IndexError:\n",
    "#         string2 = ''\n",
    "#     try:\n",
    "#         string3 = tofindlist[2]\n",
    "#     except IndexError:\n",
    "#         string3 = ''\n",
    "#     try:\n",
    "#         string4 = tofindlist[3]\n",
    "#     except IndexError:\n",
    "#         string4 = ''\n",
    "\n",
    "# #    for x in tofindlist:\n",
    "# #        print(x)\n",
    "        \n",
    "#     print('')\n",
    "    \n",
    "#     varlist = mdf['variable'][mdf['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x) & (string4 in x))].values.tolist()\n",
    "    \n",
    "#     return varlist\n",
    "# print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# phrases = []\n",
    "# #phrases.append('Median household income')\n",
    "# phrases.append('overty')\n",
    "# #phrases.append('chool')\n",
    "# #phrases.append('egree')\n",
    "\n",
    "# metadata_df['variable'] = metadata_df['variable'].astype('str')\n",
    "# metadata_df['description'] = metadata_df['description'].astype('str')\n",
    "\n",
    "# thelist = find_variables4(metadata_df, phrases)\n",
    "# print('Variables found: ',thelist)\n",
    "\n",
    "# #metadata_df.dtypes\n",
    "# metadata_df.loc[thelist]\n",
    "\n",
    "# #Total population: sequence 2, variable B01001_001\n",
    "# #Aggregate travel time to work: sequence 23, variable B08013_001\n",
    "# #White alone: sequence 4, variable B02001_003\n",
    "# #Black alone: sequence 4, variable B02001_004\n",
    "# #Two or more races: sequence 4, variable B02001_008\n",
    "# #Hispanic or Latino origin: sequence 5, variable B03001_003\n",
    "# #Sex by age by educational attainment: sequence 43, variable B15001_001\n",
    "# #Poverty status in the past 12 months by sex by age: sequence 48, variable B17001_001\n",
    "# #Median household income: sequence 59, variable B19013_001\n",
    "# #Aggregate wage or salary income in past 12 months: sequence 63, variable B19062_001\n",
    "\n",
    "# #SO, the sequences we need are: 2, 4, 5, 23, 43, 48, 59, 63\n",
    "# #The variables we need are: B01001_001, B08013_001, B02001_003, B02001_004, B02001_008, B03001_003, B15001_001, B17001_001, B19013_001, B19062_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata_df[metadata_df['sequence_number'] == 48]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
