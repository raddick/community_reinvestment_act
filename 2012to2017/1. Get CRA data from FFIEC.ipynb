{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages, define directories to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "Now in directory: /home/idies/workspace/Temporary/raddick/cra_scratch\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import urllib\n",
    "import pandas\n",
    "import zipfile\n",
    "import time\n",
    "#import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch/'\n",
    "code_lookup_dir = thisdir + 'code_guide_lookups/'\n",
    "#baltimore_dir = thisdir + 'baltimore/'\n",
    "\n",
    "g = 0  # keep track of grand total of processing time\n",
    "\n",
    "os.chdir(data_dir)\n",
    "print('Now in directory: {0:}'.format(os.getcwd()))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get flatfiles for disclosure reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download zipfiles of disclosure reports from ffiec.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading disclousre flatfiles from ffiec.gov...\n",
      "Starting to download 96exp_discl.zip...\n",
      "Starting to download 97exp_discl.zip...\n",
      "Starting to download 98exp_discl.zip...\n",
      "Starting to download 99exp_discl.zip...\n",
      "Starting to download 00exp_discl.zip...\n",
      "Starting to download 01exp_discl.zip...\n",
      "Starting to download 02exp_discl.zip...\n",
      "Starting to download 03exp_discl.zip...\n",
      "Starting to download 04exp_discl.zip...\n",
      "Starting to download 05exp_discl.zip...\n",
      "Starting to download 06exp_discl.zip...\n",
      "Starting to download 07exp_discl.zip...\n",
      "Starting to download 08exp_discl.zip...\n",
      "Starting to download 09exp_discl.zip...\n",
      "Starting to download 10exp_discl.zip...\n",
      "Starting to download 11exp_discl.zip...\n",
      "Starting to download 12exp_discl.zip...\n",
      "Starting to download 13exp_discl.zip...\n",
      "Starting to download 14exp_discl.zip...\n",
      "Starting to download 15exp_discl.zip...\n",
      "Starting to download 16exp_discl.zip...\n",
      "Starting to download 17exp_discl.zip...\n",
      "Starting to download 18exp_discl.zip...\n",
      "Starting to download 19exp_discl.zip...\n",
      "Got 24 files in 59 seconds!\n"
     ]
    }
   ],
   "source": [
    "# Get oroginal datafiles from ffiec.gov\n",
    "s = time.time()\n",
    "\n",
    "print('Downloading disclousre flatfiles from ffiec.gov...')\n",
    "thatpath = 'https://www.ffiec.gov/cra/xls/'\n",
    "theyears = list(range(96,100))\n",
    "theyears += list(range(0,20))\n",
    "filenames = []\n",
    "\n",
    "for i in theyears:\n",
    "    filenames.append('{:02d}exp_discl.zip'.format(i))\n",
    "#filenames\n",
    "\n",
    "for thisfile in filenames:\n",
    "    print('Starting to download {:}...'.format(thisfile))\n",
    "    with urllib.request.urlopen(thatpath+thisfile) as response:    \n",
    "        it = response.read()\n",
    "        with open(thisfile, 'wb') as f:\n",
    "            f.write(it)\n",
    "            \n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Got {0:,.0f} files in {1:,.0f} seconds!'.format(len(filenames), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip disclosure flatfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 96exp_discl.zip...\n",
      "Extracting 97exp_discl.zip...\n",
      "Extracting 98exp_discl.zip...\n",
      "Extracting 99exp_discl.zip...\n",
      "Extracting 00exp_discl.zip...\n",
      "Extracting 01exp_discl.zip...\n",
      "Extracting 02exp_discl.zip...\n",
      "Extracting 03exp_discl.zip...\n",
      "Extracting 04exp_discl.zip...\n",
      "Extracting 05exp_discl.zip...\n",
      "Extracting 06exp_discl.zip...\n",
      "Extracting 07exp_discl.zip...\n",
      "Extracting 08exp_discl.zip...\n",
      "Extracting 09exp_discl.zip...\n",
      "Extracting 10exp_discl.zip...\n",
      "Extracting 11exp_discl.zip...\n",
      "Extracting 12exp_discl.zip...\n",
      "Extracting 13exp_discl.zip...\n",
      "Extracting 14exp_discl.zip...\n",
      "Extracting 15exp_discl.zip...\n",
      "Extracting 16exp_discl.zip...\n",
      "Extracting 17exp_discl.zip...\n",
      "Extracting 18exp_discl.zip...\n",
      "Extracting 19exp_discl.zip...\n",
      "Deleting zipfiles...\n",
      "Extracted 24 zipfiles in 131 seconds!\n"
     ]
    }
   ],
   "source": [
    "#theyears = list(range(96,100))\n",
    "#theyears += list(range(0,18))\n",
    "\n",
    "s = time.time()\n",
    "for i in theyears:\n",
    "    thisfile = '{0:02d}exp_discl.zip'.format(i)\n",
    "    if (thisfile in os.listdir()):\n",
    "        print('Extracting {0:}...'.format(thisfile))\n",
    "    else:\n",
    "        print(thisfile+' not found!!!')\n",
    "    thezipfile = zipfile.ZipFile(thisfile)\n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    if ((i >= 8) & (i <= 15)):\n",
    "        os.rename('exp_discl.dat', '{0:02d}exp_discl.dat'.format(i))\n",
    "\n",
    "print('Deleting zipfiles...')\n",
    "thezipfiles = [x for x in os.listdir() if '.zip' in x]\n",
    "for thiszip in thezipfiles:\n",
    "    os.remove(thiszip)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Extracted {0:,.0f} zipfiles in {1:,.0f} seconds!'.format(len(thezipfiles), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the single rawdata string into separate columns of strings\n",
    "\n",
    "Using the guides on their website (https://www.ffiec.gov/cra/pdf/17FlatDiscSpecs.pdf)\n",
    "\n",
    "Pre-2004 guides: https://www.ffiec.gov/cra/pdf/2003specs.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016-2019 load strings from multiple files into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file cra2019_Discl_D11.dat...\n",
      "Reading file cra2019_Discl_D12.dat...\n",
      "Reading file cra2019_Discl_D21.dat...\n",
      "Reading file cra2019_Discl_D22.dat...\n",
      "Reading file cra2019_Discl_D3.dat...\n",
      "Reading file cra2019_Discl_D4.dat...\n",
      "Reading file cra2019_Discl_D5.dat...\n",
      "Reading file cra2019_Discl_D6.dat...\n",
      "Reading file cra2018_Discl_D11.dat...\n",
      "Reading file cra2018_Discl_D12.dat...\n",
      "Reading file cra2018_Discl_D21.dat...\n",
      "Reading file cra2018_Discl_D22.dat...\n",
      "Reading file cra2018_Discl_D3.dat...\n",
      "Reading file cra2018_Discl_D4.dat...\n",
      "Reading file cra2018_Discl_D5.dat...\n",
      "Reading file cra2018_Discl_D6.dat...\n",
      "Reading file cra2017_Discl_D11.dat...\n",
      "Reading file cra2017_Discl_D12.dat...\n",
      "Reading file cra2017_Discl_D21.dat...\n",
      "Reading file cra2017_Discl_D22.dat...\n",
      "Reading file cra2017_Discl_D3.dat...\n",
      "Reading file cra2017_Discl_D4.dat...\n",
      "Reading file cra2017_Discl_D5.dat...\n",
      "Reading file cra2017_Discl_D6.dat...\n",
      "Reading file cra2016_Discl_D11.dat...\n",
      "Reading file cra2016_Discl_D12.dat...\n",
      "Reading file cra2016_Discl_D21.dat...\n",
      "Reading file cra2016_Discl_D22.dat...\n",
      "Reading file cra2016_Discl_D3.dat...\n",
      "Reading file cra2016_Discl_D4.dat...\n",
      "Reading file cra2016_Discl_D5.dat...\n",
      "Reading file cra2016_Discl_D6.dat...\n",
      "\n",
      "\n",
      "Read 2016-2019 data: 14,936,200 rows in 63 seconds.\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "rdf = pandas.DataFrame()\n",
    "\n",
    "minyear = 2016\n",
    "maxyear = 2019\n",
    "for y in range(maxyear, minyear-1, -1):\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,3):\n",
    "            thisfile = 'cra{0:04d}_Discl_D{1:.0f}{2:.0f}.dat'.format(y,i,j)\n",
    "            print('Reading file {:}...'.format(thisfile))\n",
    "            rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "    for k in range(3,7):\n",
    "        thisfile = 'cra{0:04d}_Discl_D{1:.0f}.dat'.format(y,k)\n",
    "        print('Reading file {:}...'.format(thisfile))\n",
    "        rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('\\n')\n",
    "print('Read {0:04d}-{1:04d} data: {2:,.0f} rows in {3:,.0f} seconds.'.format(minyear, maxyear, len(rdf), e-s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read 2004-2015 data (the long strings), append to the same DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filenames!\n",
      "Reading file 15exp_discl.dat...\n",
      "Reading file 14exp_discl.dat...\n",
      "Reading file 13exp_discl.dat...\n",
      "Reading file 12exp_discl.dat...\n",
      "Reading file 11exp_discl.dat...\n",
      "Reading file 10exp_discl.dat...\n",
      "Reading file 09exp_discl.dat...\n",
      "Reading file 08exp_discl.dat...\n",
      "Reading file 07exp_discl.dat...\n",
      "Reading file 06exp_discl_new.dat...\n",
      "Reading file 05exp_discl_new.dat...\n",
      "Reading file 04exp_discl_new.dat...\n",
      "Read 2004-2015 data: 50,361,895 rows in 137 seconds.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "minyear = 2004\n",
    "maxyear = 2015\n",
    "\n",
    "filelist = []\n",
    "for i in range(maxyear, minyear-1, -1):\n",
    "    thisfile = '{:}exp_discl'.format(str(i)[2:])\n",
    "    if i in [2004,2005,2006]:\n",
    "        thisfile = thisfile + '_new.dat'\n",
    "    else:\n",
    "        thisfile = thisfile + '.dat'\n",
    "    filelist.append(thisfile)\n",
    "print('Found filenames!')\n",
    "#print(filelist)\n",
    "for thisfile in filelist:\n",
    "    print('Reading file {:}...'.format(thisfile))\n",
    "    rdf = rdf.append(pandas.read_csv(thisfile, header=None))\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:4d}-{1:04d} data: {2:,.0f} rows in {3:,.0f} seconds.'.format(minyear, maxyear, len(rdf), e-s))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse strings into DataFrame for 2004-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse tableID so we can tell the difference between tables\n",
    "\n",
    "Also get things that appear in the same place in every table: respondentID, agency_code, agency_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding...\n",
      "tableID...\n",
      "respondentID...\n",
      "agency_code...\n",
      "activity_year...\n",
      "Parsed 50,361,895 rows in 326 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "rdf.columns = ['thestring']\n",
    "rdf.index.name = 'rownumber'\n",
    "print('finding...')\n",
    "print('tableID...')\n",
    "rdf = rdf.assign(tableID = rdf['thestring'].apply(lambda x: x[0:5].strip()))\n",
    "print('respondentID...')\n",
    "rdf = rdf.assign(respondentID = pandas.to_numeric(rdf['thestring'].apply(lambda x: x[5:15]), errors='coerce'))\n",
    "print('agency_code...')\n",
    "rdf = rdf.assign(agency_code = pandas.to_numeric(rdf['thestring'].apply(lambda x: x[15]), errors='coerce'))\n",
    "print('activity_year...')\n",
    "rdf = rdf.assign(activity_year = pandas.to_numeric(rdf['thestring'].apply(lambda x: x[16:20]), errors='coerce'))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Parsed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(rdf), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tableID to identify which table is which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying...\n",
      "loans...\n",
      "assessment areas...\n",
      "community development loans...\n",
      "census tracts...\n",
      "Done in 73 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('identifying...')\n",
    "print('loans...')\n",
    "loans_df = rdf[rdf['tableID'].apply(lambda x: x in ['D1-1', 'D1-2', 'D2-1', 'D2-2'])]\n",
    "print('assessment areas...')\n",
    "assessment_areas_df = rdf[rdf['tableID'].apply(lambda x: x in ['D3-0', 'D4-0'])]\n",
    "print('community development loans...')\n",
    "community_development_df = rdf[rdf['tableID'] == 'D5-0']\n",
    "print('census tracts...')\n",
    "tracts_df = rdf[rdf['tableID'] == 'D6-0']\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.0f} seconds!'.format(e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse loans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially 17,439,173 rows...\n",
      "finding report_level...\n",
      "keeping only lowest level of aggregation...\n",
      "Reduced to 14,746,543 rows...\n",
      "\n",
      "Creating new columns...\n",
      "loan_type...\n",
      "action_taken_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "assessment_area_number...\n",
      "partial_county_indicator...\n",
      "split_county_indicator...\n",
      "population_classification...\n",
      "income_group_total...\n",
      "nLoans1...\n",
      "amtLoans1...\n",
      "nLoans100k...\n",
      "amtLoans100k...\n",
      "nLoans250k...\n",
      "amtLoans250k...\n",
      "nLoansToSmallest...\n",
      "amtLoansToSmallest...\n",
      "nLoansAff...\n",
      "amtLoansAff..\n",
      "\n",
      "\n",
      "Converting to numeric...\n",
      "loan_type...\n",
      "action_taken_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "assessment_area_number...\n",
      "income_group_total...\n",
      "nLoans1...\n",
      "amtLoans1...\n",
      "nLoans100k...\n",
      "amtLoans100k...\n",
      "nLoans250k...\n",
      "amtLoans250k...\n",
      "nLoansToSmallest...\n",
      "amtLoansToSmallest...\n",
      "nLoansAff...\n",
      "amtLoansAff...\n",
      "Multiplying loan amounts by 1000 for real dollars...\n",
      "Dropping columns we do not need...\n",
      "Writing out loans data...\n",
      "\n",
      "Processed 14,746,543 rows in 972 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('Initially {0:,.0f} rows...'.format(len(loans_df)))\n",
    "#s = time.time()\n",
    "print('finding report_level...')\n",
    "loans_df = loans_df.assign(report_level = loans_df['thestring'].apply(lambda x: x[42:45]))\n",
    "\n",
    "print('keeping only lowest level of aggregation...')\n",
    "loans_df = loans_df[loans_df['report_level'] == '   ']\n",
    "print('Reduced to {0:,.0f} rows...'.format(len(loans_df)))\n",
    "\n",
    "print('\\nCreating new columns...')\n",
    "print('loan_type...')\n",
    "loans_df = loans_df.assign(loan_type = loans_df['thestring'].apply(lambda x: x[20]))\n",
    "print('action_taken_type...')\n",
    "loans_df = loans_df.assign(action_taken_type = loans_df['thestring'].apply(lambda x: x[21]))\n",
    "print('state...')\n",
    "loans_df = loans_df.assign(state = loans_df['thestring'].apply(lambda x: x[22:24]))\n",
    "print('county...')\n",
    "loans_df = loans_df.assign(county = loans_df['thestring'].apply(lambda x: x[24:27]))\n",
    "print('msa...')\n",
    "loans_df = loans_df.assign(msa = loans_df['thestring'].apply(lambda x: x[27:32]))\n",
    "print('assessment_area_number...')\n",
    "loans_df = loans_df.assign(assessment_area_number = loans_df['thestring'].apply(lambda x: x[32:36]))\n",
    "print('partial_county_indicator...')\n",
    "loans_df = loans_df.assign(partial_county_indicator = loans_df['thestring'].apply(lambda x: x[36]))\n",
    "print('split_county_indicator...')\n",
    "loans_df = loans_df.assign(split_county_indicator = loans_df['thestring'].apply(lambda x: x[37]))\n",
    "print('population_classification...')\n",
    "loans_df = loans_df.assign(population_classification = loans_df['thestring'].apply(lambda x: x[38]))\n",
    "print('income_group_total...')\n",
    "loans_df = loans_df.assign(income_group_total = loans_df['thestring'].apply(lambda x: x[39:42]))\n",
    "print('nLoans1...')\n",
    "loans_df = loans_df.assign(nLoans1 = loans_df['thestring'].apply(lambda x: x[45:55]))\n",
    "print('amtLoans1...')\n",
    "loans_df = loans_df.assign(amtLoans1 = loans_df['thestring'].apply(lambda x: x[55:65]))\n",
    "print('nLoans100k...')\n",
    "loans_df = loans_df.assign(nLoans100k = loans_df['thestring'].apply(lambda x: x[65:75]))\n",
    "print('amtLoans100k...')\n",
    "loans_df = loans_df.assign(amtLoans100k = loans_df['thestring'].apply(lambda x: x[75:85]))\n",
    "print('nLoans250k...')\n",
    "loans_df = loans_df.assign(nLoans250k = loans_df['thestring'].apply(lambda x: x[85:95]))\n",
    "print('amtLoans250k...')\n",
    "loans_df = loans_df.assign(amtLoans250k = loans_df['thestring'].apply(lambda x: x[95:105]))\n",
    "print('nLoansToSmallest...')\n",
    "loans_df = loans_df.assign(nLoansToSmallest = loans_df['thestring'].apply(lambda x: x[105:115]))\n",
    "print('amtLoansToSmallest...')\n",
    "loans_df = loans_df.assign(amtLoansToSmallest = loans_df['thestring'].apply(lambda x: x[115:125]))\n",
    "print('nLoansAff...')\n",
    "loans_df = loans_df.assign(nLoansAff = loans_df['thestring'].apply(lambda x: x[125:135]))\n",
    "print('amtLoansAff..\\n')\n",
    "loans_df = loans_df.assign(amtLoansAff = loans_df['thestring'].apply(lambda x: x[135:145]))\n",
    "\n",
    "numeric_columns = ['loan_type','action_taken_type','state','county','msa']\n",
    "numeric_columns += ['assessment_area_number','income_group_total']\n",
    "numeric_columns += ['nLoans1','amtLoans1','nLoans100k','amtLoans100k']\n",
    "numeric_columns += ['nLoans250k','amtLoans250k','nLoansToSmallest','amtLoansToSmallest']\n",
    "numeric_columns += ['nLoansAff','amtLoansAff']\n",
    "\n",
    "print('\\nConverting to numeric...')\n",
    "for x in numeric_columns:\n",
    "    print('{0:}...'.format(x))\n",
    "    loans_df.loc[:, x] = pandas.to_numeric(loans_df[x], errors='coerce')\n",
    "\n",
    "print('Multiplying loan amounts by 1000 for real dollars...')\n",
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k']\n",
    "money_columns += ['amtLoansToSmallest', 'amtLoansAff']\n",
    "for x in money_columns:\n",
    "    loans_df.loc[:, x] = loans_df[x] * 1000\n",
    "\n",
    "print('Dropping columns we do not need...')\n",
    "loans_df = loans_df.drop(['thestring', 'tableID', 'report_level'], axis=1)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Writing out loans data...')\n",
    "loans_df.to_csv('loans.csv', encoding='utf-8')\n",
    "\n",
    "print('\\nProcessed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(loans_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse assessment areas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding report level...\n",
      "keeping only report_level = 10 (so we can connect to county)...\n",
      "loan_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "assessment_area_number...\n",
      "partial_county_indicator...\n",
      "split_county_indicator...\n",
      "nBizLoans...\n",
      "amtBizLoans...\n",
      "nLoansToSmallest...\n",
      "amtLoansToSmallest...\n",
      "nLoansPurchased...\n",
      "amtLoansPurchased...\n",
      "dropping columns we do not need...\n",
      "converting to numeric...\n",
      "Multiplying loan amounts by 1000 for real dollars...\n",
      "Writing out...\n",
      "Processed 361,204 rows in 19 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('finding report level...')\n",
    "assessment_areas_df = assessment_areas_df.assign(report_level = assessment_areas_df['thestring'].apply(lambda x: x[37:39]))\n",
    "\n",
    "print('keeping only report_level = 10 (so we can connect to county)...')\n",
    "assessment_areas_df = assessment_areas_df[assessment_areas_df['report_level'] == '10']\n",
    "\n",
    "print('loan_type...')\n",
    "assessment_areas_df = assessment_areas_df.assign(loan_type = assessment_areas_df['thestring'].apply(lambda x: x[20]))\n",
    "print('state...')\n",
    "assessment_areas_df = assessment_areas_df.assign(state = assessment_areas_df['thestring'].apply(lambda x: x[21:23]))\n",
    "print('county...')\n",
    "assessment_areas_df = assessment_areas_df.assign(county = assessment_areas_df['thestring'].apply(lambda x: x[23:26]))\n",
    "print('msa...')\n",
    "assessment_areas_df = assessment_areas_df.assign(msa = assessment_areas_df['thestring'].apply(lambda x: x[26:31]))\n",
    "print('assessment_area_number...')\n",
    "assessment_areas_df = assessment_areas_df.assign(assessment_area_number = assessment_areas_df['thestring'].apply(lambda x: x[31:35]))\n",
    "print('partial_county_indicator...')\n",
    "assessment_areas_df = assessment_areas_df.assign(partial_county_indicator = assessment_areas_df['thestring'].apply(lambda x: x[35]))\n",
    "print('split_county_indicator...')\n",
    "assessment_areas_df = assessment_areas_df.assign(split_county_indicator = assessment_areas_df['thestring'].apply(lambda x: x[36]))\n",
    "\n",
    "print('nBizLoans...')\n",
    "assessment_areas_df = assessment_areas_df.assign(nBizLoans = assessment_areas_df['thestring'].apply(lambda x: x[39:49]))\n",
    "print('amtBizLoans...')\n",
    "assessment_areas_df = assessment_areas_df.assign(amtBizLoans = assessment_areas_df['thestring'].apply(lambda x: x[49:59]))\n",
    "print('nLoansToSmallest...')\n",
    "assessment_areas_df = assessment_areas_df.assign(nLoansToSmallest = assessment_areas_df['thestring'].apply(lambda x: x[59:69]))\n",
    "print('amtLoansToSmallest...')\n",
    "assessment_areas_df = assessment_areas_df.assign(amtLoansToSmallest = assessment_areas_df['thestring'].apply(lambda x: x[69:79]))\n",
    "print('nLoansPurchased...')\n",
    "assessment_areas_df = assessment_areas_df.assign(nLoansPurchased = assessment_areas_df['thestring'].apply(lambda x: x[79:89]))\n",
    "print('amtLoansPurchased...')\n",
    "assessment_areas_df = assessment_areas_df.assign(amtLoansPurchased = assessment_areas_df['thestring'].apply(lambda x: x[89:99]))\n",
    "#assessment_areas_df.head(10)\n",
    "print('dropping columns we do not need...')\n",
    "assessment_areas_df = assessment_areas_df.drop(['thestring', 'tableID', 'report_level'], axis=1)\n",
    "assessment_areas_df.head(1).T\n",
    "\n",
    "print('converting to numeric...')\n",
    "numeric_columns = ['respondentID','agency_code','activity_year']\n",
    "numeric_columns += ['loan_type','state','county','msa','assessment_area_number']\n",
    "numeric_columns += ['nBizLoans','amtBizLoans','nLoansToSmallest','amtLoansToSmallest']\n",
    "numeric_columns += ['amtLoansPurchased','nLoansPurchased']\n",
    "for x in numeric_columns:\n",
    "    assessment_areas_df.loc[:, x] = pandas.to_numeric(assessment_areas_df[x], errors='coerce')\n",
    "\n",
    "print('Multiplying loan amounts by 1000 for real dollars...')\n",
    "money_columns = ['amtBizLoans', 'amtLoansToSmallest', 'amtLoansPurchased']\n",
    "for x in money_columns:\n",
    "    assessment_areas_df.loc[:, x] = assessment_areas_df[x] * 1000\n",
    "\n",
    "print('Writing out...')\n",
    "assessment_areas_df.to_csv('assessment_areas.csv', encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(assessment_areas_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse community development and third-party loans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting community development and third-party loans...\n",
      "Writing out...\n",
      "Read 48,849 rows in 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "print('Getting community development and third-party loans...')\n",
    "s = time.time()\n",
    "community_development_df = community_development_df.assign(loan_type = community_development_df['thestring'].apply(lambda x: x[20]))\n",
    "community_development_df = community_development_df.assign(nLoans = community_development_df['thestring'].apply(lambda x: x[21:31]))\n",
    "community_development_df = community_development_df.assign(amtLoans = community_development_df['thestring'].apply(lambda x: x[31:41]))\n",
    "community_development_df = community_development_df.assign(nLoansAff = community_development_df['thestring'].apply(lambda x: x[41:51]))\n",
    "community_development_df = community_development_df.assign(amtLoansAff = community_development_df['thestring'].apply(lambda x: x[51:61]))\n",
    "community_development_df = community_development_df.assign(action_taken_type = community_development_df['thestring'].apply(lambda x: x[61]))\n",
    "\n",
    "community_development_df = community_development_df.drop(['thestring', 'tableID'], axis=1)\n",
    "\n",
    "numeric_columns = ['loan_type','nLoans','amtLoans','nLoansAff','amtLoansAff']\n",
    "for x in numeric_columns:\n",
    "    community_development_df.loc[:, x] = pandas.to_numeric(community_development_df[x], errors='coerce')\n",
    "\n",
    "money_columns = ['amtLoans', 'amtLoansAff']\n",
    "for x in money_columns:\n",
    "    community_development_df.loc[:, x] = community_development_df[x] * 1000\n",
    "\n",
    "print('Writing out...')\n",
    "community_development_df.to_csv('community_development.csv', encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Read {0:,.0f} rows in {1:,.0f} seconds.'.format(len(community_development_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse census tracts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigning...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "census_tract...\n",
      "assessment_area_number...\n",
      "partial_county_indicator...\n",
      "split_county_indicator...\n",
      "population_classification...\n",
      "income_group...\n",
      "loan_indicator...\n",
      "\n",
      "dropping columns we do not need...\n",
      "\n",
      "converting to numeric...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "census_tract...\n",
      "assessment_area_number...\n",
      "income_group...\n",
      "Writing out...\n",
      "Processed 32,427,315 rows in 653 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('assigning...')\n",
    "print('state...')\n",
    "tracts_df = tracts_df.assign(state = tracts_df['thestring'].apply(lambda x: x[20:22]))\n",
    "print('county...')\n",
    "tracts_df = tracts_df.assign(county = tracts_df['thestring'].apply(lambda x: x[22:25]))\n",
    "print('msa...')\n",
    "tracts_df = tracts_df.assign(msa = tracts_df['thestring'].apply(lambda x: x[25:30]))\n",
    "print('census_tract...')\n",
    "tracts_df = tracts_df.assign(census_tract = tracts_df['thestring'].apply(lambda x: x[30:37]))\n",
    "print('assessment_area_number...')\n",
    "tracts_df = tracts_df.assign(assessment_area_number = tracts_df['thestring'].apply(lambda x: x[37:41]))\n",
    "print('partial_county_indicator...')\n",
    "tracts_df = tracts_df.assign(partial_county_indicator = tracts_df['thestring'].apply(lambda x: x[41]))\n",
    "print('split_county_indicator...')\n",
    "tracts_df = tracts_df.assign(split_county_indicator = tracts_df['thestring'].apply(lambda x: x[42]))\n",
    "print('population_classification...')\n",
    "tracts_df = tracts_df.assign(population_classification = tracts_df['thestring'].apply(lambda x: x[43]))\n",
    "print('income_group...')\n",
    "tracts_df = tracts_df.assign(income_group = tracts_df['thestring'].apply(lambda x: x[44:47]))\n",
    "print('loan_indicator...')\n",
    "tracts_df = tracts_df.assign(loan_indicator = tracts_df['thestring'].apply(lambda x: x[47]))\n",
    "\n",
    "print('\\ndropping columns we do not need...')\n",
    "tracts_df = tracts_df.drop(['thestring', 'tableID'], axis=1)\n",
    "\n",
    "print('\\nconverting to numeric...')\n",
    "numeric_columns = ['state', 'county', 'msa', 'census_tract']\n",
    "numeric_columns += ['assessment_area_number', 'income_group']\n",
    "for x in numeric_columns:\n",
    "    print('{0:}...'.format(x))\n",
    "    tracts_df.loc[:, x] = pandas.to_numeric(tracts_df[x], errors='coerce')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Writing out...')\n",
    "tracts_df.to_csv('tracts.csv', encoding='utf-8')\n",
    "\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(tracts_df), e-s))\n",
    "\n",
    "##agency_code\n",
    "#code,value\n",
    "#1,'OCC'\n",
    "#2,'FRS'\n",
    "#3,'FDIC'\n",
    "#4,'OTS'\n",
    "\n",
    "##loan_type\n",
    "#3,'small business'\n",
    "#4,'small farm'\n",
    "\n",
    "##action_taken_type\n",
    "#1,'origination'\n",
    "#6,'purchase'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete .dat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing .dat files...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Removing .dat files...')\n",
    "deletefiles = [data_dir+x for x in os.listdir(data_dir) if '.dat' in x]\n",
    "for thisfile in deletefiles:\n",
    "    os.remove(thisfile)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get aggregate data\n",
    "\n",
    "File specs: https://www.ffiec.gov/cra/pdf/17FlatAggSpecs.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get zipfiles from ffiec.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading aggregate data flatfiles...\n",
      "Starting to download 96exp_aggr.zip...\n",
      "Starting to download 97exp_aggr.zip...\n",
      "Starting to download 98exp_aggr.zip...\n",
      "Starting to download 99exp_aggr.zip...\n",
      "Starting to download 00exp_aggr.zip...\n",
      "Starting to download 01exp_aggr.zip...\n",
      "Starting to download 02exp_aggr.zip...\n",
      "Starting to download 03exp_aggr.zip...\n",
      "Starting to download 04exp_aggr.zip...\n",
      "Starting to download 05exp_aggr.zip...\n",
      "Starting to download 06exp_aggr.zip...\n",
      "Starting to download 07exp_aggr.zip...\n",
      "Starting to download 08exp_aggr.zip...\n",
      "Starting to download 09exp_aggr.zip...\n",
      "Starting to download 10exp_aggr.zip...\n",
      "Starting to download 11exp_aggr.zip...\n",
      "Starting to download 12exp_aggr.zip...\n",
      "Starting to download 13exp_aggr.zip...\n",
      "Starting to download 14exp_aggr.zip...\n",
      "Starting to download 15exp_aggr.zip...\n",
      "Starting to download 16exp_aggr.zip...\n",
      "Starting to download 17exp_aggr.zip...\n",
      "Starting to download 18exp_aggr.zip...\n",
      "Starting to download 19exp_aggr.zip...\n",
      "Got 24 files in 20 seconds!\n"
     ]
    }
   ],
   "source": [
    "# Get aggregate datafiles from ffiec.gov\n",
    "s = time.time()\n",
    "print('Downloading aggregate data flatfiles...')\n",
    "thatpath = 'https://www.ffiec.gov/cra/xls/'\n",
    "theyears = list(range(96,100))\n",
    "theyears += list(range(0,20))\n",
    "\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for i in theyears:\n",
    "    filenames.append('{:02d}exp_aggr.zip'.format(i))\n",
    "#filenames\n",
    "\n",
    "for thisfile in filenames:\n",
    "    print('Starting to download {:}...'.format(thisfile))\n",
    "    with urllib.request.urlopen(thatpath+thisfile) as response:    \n",
    "        it = response.read()\n",
    "        with open(thisfile, 'wb') as f:\n",
    "            f.write(it)\n",
    "            \n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Got {0:,.0f} files in {1:,.0f} seconds!'.format(len(filenames), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 96exp_aggr.zip...\n",
      "Extracting 97exp_aggr.zip...\n",
      "Extracting 98exp_aggr.zip...\n",
      "Extracting 99exp_aggr.zip...\n",
      "Extracting 00exp_aggr.zip...\n",
      "Extracting 01exp_aggr.zip...\n",
      "Extracting 02exp_aggr.zip...\n",
      "Extracting 03exp_aggr.zip...\n",
      "Extracting 04exp_aggr.zip...\n",
      "Extracting 05exp_aggr.zip...\n",
      "Extracting 06exp_aggr.zip...\n",
      "Extracting 07exp_aggr.zip...\n",
      "Extracting 08exp_aggr.zip...\n",
      "Extracting 09exp_aggr.zip...\n",
      "Extracting 10exp_aggr.zip...\n",
      "Extracting 11exp_aggr.zip...\n",
      "Extracting 12exp_aggr.zip...\n",
      "Extracting 13exp_aggr.zip...\n",
      "Extracting 14exp_aggr.zip...\n",
      "Extracting 15exp_aggr.zip...\n",
      "Extracting 16exp_aggr.zip...\n",
      "Extracting 17exp_aggr.zip...\n",
      "Extracting 18exp_aggr.zip...\n",
      "Extracting 19exp_aggr.zip...\n",
      "Deleting zipfiles...\n",
      "Extracted 24 zipfiles in 23 seconds!\n"
     ]
    }
   ],
   "source": [
    "#theyears = list(range(96,100))\n",
    "#theyears += list(range(0,18))\n",
    "#theyears = [17]\n",
    "s = time.time()\n",
    "\n",
    "for i in theyears:\n",
    "    thisfile = '{0:02d}exp_aggr.zip'.format(i)\n",
    "    if (thisfile in os.listdir()):\n",
    "        print('Extracting {0:}...'.format(thisfile))\n",
    "    else:\n",
    "        print(thisfile+' not found!!!')\n",
    "    thezipfile = zipfile.ZipFile(thisfile)\n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    if (i in (5,6,8,9,10,11,12,13,14,15)):\n",
    "        os.rename('exp_aggr.dat', '{0:02d}exp_aggr.dat'.format(i))\n",
    "\n",
    "print('Deleting zipfiles...')\n",
    "thezipfiles = [x for x in os.listdir() if '.zip' in x]\n",
    "for thiszip in thezipfiles:\n",
    "    os.remove(thiszip)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Extracted {0:,.0f} zipfiles in {1:,.0f} seconds!'.format(len(theyears), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016-2019: load strings from multiple files into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file cra2019_Aggr_A11.dat...\n",
      "Reading file cra2019_Aggr_A12.dat...\n",
      "Reading file cra2019_Aggr_A21.dat...\n",
      "Reading file cra2019_Aggr_A22.dat...\n",
      "Reading file cra2018_Aggr_A11.dat...\n",
      "Reading file cra2018_Aggr_A12.dat...\n",
      "Reading file cra2018_Aggr_A21.dat...\n",
      "Reading file cra2018_Aggr_A22.dat...\n",
      "Reading file cra2017_Aggr_A11.dat...\n",
      "Reading file cra2017_Aggr_A12.dat...\n",
      "Reading file cra2017_Aggr_A21.dat...\n",
      "Reading file cra2017_Aggr_A22.dat...\n",
      "Reading file cra2016_Aggr_A11.dat...\n",
      "Reading file cra2016_Aggr_A12.dat...\n",
      "Reading file cra2016_Aggr_A21.dat...\n",
      "Reading file cra2016_Aggr_A22.dat...\n",
      "\n",
      "\n",
      "Read 2016-2019 data: 1,008,878 rows in 4 seconds.\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "agg_loans_df = pandas.DataFrame()\n",
    "\n",
    "minyear = 2016\n",
    "maxyear = 2019\n",
    "for y in range(maxyear, minyear-1, -1):\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,3):\n",
    "            thisfile = 'cra{0:04d}_Aggr_A{1:.0f}{2:.0f}.dat'.format(y,i,j)\n",
    "            print('Reading file {:}...'.format(thisfile))\n",
    "            agg_loans_df = agg_loans_df.append(pandas.read_csv(thisfile, header=None))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('\\n')\n",
    "print('Read {0:04d}-{1:04d} data: {2:,.0f} rows in {3:,.0f} seconds.'.format(minyear, maxyear, len(agg_loans_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read 2004-2015 data (the long strings), append to the same DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found filenames!\n",
      "Reading file 15exp_aggr.dat...\n",
      "Reading file 14exp_aggr.dat...\n",
      "Reading file 13exp_aggr.dat...\n",
      "Reading file 12exp_aggr.dat...\n",
      "Reading file 11exp_aggr.dat...\n",
      "Reading file 10exp_aggr.dat...\n",
      "Reading file 09exp_aggr.dat...\n",
      "Reading file 08exp_aggr.dat...\n",
      "Reading file 07exp_aggr.dat...\n",
      "Reading file 06exp_aggr.dat...\n",
      "Reading file 05exp_aggr.dat...\n",
      "Reading file 04exp_aggr.dat...\n",
      "Read 2004-2015 data: 5,718,233 rows in 19 seconds.\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "minyear = 2004\n",
    "maxyear = 2015\n",
    "\n",
    "filelist = []\n",
    "for i in range(maxyear, minyear-1, -1):\n",
    "    thisfile = '{:}exp_aggr.dat'.format(str(i)[2:])\n",
    "    filelist.append(thisfile)\n",
    "print('Found filenames!')\n",
    "#print(filelist)\n",
    "for thisfile in filelist:\n",
    "    print('Reading file {:}...'.format(thisfile))\n",
    "    agg_loans_df = agg_loans_df.append(pandas.read_csv(thisfile, header=None))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:4d}-{1:04d} data: {2:,.0f} rows in {3:,.0f} seconds.'.format(minyear, maxyear, len(agg_loans_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tableID to keep only aggregated loans data (not lenders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse aggregate loans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning tableID...\n",
      "keeping only loans data...\n",
      "Assigning report_level...\n",
      "keeping only base level data (report_level blank)...\n",
      "\n",
      "Assigning...\n",
      "activity_year...\n",
      "loan_type...\n",
      "action_taken_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "census_tract...\n",
      "split_county_indicator...\n",
      "population_classification...\n",
      "income_group_total...\n",
      "nLoans1...\n",
      "amtLoans1...\n",
      "nLoans100k...\n",
      "amtLoans100k...\n",
      "nLoans250k...\n",
      "amtLoans250k...\n",
      "nLoansToSmalest...\n",
      "amtLoansToSmalest...\n",
      "\n",
      "Deleting columns we do not need...\n",
      "Converting columns to numeric...\n",
      "activity_year...\n",
      "loan_type...\n",
      "action_taken_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "census_tract...\n",
      "income_group_total...\n",
      "nLoans1...\n",
      "amtLoans1...\n",
      "nLoans100k...\n",
      "amtLoans100k...\n",
      "nLoans250k...\n",
      "amtLoans250k...\n",
      "nLoansToSmallest...\n",
      "amtLoansToSmallest...\n",
      "Multiplying loan amounts by 1000 for real dollars...\n",
      "Writing out...\n",
      "Processed 3,046,200 rows in 196 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "agg_loans_df.columns = ['thestring']\n",
    "agg_loans_df.index.name = 'rownumber'\n",
    "\n",
    "print('Assigning tableID...')\n",
    "agg_loans_df = agg_loans_df.assign(tableID = agg_loans_df['thestring'].apply(lambda x: x[0:5]))\n",
    "print('keeping only loans data...')\n",
    "agg_loans_df = agg_loans_df[agg_loans_df['tableID'].apply(lambda x: 'a' not in x)]\n",
    "\n",
    "print('Assigning report_level...')\n",
    "agg_loans_df = agg_loans_df.assign(report_level = agg_loans_df['thestring'].apply(lambda x: x[33:36]))\n",
    "print('keeping only base level data (report_level blank)...')\n",
    "agg_loans_df = agg_loans_df[agg_loans_df['report_level'] == '   ']\n",
    "\n",
    "print('\\nAssigning...')\n",
    "print('activity_year...')\n",
    "agg_loans_df = agg_loans_df.assign(activity_year = agg_loans_df['thestring'].apply(lambda x: x[5:9]))\n",
    "print('loan_type...')\n",
    "agg_loans_df = agg_loans_df.assign(loan_type = agg_loans_df['thestring'].apply(lambda x: x[9]))\n",
    "print('action_taken_type...')\n",
    "agg_loans_df = agg_loans_df.assign(action_taken_type = agg_loans_df['thestring'].apply(lambda x: x[10]))\n",
    "print('state...')\n",
    "agg_loans_df = agg_loans_df.assign(state = agg_loans_df['thestring'].apply(lambda x: x[11:13]))\n",
    "print('county...')\n",
    "agg_loans_df = agg_loans_df.assign(county = agg_loans_df['thestring'].apply(lambda x: x[13:16]))\n",
    "print('msa...')\n",
    "agg_loans_df = agg_loans_df.assign(msa = agg_loans_df['thestring'].apply(lambda x: x[16:21]))\n",
    "print('census_tract...')\n",
    "agg_loans_df = agg_loans_df.assign(census_tract = agg_loans_df['thestring'].apply(lambda x: x[21:28]))\n",
    "print('split_county_indicator...')\n",
    "agg_loans_df = agg_loans_df.assign(split_county_indicator = agg_loans_df['thestring'].apply(lambda x: x[28]))\n",
    "print('population_classification...')\n",
    "agg_loans_df = agg_loans_df.assign(population_classification = agg_loans_df['thestring'].apply(lambda x: x[29]))\n",
    "print('income_group_total...')\n",
    "agg_loans_df = agg_loans_df.assign(income_group_total = agg_loans_df['thestring'].apply(lambda x: x[30:33]))\n",
    "print('nLoans1...')\n",
    "agg_loans_df = agg_loans_df.assign(nLoans1 = agg_loans_df['thestring'].apply(lambda x: x[36:46]))\n",
    "print('amtLoans1...')\n",
    "agg_loans_df = agg_loans_df.assign(amtLoans1 = agg_loans_df['thestring'].apply(lambda x: x[46:56]))\n",
    "print('nLoans100k...')\n",
    "agg_loans_df = agg_loans_df.assign(nLoans100k = agg_loans_df['thestring'].apply(lambda x: x[56:66]))\n",
    "print('amtLoans100k...')\n",
    "agg_loans_df = agg_loans_df.assign(amtLoans100k = agg_loans_df['thestring'].apply(lambda x: x[66:76]))\n",
    "print('nLoans250k...')\n",
    "agg_loans_df = agg_loans_df.assign(nLoans250k = agg_loans_df['thestring'].apply(lambda x: x[76:86]))\n",
    "print('amtLoans250k...')\n",
    "agg_loans_df = agg_loans_df.assign(amtLoans250k = agg_loans_df['thestring'].apply(lambda x: x[86:96]))\n",
    "print('nLoansToSmalest...')\n",
    "agg_loans_df = agg_loans_df.assign(nLoansToSmallest = agg_loans_df['thestring'].apply(lambda x: x[96:106]))\n",
    "print('amtLoansToSmalest...')\n",
    "agg_loans_df = agg_loans_df.assign(amtLoansToSmallest = agg_loans_df['thestring'].apply(lambda x: x[106:116]))\n",
    "\n",
    "print('\\nDeleting columns we do not need...')\n",
    "agg_loans_df = agg_loans_df.drop(['thestring', 'tableID', 'report_level'], axis=1)\n",
    "\n",
    "print('Converting columns to numeric...')\n",
    "numeric_columns = ['activity_year', 'loan_type', 'action_taken_type']\n",
    "numeric_columns += ['state', 'county', 'msa', 'census_tract']\n",
    "numeric_columns += ['income_group_total', 'nLoans1', 'amtLoans1']\n",
    "numeric_columns += ['nLoans100k', 'amtLoans100k']\n",
    "numeric_columns += ['nLoans250k', 'amtLoans250k']\n",
    "numeric_columns += ['nLoansToSmallest', 'amtLoansToSmallest']\n",
    "\n",
    "for x in numeric_columns:\n",
    "    print('{0:}...'.format(x))\n",
    "    agg_loans_df.loc[:, x] = pandas.to_numeric(agg_loans_df[x], errors='coerce')\n",
    "\n",
    "print('Multiplying loan amounts by 1000 for real dollars...')\n",
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k']\n",
    "money_columns += ['amtLoansToSmallest']\n",
    "for x in money_columns:\n",
    "    agg_loans_df.loc[:, x] = agg_loans_df[x] * 1000\n",
    "\n",
    "print('Writing out...')\n",
    "agg_loans_df.to_csv('agg_loans.csv', encoding='utf-8')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(agg_loans_df), e-s))\n",
    "\n",
    "#agg_loans_df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse aggregated lender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file cra2019_Aggr_A11a.dat...\n",
      "Reading file cra2019_Aggr_A12a.dat...\n",
      "Reading file cra2019_Aggr_A21a.dat...\n",
      "Reading file cra2019_Aggr_A22a.dat...\n",
      "Reading file cra2018_Aggr_A11a.dat...\n",
      "Reading file cra2018_Aggr_A12a.dat...\n",
      "Reading file cra2018_Aggr_A21a.dat...\n",
      "Reading file cra2018_Aggr_A22a.dat...\n",
      "Reading file cra2017_Aggr_A11a.dat...\n",
      "Reading file cra2017_Aggr_A12a.dat...\n",
      "Reading file cra2017_Aggr_A21a.dat...\n",
      "Reading file cra2017_Aggr_A22a.dat...\n",
      "Reading file cra2016_Aggr_A11a.dat...\n",
      "Reading file cra2016_Aggr_A12a.dat...\n",
      "Reading file cra2016_Aggr_A21a.dat...\n",
      "Reading file cra2016_Aggr_A22a.dat...\n",
      "Read 2016-2019 data: 864,695 rows...\n",
      "\n",
      "\n",
      "Found filenames!\n",
      "Reading file 15exp_aggr.dat...\n",
      "Reading file 14exp_aggr.dat...\n",
      "Reading file 13exp_aggr.dat...\n",
      "Reading file 12exp_aggr.dat...\n",
      "Reading file 11exp_aggr.dat...\n",
      "Reading file 10exp_aggr.dat...\n",
      "Reading file 09exp_aggr.dat...\n",
      "Reading file 08exp_aggr.dat...\n",
      "Reading file 07exp_aggr.dat...\n",
      "Reading file 06exp_aggr.dat...\n",
      "Reading file 05exp_aggr.dat...\n",
      "Reading file 04exp_aggr.dat...\n",
      "Read 2004-2015 data: 3,046,200 rows...\n",
      "\n",
      "\n",
      "Assigning tableID...\n",
      "keeping only loans data...\n",
      "Assigning report_level...\n",
      "keeping only lenders data...\n",
      "\n",
      "Assigning...\n",
      "activity_year...\n",
      "loan_type...\n",
      "action_taken_type...\n",
      "state...\n",
      "county...\n",
      "msa...\n",
      "respondentID...\n",
      "agency_code...\n",
      "nLenders...\n",
      "nLoans...\n",
      "amtLoans...\n",
      "nLoansToSmallest...\n",
      "amtLoansToSmallest...\n",
      "\n",
      "Dropping columns we do not need...\n",
      "Multiplying loan amounts by 1000 for real dollars...\n",
      "Writing out...\n",
      "Processed 2,588,233 rows in 146 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "agg_lenders_df = pandas.DataFrame()\n",
    "\n",
    "minyear = 2016\n",
    "maxyear = 2019\n",
    "for y in range(maxyear, minyear-1, -1):\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,3):\n",
    "            thisfile = 'cra{0:04d}_Aggr_A{1:.0f}{2:.0f}a.dat'.format(y,i,j)\n",
    "            print('Reading file {:}...'.format(thisfile))\n",
    "            agg_lenders_df = agg_lenders_df.append(pandas.read_csv(thisfile, header=None))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:04d}-{1:04d} data: {2:,.0f} rows...'.format(minyear, maxyear, len(agg_lenders_df)))\n",
    "\n",
    "minyear = 2004\n",
    "maxyear = 2015\n",
    "\n",
    "filelist = []\n",
    "for i in range(maxyear, minyear-1, -1):\n",
    "    thisfile = '{:}exp_aggr.dat'.format(str(i)[2:])\n",
    "    filelist.append(thisfile)\n",
    "print('\\n')\n",
    "print('Found filenames!')\n",
    "#print(filelist)\n",
    "for thisfile in filelist:\n",
    "    print('Reading file {:}...'.format(thisfile))\n",
    "    agg_lenders_df = agg_lenders_df.append(pandas.read_csv(thisfile, header=None))\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:4d}-{1:04d} data: {2:,.0f} rows...'.format(minyear, maxyear, len(agg_loans_df), e-s))\n",
    "print('\\n')\n",
    "\n",
    "agg_lenders_df.columns = ['thestring']\n",
    "agg_lenders_df.index.name = 'rownumber'\n",
    "\n",
    "print('Assigning tableID...')\n",
    "agg_lenders_df = agg_lenders_df.assign(tableID = agg_lenders_df['thestring'].apply(lambda x: x[0:5]))\n",
    "print('keeping only loans data...')\n",
    "agg_lenders_df = agg_lenders_df[agg_lenders_df['tableID'].apply(lambda x: 'a' in x)]\n",
    "\n",
    "print('Assigning report_level...')\n",
    "agg_lenders_df = agg_lenders_df.assign(report_level = agg_lenders_df['thestring'].apply(lambda x: x[37:40]))\n",
    "print('keeping only lenders data...')\n",
    "agg_lenders_df = agg_lenders_df[agg_lenders_df['report_level'] == '   ']\n",
    "\n",
    "print('\\nAssigning...')\n",
    "print('activity_year...')\n",
    "agg_lenders_df = agg_lenders_df.assign(activity_year = agg_lenders_df['thestring'].apply(lambda x: x[5:9]))\n",
    "print('loan_type...')\n",
    "agg_lenders_df = agg_lenders_df.assign(loan_type = agg_lenders_df['thestring'].apply(lambda x: x[9]))\n",
    "print('action_taken_type...')\n",
    "agg_lenders_df = agg_lenders_df.assign(action_taken_type = agg_lenders_df['thestring'].apply(lambda x: x[10]))\n",
    "print('state...')\n",
    "agg_lenders_df = agg_lenders_df.assign(state = agg_lenders_df['thestring'].apply(lambda x: x[11:13]))\n",
    "print('county...')\n",
    "agg_lenders_df = agg_lenders_df.assign(county = agg_lenders_df['thestring'].apply(lambda x: x[13:16]))\n",
    "print('msa...')\n",
    "agg_lenders_df = agg_lenders_df.assign(msa = agg_lenders_df['thestring'].apply(lambda x: x[16:21]))\n",
    "print('respondentID...')\n",
    "agg_lenders_df = agg_lenders_df.assign(respondentID = agg_lenders_df['thestring'].apply(lambda x: x[21:31]))\n",
    "print('agency_code...')\n",
    "agg_lenders_df = agg_lenders_df.assign(agency_code = agg_lenders_df['thestring'].apply(lambda x: x[31]))\n",
    "print('nLenders...')\n",
    "agg_lenders_df = agg_lenders_df.assign(nLenders = agg_lenders_df['thestring'].apply(lambda x: x[32:37]))\n",
    "print('nLoans...')\n",
    "agg_lenders_df = agg_lenders_df.assign(nLoans = agg_lenders_df['thestring'].apply(lambda x: x[40:50]))\n",
    "print('amtLoans...')\n",
    "agg_lenders_df = agg_lenders_df.assign(amtLoans = agg_lenders_df['thestring'].apply(lambda x: x[50:60]))\n",
    "print('nLoansToSmallest...')\n",
    "agg_lenders_df = agg_lenders_df.assign(nLoansToSmallest = agg_lenders_df['thestring'].apply(lambda x: x[60:70]))\n",
    "print('amtLoansToSmallest...')\n",
    "agg_lenders_df = agg_lenders_df.assign(amtLoansToSmallest = agg_lenders_df['thestring'].apply(lambda x: x[70:80]))\n",
    "\n",
    "print('\\nDropping columns we do not need...')\n",
    "agg_lenders_df = agg_lenders_df.drop(['thestring', 'tableID', 'report_level'], axis=1)\n",
    "\n",
    "numeric_columns = ['activity_year', 'loan_type', 'action_taken_type']\n",
    "numeric_columns += ['state', 'county', 'msa', 'respondentID', 'agency_code']\n",
    "numeric_columns += ['nLenders', 'nLoans', 'amtLoans']\n",
    "numeric_columns += ['nLoansToSmallest', 'amtLoansToSmallest']\n",
    "\n",
    "for x in numeric_columns:\n",
    "    agg_lenders_df.loc[:, x] = pandas.to_numeric(agg_lenders_df[x], errors='coerce')\n",
    "    \n",
    "print('Multiplying loan amounts by 1000 for real dollars...')\n",
    "money_columns = ['amtLoans', 'amtLoansToSmallest']\n",
    "for x in money_columns:\n",
    "    agg_lenders_df.loc[:, x] = agg_lenders_df[x] * 1000\n",
    "\n",
    "print('Writing out...')\n",
    "agg_lenders_df.to_csv('agg_lenders.csv', encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(agg_lenders_df), e-s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete .dat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing .dat files...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Removing .dat files...')\n",
    "deletefiles = [data_dir+x for x in os.listdir(data_dir) if '.dat' in x]\n",
    "for thisfile in deletefiles:\n",
    "    os.remove(thisfile)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
