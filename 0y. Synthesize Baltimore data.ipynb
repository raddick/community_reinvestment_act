{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "Now in directory: /home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "#from IPython.display import display, HTML\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "debug = 1\n",
    "\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "#data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch_final/'\n",
    "baltimore_dir = thisdir + 'baltimore/'\n",
    "\n",
    "code_lookup_dir = thisdir + 'code_guide_lookups/'\n",
    "inflation_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/inflation/'\n",
    "\n",
    "g = 0  # keep track of grand total of processing time\n",
    "\n",
    "os.chdir(thisdir)\n",
    "print('Now in directory: {0:}'.format(os.getcwd()))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CRA loans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading loan data...\n",
      "Keeping loans 2011 and later (since we do not have 2010 small business jobs...\n",
      "Keeping only business loan originations...\n",
      "Processed 1,388 rows in 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading loan data...')\n",
    "baltimore_agg_loans_df = pandas.read_csv(baltimore_dir+'baltimore_agg_loans_df.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "print('Keeping loans 2011 and later (since we do not have 2010 small business jobs...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df[baltimore_agg_loans_df['activity_year'] >= 2011]\n",
    "print('Keeping only business loan originations...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df[(baltimore_agg_loans_df['loan_type'] == 4) & (baltimore_agg_loans_df['action_taken_type'] == 1)]\n",
    "e = time.time()\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(baltimore_agg_loans_df), e-s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate total loans and working loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total loans per tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting total loans...\n",
      "Processed 1,388 rows in 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "print('getting total loans...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans = baltimore_agg_loans_df['nLoans1'] + baltimore_agg_loans_df['nLoans100k'] + baltimore_agg_loans_df['nLoans250k'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans = baltimore_agg_loans_df['amtLoans1'] + baltimore_agg_loans_df['amtLoans100k'] + baltimore_agg_loans_df['amtLoans250k'])\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(baltimore_agg_loans_df), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working loans per tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating working loans...\n",
      "Setting multi-index to census_tract and year...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('calculating working loans...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(avgSmallLoan = baltimore_agg_loans_df['amtLoans1'] / baltimore_agg_loans_df['nLoans1'])\n",
    "#print('Removing loans from American Express...')\n",
    "#respondents_df = pandas.read_csv(code_lookup_dir+'respondentid.csv', low_memory=False, encoding='utf-8')#, index_col='respondentID')\n",
    "#amex_respondentIDs = baltimore_loans_df.merge(respondents_df, how='left', on='respondentID')['respondentID'][baltimore_loans_df.merge(respondents_df, how='left', on='respondentID')['institution_name'].apply(lambda x: 'american express' in str(x).lower())].drop_duplicates().tolist()\n",
    "#respondents_df[respondents_df['respondentID'].apply(lambda x: x in amex_respondentIDs)]\n",
    "#baltimore_loans_df = baltimore_loans_df[baltimore_loans_df['respondentID'].apply(lambda x: x not in amex_respondentIDs)]\n",
    "#print('Removed (credit card) loans from American Express, now {0:,.0f} loans...'.format(len(baltimore_loans_df)))\n",
    "\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nWorkingLoans = np.nan)\n",
    "baltimore_agg_loans_df.loc[baltimore_agg_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'nWorkingLoans'] = baltimore_agg_loans_df['nLoans'][baltimore_agg_loans_df['avgSmallLoan'] < 10000] - baltimore_agg_loans_df['nLoans1'][baltimore_agg_loans_df['avgSmallLoan'] < 10000]\n",
    "baltimore_agg_loans_df.loc[baltimore_agg_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'nWorkingLoans'] = baltimore_agg_loans_df['nLoans'][baltimore_agg_loans_df['avgSmallLoan'] >= 10000]\n",
    "\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtWorkingLoans = np.nan)\n",
    "baltimore_agg_loans_df.loc[baltimore_agg_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'amtWorkingLoans'] = baltimore_agg_loans_df['amtLoans'][baltimore_agg_loans_df['avgSmallLoan'] < 10000] - baltimore_agg_loans_df['amtLoans1'][baltimore_agg_loans_df['avgSmallLoan'] < 10000]\n",
    "baltimore_agg_loans_df.loc[baltimore_agg_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'amtWorkingLoans'] = baltimore_agg_loans_df['amtLoans'][baltimore_agg_loans_df['avgSmallLoan'] >= 10000]\n",
    "\n",
    "print('Setting multi-index to census_tract and year...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.set_index(['census_tract', 'activity_year'])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading job data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping by census tract and year...\n",
      "removing jobs data from 2010...\n",
      "joining jobs data onto loans data...\n",
      "Processed 1,388 rows in 31 seconds!\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loan_type</th>\n",
       "      <th>action_taken_type</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>msa</th>\n",
       "      <th>split_county_indicator</th>\n",
       "      <th>population_classification</th>\n",
       "      <th>income_group_total</th>\n",
       "      <th>nLoans1</th>\n",
       "      <th>amtLoans1</th>\n",
       "      <th>...</th>\n",
       "      <th>CFA01</th>\n",
       "      <th>CFA02</th>\n",
       "      <th>CFA03</th>\n",
       "      <th>CFA04</th>\n",
       "      <th>CFA05</th>\n",
       "      <th>CFS01</th>\n",
       "      <th>CFS02</th>\n",
       "      <th>CFS03</th>\n",
       "      <th>CFS04</th>\n",
       "      <th>CFS05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_tract</th>\n",
       "      <th>activity_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1205.0</th>\n",
       "      <th>2014</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>12580.0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>799000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904.0</th>\n",
       "      <th>2015</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>510</td>\n",
       "      <td>12580.0</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>549000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            loan_type  action_taken_type  state  county  \\\n",
       "census_tract activity_year                                                \n",
       "1205.0       2014           4          1                  24     510      \n",
       "904.0        2015           4          1                  24     510      \n",
       "\n",
       "                                msa split_county_indicator  \\\n",
       "census_tract activity_year                                   \n",
       "1205.0       2014           12580.0  N                       \n",
       "904.0        2015           12580.0  N                       \n",
       "\n",
       "                           population_classification  income_group_total  \\\n",
       "census_tract activity_year                                                 \n",
       "1205.0       2014           L                         8                    \n",
       "904.0        2015           L                         3                    \n",
       "\n",
       "                            nLoans1  amtLoans1  ...    CFA01  CFA02  CFA03  \\\n",
       "census_tract activity_year                      ...                          \n",
       "1205.0       2014           41       799000     ...    40.0   27.0   81.0    \n",
       "904.0        2015           24       549000     ...    34.0   6.0    5.0     \n",
       "\n",
       "                            CFA04  CFA05  CFS01  CFS02  CFS03  CFS04  CFS05  \n",
       "census_tract activity_year                                                   \n",
       "1205.0       2014           121.0  702.0  356.0  253.0  231.0  44.0   87.0   \n",
       "904.0        2015           5.0    521.0  112.0  77.0   11.0   162.0  209.0  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = time.time()\n",
    "print('reading job data...')\n",
    "\n",
    "raw_jobs_df = pandas.read_csv(baltimore_dir+'wac_jobs_df.csv', index_col='rownumber')\n",
    "\n",
    "print('grouping by census tract and year...')\n",
    "# GeoID format is STATE+COUNTY+TRACT+BLOCK (2+3+6+4 = 15 characters)\n",
    "raw_jobs_df = raw_jobs_df.assign(census_tract = pandas.to_numeric(raw_jobs_df['w_geocode'].apply(lambda x: str(x)[5:9] + '.' + str(x)[9:11]), errors='coerce'))#.drop_duplicates().sort_values()[0:3]\n",
    "\n",
    "sum_columns = [x for x in raw_jobs_df.columns.tolist() if x not in ('w_geocode', 'createdate', 'year')]\n",
    "jobs_df = pandas.DataFrame()\n",
    "\n",
    "for i in range(2010,2018):\n",
    "    jobs_i_df = raw_jobs_df[sum_columns][raw_jobs_df['year'] == i].groupby('census_tract', as_index=False).sum()\n",
    "    if (i >= 2016):\n",
    "        jobs_i_df = raw_jobs_df[sum_columns][raw_jobs_df['year'] == 2015].groupby('census_tract', as_index=False).sum()\n",
    "    jobs_i_df = jobs_i_df.assign(year = i)\n",
    "    jobs_df = pandas.concat((jobs_df, jobs_i_df), axis=0)\n",
    "\n",
    "jobs_df = jobs_df.rename(columns={'year': 'activity_year'})\n",
    "print('removing jobs data from 2010...')\n",
    "jobs_df = jobs_df[jobs_df['activity_year'] >= 2011]\n",
    "jobs_df = jobs_df.set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('joining jobs data onto loans data...')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.join(jobs_df)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Processed {0:,.0f} rows in {1:,.0f} seconds!'.format(len(baltimore_agg_loans_df), e-s))\n",
    "print('Done!')\n",
    "baltimore_agg_loans_df.sample(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which jobs columns do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable: C000\t\tdescription:Total number of jobs\n",
      "variable: CFS01\t\tdescription:Number of jobs for workers at firms with Firm Size: 0-19 Employees\n"
     ]
    }
   ],
   "source": [
    "jobs_metadata_df = pandas.read_csv(baltimore_dir+'wac_jobs_metadata.csv', encoding='utf-8', index_col='varnum')\n",
    "jobs_metadata_df = jobs_metadata_df.set_index('variable')\n",
    "\n",
    "jobs_columns = ['C000', 'CA01', 'CA02', 'CA03', 'CE01', 'CE02', 'CE03', 'CNS01']\n",
    "jobs_columns += ['CNS02', 'CNS03', 'CNS04', 'CNS05', 'CNS06', 'CNS07', 'CNS08']\n",
    "jobs_columns += ['CNS09', 'CNS10', 'CNS11', 'CNS12', 'CNS13', 'CNS14', 'CNS15']\n",
    "jobs_columns += ['CNS16', 'CNS17', 'CNS18', 'CNS19', 'CNS20', 'CR01', 'CR02']\n",
    "jobs_columns += ['CR03', 'CR04', 'CR05', 'CR07', 'CT01', 'CT02', 'CD01', 'CD02']\n",
    "jobs_columns += ['CD03', 'CD04', 'CS01', 'CS02', 'CFA01', 'CFA02', 'CFA03']\n",
    "jobs_columns += ['CFA04', 'CFA05', 'CFS01', 'CFS02', 'CFS03', 'CFS04', 'CFS05']\n",
    "\n",
    "#for x in baltimore_agg_loans_df[jobs_columns].columns:\n",
    "#    print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n",
    "    \n",
    "jobs_columns_we_want = ['C000', 'CFS01']\n",
    "for x in baltimore_agg_loans_df[jobs_columns_we_want].columns:\n",
    "    print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcuate loans per job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calulating loans per job (total and with firm size 0-19)...\n",
      "recoding infinite values to NaN...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#sbjobs_column = jobs_varnames_df[jobs_varnames_df['description'].apply(lambda x: '0-19' in x)].index.values[0]\n",
    "#loans_columns = []\n",
    "#baltimore_agg_loans_df[sbjobs_column]\n",
    "print('Calulating loans per job (total and with firm size 0-19)...')\n",
    "\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans1_per_totaljob = baltimore_agg_loans_df['nLoans1'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans1_per_totaljob = baltimore_agg_loans_df['amtLoans1'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans100k_per_totaljob = baltimore_agg_loans_df['nLoans100k'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans100k_per_totaljob = baltimore_agg_loans_df['amtLoans100k'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans250k_per_totaljob = baltimore_agg_loans_df['nLoans250k'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans250k_per_totaljob = baltimore_agg_loans_df['amtLoans250k'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoansToSmallest_per_totaljob = baltimore_agg_loans_df['nLoansToSmallest'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoansToSmallest_per_totaljob = baltimore_agg_loans_df['amtLoansToSmallest'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans_per_totaljob = baltimore_agg_loans_df['nLoans'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans_per_totaljob = baltimore_agg_loans_df['amtLoans'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nWorkingLoans_per_totaljob = baltimore_agg_loans_df['nWorkingLoans'] / baltimore_agg_loans_df['C000'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtWorkingLoans_per_totaljob = baltimore_agg_loans_df['amtWorkingLoans'] / baltimore_agg_loans_df['C000'])\n",
    "\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans1_per_sbjob = baltimore_agg_loans_df['nLoans1'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans1_per_sbjob = baltimore_agg_loans_df['amtLoans1'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans100k_per_sbjob = baltimore_agg_loans_df['nLoans100k'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans100k_per_sbjob = baltimore_agg_loans_df['amtLoans100k'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans250k_per_sbjob = baltimore_agg_loans_df['nLoans250k'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans250k_per_sbjob = baltimore_agg_loans_df['amtLoans250k'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoansToSmallest_per_sbjob = baltimore_agg_loans_df['nLoansToSmallest'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoansToSmallest_per_sbjob = baltimore_agg_loans_df['amtLoansToSmallest'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nLoans_per_sbjob = baltimore_agg_loans_df['nLoans'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtLoans_per_sbjob = baltimore_agg_loans_df['amtLoans'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(nWorkingLoans_per_sbjob = baltimore_agg_loans_df['nWorkingLoans'] / baltimore_agg_loans_df['CFS01'])\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.assign(amtWorkingLoans_per_sbjob = baltimore_agg_loans_df['amtWorkingLoans'] / baltimore_agg_loans_df['CFS01'])\n",
    "\n",
    "print('recoding infinite values to NaN...')\n",
    "\n",
    "per_job_columns = ['nLoans1_per_totaljob', 'amtLoans1_per_totaljob', 'nLoans100k_per_totaljob']\n",
    "per_job_columns += ['amtLoans100k_per_totaljob', 'nLoans250k_per_totaljob', 'amtLoans250k_per_totaljob']\n",
    "per_job_columns += ['nLoansToSmallest_per_totaljob', 'amtLoansToSmallest_per_totaljob']\n",
    "per_job_columns += ['nLoans_per_totaljob', 'amtLoans_per_totaljob', 'nWorkingLoans_per_totaljob']\n",
    "per_job_columns += ['amtWorkingLoans_per_totaljob', 'nLoans1_per_sbjob', 'amtLoans1_per_sbjob']\n",
    "per_job_columns += ['nLoans100k_per_sbjob', 'amtLoans100k_per_sbjob', 'nLoans250k_per_sbjob']\n",
    "per_job_columns += ['amtLoans250k_per_sbjob', 'nLoansToSmallest_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "per_job_columns += ['nLoans_per_sbjob', 'amtLoans_per_sbjob', 'nWorkingLoans_per_sbjob']\n",
    "per_job_columns += ['amtWorkingLoans_per_sbjob']\n",
    "\n",
    "for x in baltimore_agg_loans_df[per_job_columns]:\n",
    "    baltimore_agg_loans_df.loc[baltimore_agg_loans_df[x] == np.inf, x] = np.nan\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect ACS 5-year census data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "acs5_df = pandas.read_csv(baltimore_dir+'acs5_2010_2017.csv', encoding='utf-8', low_memory=False, index_col='Unnamed: 0')\n",
    "acs5_df.index.name = 'rownumber'\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# MAKE A LIST of all variables\n",
    "descriptions = []\n",
    "metadata_df = pandas.read_csv(baltimore_dir+'acs5_metadata/acs5_metadata_2017.csv', encoding='utf-8', low_memory=False, index_col='variable')\n",
    "acs5_columns = [x for x in acs5_df.columns[4:-2].tolist() if ('_err' not in x)]\n",
    "for x in acs5_columns:\n",
    "    this_description = {}\n",
    "    this_description[x] = metadata_df['description'].loc[x]\n",
    "    descriptions.append(this_description)\n",
    "#acs5_df['description']\n",
    "#for x in descriptions:\n",
    "#    for k,v in x.items():\n",
    "#        if ('education' in v.lower()):\n",
    "#            print(k,v)\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating and renaming estimates columns for IVs...\n",
      "...high school graduates or higher 25 years and older...\n",
      "...householder sex & race, unempoyment, poverty, home value, home age...\n",
      "...race, owner-occupied units, mfi...\n",
      "....comparison variables: total population, total households, poverty status...\n",
      "...population 25plus...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('\\ncalculating and renaming estimates columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...high school graduates or higher 25 years and older...')\n",
    "h = acs5_df['B15002_011'] + acs5_df['B15002_012'] + acs5_df['B15002_013'] \n",
    "h += acs5_df['B15002_014'] + acs5_df['B15002_015'] + acs5_df['B15002_016']\n",
    "h += acs5_df['B15002_017'] + acs5_df['B15002_018']\n",
    "h += acs5_df['B15002_028'] + acs5_df['B15002_029'] + acs5_df['B15002_030'] \n",
    "h += acs5_df['B15002_031'] + acs5_df['B15002_032'] + acs5_df['B15002_033'] \n",
    "h += acs5_df['B15002_034'] + acs5_df['B15002_035']\n",
    "acs5_df = acs5_df.assign(hs_grad_25plus = pandas.to_numeric(h, errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "acs5_df = acs5_df.rename(columns = {     \n",
    "    'B11001_006': 'female_householder',\n",
    "    'B11001B_001': 'black_householder',\n",
    "    'B11001H_001': 'white_householder',\n",
    "    'B23025_005': 'unemployed_16plus',\n",
    "    'B17001_002': 'poverty_past_12_months',\n",
    "    'B25077_001': 'median_home_value',\n",
    "    'B25035_001': 'median_year_built'\n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "acs5_df = acs5_df.rename(columns = {\n",
    "    'B02001_002': 'pop_white',\n",
    "    'B02001_003': 'pop_black',\n",
    "    'B25003_002': 'owner_occ_housing_units',\n",
    "    'B19113_001': 'mfi'    \n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('....comparison variables: total population, total households, poverty status...')\n",
    "acs5_df = acs5_df.rename(columns = {\n",
    "    'B01001_001': 'pop_total',\n",
    "    'B11001_001': 'total_householders',\n",
    "    'B23025_002': 'labor_force_16plus',\n",
    "    'B17001_001': 'poverty_status_known'\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "acs5_df = acs5_df.assign(pop_25plus = pandas.to_numeric(\n",
    "                                             (acs5_df['B01001_011'] + acs5_df['B01001_012'] + acs5_df['B01001_013'] \n",
    "                                              + acs5_df['B01001_014'] + acs5_df['B01001_015'] + acs5_df['B01001_016']\n",
    "                                              + acs5_df['B01001_017'] + acs5_df['B01001_018'] + acs5_df['B01001_019']\n",
    "                                              + acs5_df['B01001_020'] + acs5_df['B01001_021'] + acs5_df['B01001_022']\n",
    "                                              + acs5_df['B01001_023'] + acs5_df['B01001_024'] + acs5_df['B01001_025']\n",
    "                                              + acs5_df['B01001_035'] + acs5_df['B01001_036'] + acs5_df['B01001_037']\n",
    "                                              + acs5_df['B01001_038'] + acs5_df['B01001_039'] + acs5_df['B01001_040']\n",
    "                                              + acs5_df['B01001_041'] + acs5_df['B01001_042'] + acs5_df['B01001_043']\n",
    "                                              + acs5_df['B01001_044'] + acs5_df['B01001_045'] + acs5_df['B01001_046']\n",
    "                                              + acs5_df['B01001_047'] + acs5_df['B01001_048'] + acs5_df['B01001_049']\n",
    "                                             ), errors='coerce'\n",
    "                                         )\n",
    "                                        )\n",
    "#acs5_df.sample(1).T\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get errors for composite columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the functions we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined standard-error-calculating functions!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "### Guide on how to calculate errors in percentages:\n",
    "# https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "    \n",
    "## Aggregating Data Across Population Subgroups: add error for each group in quadrature, divide by 1.645 for serr\n",
    "\n",
    "def find_serr_hsgrad25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B15002_011_err']**2 + row['B15002_012_err']**2 + row['B15002_013_err']**2 \n",
    "                                 + row['B15002_014_err']**2 + row['B15002_015_err']**2 + row['B15002_016_err']**2 \n",
    "                                 + row['B15002_017_err']**2 + row['B15002_018_err']**2 + \n",
    "                                 + row['B15002_028_err']**2 + row['B15002_029_err']**2 + row['B15002_030_err']**2 \n",
    "                                 + row['B15002_031_err']**2 + row['B15002_032_err']**2 + row['B15002_033_err']**2 \n",
    "                                 + row['B15002_034_err']**2 + row['B15002_035_err']**2\n",
    "                                ) / 1.645, errors='coerce')\n",
    "\n",
    "def find_serr_pop25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B01001_011_err']**2 + row['B01001_012_err']**2 + row['B01001_013_err']**2 \n",
    "                                     + row['B01001_014_err']**2 + row['B01001_015_err']**2 + row['B01001_016_err']**2 \n",
    "                                     + row['B01001_017_err']**2 + row['B01001_018_err']**2 + row['B01001_019_err']**2 \n",
    "                                     + row['B01001_020_err']**2 + row['B01001_021_err']**2 + row['B01001_022_err']**2 \n",
    "                                     + row['B01001_023_err']**2 + row['B01001_024_err']**2 + row['B01001_025_err']**2 \n",
    "                                     + row['B01001_035_err']**2 + row['B01001_036_err']**2 + row['B01001_037_err']**2 \n",
    "                                     + row['B01001_038_err']**2 + row['B01001_039_err']**2 + row['B01001_040_err']**2 \n",
    "                                     + row['B01001_041_err']**2 + row['B01001_042_err']**2 + row['B01001_043_err']**2 \n",
    "                                     + row['B01001_044_err']**2 + row['B01001_045_err']**2 + row['B01001_046_err']**2 \n",
    "                                     + row['B01001_047_err']**2 + row['B01001_048_err']**2 + row['B01001_049_err']**2 \n",
    "                                    ) / 1.645, errors='coerce')\n",
    "print('Defined standard-error-calculating functions!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating and renaming margins of error columns for IVs...\n",
      "...margins for race, owner-occupied units, mfi...\n",
      "...standard errors for hs graduates 25 and older (using custom serr-finding function...\n",
      "...margins of error for householder sex & race, unempoyment, poverty, home value, home age...\n",
      "\n",
      "calculating and renaming margins of error for comparison variables...\n",
      "...race, owner-occupied units, mfi...\n",
      "...population 25plus...\n",
      "...labor force, poverty status known...\n",
      "Calculated errors for all columns!\n"
     ]
    }
   ],
   "source": [
    "print('\\ncalculating and renaming margins of error columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins for race, owner-occupied units, mfi...')\n",
    "acs5_df = acs5_df.rename(columns = {\n",
    "    'B02001_002_err': 'pop_white_err',\n",
    "    'B02001_003_err': 'pop_black_err',\n",
    "    'B25003_002_err': 'owner_occ_housing_units_err',\n",
    "    'B19113_001_err': 'mfi_err'    \n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...standard errors for hs graduates 25 and older (using custom serr-finding function...')\n",
    "acs5_df = acs5_df.assign(hs_grad_25plus_serr = pandas.to_numeric(acs5_df.apply(lambda row: find_serr_hsgrad25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins of error for householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "acs5_df = acs5_df.rename(columns = {     \n",
    "    'B11001_006_err': 'female_householder_err',\n",
    "    'B11001B_001_err': 'black_householder_err',\n",
    "    'B11001H_001_err': 'white_householder_err',\n",
    "    'B23025_005_err': 'unemployed_16plus_err',\n",
    "    'B17001_002_err': 'poverty_past_12_months_err',\n",
    "    'B25077_001_err': 'median_home_value_err',\n",
    "    'B25035_001_err': 'median_year_built_err'\n",
    "})\n",
    "\n",
    "print('\\ncalculating and renaming margins of error for comparison variables...')\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "acs5_df = acs5_df.rename(columns = {\n",
    "    'B01001_001_err': 'pop_total_err',\n",
    "    'B11001_001_err': 'total_householders_err',\n",
    "    'B17001_001_err': 'poverty_status_known_err'\n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "acs5_df = acs5_df.assign(pop_25plus_serr = pandas.to_numeric(acs5_df.apply(lambda row: find_serr_pop25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...labor force, poverty status known...')\n",
    "acs5_df = acs5_df.rename(columns = {\n",
    "    'B23025_002_err': 'labor_force_16plus_err',\n",
    "    'B17001_001_err': 'poverty_status_known_err'\n",
    "})\n",
    "\n",
    "print('Calculated errors for all columns!')\n",
    "#reinvestment_df[['hs_grad_25plus', 'hs_grad_25plus_serr', 'pop_25plus', 'pop_25plus_serr']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join census data to loan+jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping columns we do not care about...\n",
      "calculating census tract and block group numbers...\n",
      "dropping block groups to avoid double-counting...\n",
      "setting index of both tables to do a year-by-year join...\n",
      "backing up...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('dropping columns we do not care about...')\n",
    "columns_do_not_care = ['B15002_011','B15002_012','B15002_013','B15002_014','B15002_015']\n",
    "columns_do_not_care += ['B15002_016','B15002_017','B15002_018','B15002_028','B15002_029']\n",
    "columns_do_not_care += ['B15002_030','B15002_031','B15002_032','B15002_033','B15002_034']\n",
    "columns_do_not_care += ['B15002_035','B01001_011','B01001_012','B01001_013','B01001_014']\n",
    "columns_do_not_care += ['B01001_015','B01001_016','B01001_017','B01001_018','B01001_019']\n",
    "columns_do_not_care += ['B01001_020','B01001_021','B01001_022','B01001_023','B01001_024']\n",
    "columns_do_not_care += ['B01001_025','B01001_035','B01001_036','B01001_037','B01001_038']\n",
    "columns_do_not_care += ['B01001_039','B01001_040','B01001_041','B01001_042','B01001_043']\n",
    "columns_do_not_care += ['B01001_044','B01001_045','B01001_046','B01001_047','B01001_048']\n",
    "columns_do_not_care += ['B01001_049','B15002_011_err','B15002_012_err','B15002_013_err']\n",
    "columns_do_not_care += ['B15002_014_err','B15002_015_err','B15002_016_err']\n",
    "columns_do_not_care += ['B15002_017_err','B15002_018_err','B15002_028_err']\n",
    "columns_do_not_care += ['B15002_029_err','B15002_030_err','B15002_031_err']\n",
    "columns_do_not_care += ['B15002_032_err','B15002_033_err','B15002_034_err']\n",
    "columns_do_not_care += ['B15002_035_err','B15002_011_err','B15002_012_err']\n",
    "columns_do_not_care += ['B15002_013_err','B15002_014_err','B15002_015_err']\n",
    "columns_do_not_care += ['B15002_016_err','B15002_017_err','B15002_018_err']\n",
    "columns_do_not_care += ['B15002_028_err','B15002_029_err','B15002_030_err']\n",
    "columns_do_not_care += ['B15002_031_err','B15002_032_err','B15002_033_err']\n",
    "columns_do_not_care += ['B15002_034_err','B15002_035_err','B01001_011_err']\n",
    "columns_do_not_care += ['B01001_012_err','B01001_013_err','B01001_014_err']\n",
    "columns_do_not_care += ['B01001_015_err','B01001_016_err','B01001_017_err']\n",
    "columns_do_not_care += ['B01001_018_err','B01001_019_err','B01001_020_err']\n",
    "columns_do_not_care += ['B01001_021_err','B01001_022_err','B01001_023_err']\n",
    "columns_do_not_care += ['B01001_024_err','B01001_025_err','B01001_035_err']\n",
    "columns_do_not_care += ['B01001_036_err','B01001_037_err','B01001_038_err']\n",
    "columns_do_not_care += ['B01001_039_err','B01001_040_err','B01001_041_err']\n",
    "columns_do_not_care += ['B01001_042_err','B01001_043_err','B01001_044_err']\n",
    "columns_do_not_care += ['B01001_045_err','B01001_046_err','B01001_047_err']\n",
    "columns_do_not_care += ['B01001_048_err','B01001_049_err','STATE']\n",
    "acs5_df = acs5_df.drop(columns_do_not_care, axis=1)\n",
    "\n",
    "print('calculating census tract and block group numbers...')\n",
    "acs5_df = acs5_df.assign(census_tract = np.nan)\n",
    "acs5_df = acs5_df.assign(block_group = np.nan)\n",
    "\n",
    "acs5_df.loc[:, 'census_tract'] = acs5_df['GEOID'].apply(lambda x: x[12:18])\n",
    "acs5_df.loc[:, 'census_tract'] = pandas.to_numeric(acs5_df['census_tract'], errors='coerce')\n",
    "acs5_df.loc[:, 'census_tract'] = acs5_df['census_tract'].apply(lambda x: x/100) # get right decimalization of census tracts\n",
    "acs5_df = acs5_df.assign(block_group = np.nan)\n",
    "acs5_df.loc[acs5_df['GEOID'].apply(lambda x:len(x)) == 19, \n",
    "            'block_group'] = acs5_df['GEOID'][acs5_df['GEOID'].apply(lambda x:len(x)) == 19].apply(lambda x: x[18])\n",
    "acs5_df.loc[:, 'block_group'] = pandas.to_numeric(acs5_df['block_group'], errors='coerce')\n",
    "\n",
    "print('dropping block groups to avoid double-counting...')\n",
    "acs5_df = acs5_df[acs5_df['block_group'].isnull()]  # select only census tracts (ignore block groups) to avoid double-counting\n",
    "acs5_df = acs5_df.drop('block_group', axis=1)\n",
    "\n",
    "print('setting index of both tables to do a year-by-year join...')\n",
    "acs5_df = acs5_df.set_index('census_tract')\n",
    "baltimore_agg_loans_df = baltimore_agg_loans_df.reset_index().set_index('census_tract')\n",
    "\n",
    "baltimore_tracts_years_df = pandas.DataFrame()\n",
    "theyears = baltimore_agg_loans_df['activity_year'].drop_duplicates().tolist()\n",
    "for x in theyears:\n",
    "    baltimore_tracts_years_df = pandas.concat((baltimore_tracts_years_df, \n",
    "                                               baltimore_agg_loans_df[baltimore_agg_loans_df['activity_year'] == x].join(acs5_df[acs5_df['year'] == x])\n",
    "                                              ), axis=0)\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.reset_index().set_index(['census_tract', 'activity_year'])\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.sort_index()\n",
    "\n",
    "print('backing up...')\n",
    "baltimore_tracts_years_df_bk = baltimore_tracts_years_df\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate percentages for needed demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pop_white',\n",
       " 'pop_black',\n",
       " 'black_householder',\n",
       " 'white_householder',\n",
       " 'owner_occ_housing_units',\n",
       " 'hs_grad_25plus',\n",
       " 'female_householder',\n",
       " 'unemployed_16plus',\n",
       " 'poverty_past_12_months',\n",
       " 'pop_white_err',\n",
       " 'pop_black_err',\n",
       " 'black_householder_err',\n",
       " 'white_householder_err',\n",
       " 'owner_occ_housing_units_err',\n",
       " 'hs_grad_25plus_serr',\n",
       " 'female_householder_err',\n",
       " 'unemployed_16plus_err',\n",
       " 'poverty_past_12_months_err',\n",
       " 'pop_total',\n",
       " 'total_householders',\n",
       " 'pop_25plus',\n",
       " 'labor_force_16plus',\n",
       " 'poverty_status_known',\n",
       " 'pop_total_err',\n",
       " 'total_householders_err',\n",
       " 'pop_25plus_serr',\n",
       " 'labor_force_16plus_err',\n",
       " 'poverty_status_known_err']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_for_percentification = ['pop_white', 'pop_black', 'black_householder', 'white_householder']\n",
    "vars_for_percentification += ['owner_occ_housing_units', 'hs_grad_25plus', 'female_householder']\n",
    "vars_for_percentification += ['unemployed_16plus', 'poverty_past_12_months']\n",
    "\n",
    "vars_for_percentification += ['pop_white_err', 'pop_black_err', 'black_householder_err', 'white_householder_err']\n",
    "vars_for_percentification += ['owner_occ_housing_units_err', 'hs_grad_25plus_serr', 'female_householder_err']\n",
    "vars_for_percentification += ['unemployed_16plus_err', 'poverty_past_12_months_err']\n",
    "\n",
    "vars_for_percentification += ['pop_total', 'total_householders', 'pop_25plus', 'labor_force_16plus']\n",
    "vars_for_percentification += ['poverty_status_known']\n",
    "\n",
    "vars_for_percentification += ['pop_total_err', 'total_householders_err', 'pop_25plus_serr', 'labor_force_16plus_err']\n",
    "vars_for_percentification += ['poverty_status_known_err']\n",
    "\n",
    "baltimore_tracts_years_df[vars_for_percentification].columns.tolist()\n",
    "#print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "census_tract  activity_year\n",
       "101.00        2011             0.924555\n",
       "              2012             0.941853\n",
       "              2013             0.944095\n",
       "              2014             0.915238\n",
       "              2015             0.906877\n",
       "              2016             0.898929\n",
       "              2017             0.884099\n",
       "102.00        2011             0.831728\n",
       "              2012             0.730096\n",
       "              2013             0.754756\n",
       "              2014             0.837133\n",
       "              2015             0.804982\n",
       "              2016             0.822929\n",
       "              2017             0.882353\n",
       "103.00        2011             0.881521\n",
       "              2012             0.924419\n",
       "              2013             0.920729\n",
       "              2014             0.904184\n",
       "              2015             0.907987\n",
       "              2016             0.908834\n",
       "              2017             0.893417\n",
       "104.00        2011             0.931542\n",
       "              2012             0.910345\n",
       "              2013             0.906136\n",
       "              2014             0.907244\n",
       "              2015             0.884632\n",
       "              2016             0.868619\n",
       "              2017             0.872522\n",
       "105.00        2011             0.885807\n",
       "              2012             0.917969\n",
       "                                 ...   \n",
       "2804.01       2015             0.121386\n",
       "              2016             0.135391\n",
       "              2017             0.161120\n",
       "2804.02       2011             0.000000\n",
       "              2012             0.000000\n",
       "              2013             0.003279\n",
       "              2014             0.004865\n",
       "              2015             0.004184\n",
       "              2016             0.008513\n",
       "              2017             0.006035\n",
       "2804.03       2011             0.257829\n",
       "              2012             0.240864\n",
       "              2013             0.237295\n",
       "              2014             0.246902\n",
       "              2015             0.265634\n",
       "              2016             0.249458\n",
       "              2017             0.293684\n",
       "2804.04       2011             0.048528\n",
       "              2012             0.048639\n",
       "              2013             0.043135\n",
       "              2014             0.040541\n",
       "              2015             0.033333\n",
       "              2016             0.038977\n",
       "              2017             0.042080\n",
       "2805.00       2012             0.053802\n",
       "              2013             0.089708\n",
       "              2014             0.102819\n",
       "              2015             0.105810\n",
       "              2016             0.103270\n",
       "              2017             0.102791\n",
       "Name: pct_white, Length: 1388, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df_bk\n",
    "#[x for x in vars_for_percentification if \"_err\" not in x]\n",
    "\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(pct_white = pandas.to_numeric((baltimore_tracts_years_df['pop_white'] / baltimore_tracts_years_df['pop_total']), errors='coerce'))\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(pct_black = pandas.to_numeric((baltimore_tracts_years_df['pop_black'] / baltimore_tracts_years_df['pop_total']), errors='coerce'))\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(pct_white_householders = pandas.to_numeric((baltimore_tracts_years_df['pop_white'] / baltimore_tracts_years_df['pop_total']), errors='coerce'))\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(pct_black_householders = pandas.to_numeric((baltimore_tracts_years_df['pop_black'] / baltimore_tracts_years_df['pop_total']), errors='coerce'))\n",
    "\n",
    "baltimore_tracts_years_df['pct_white']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest']\n",
    "money_columns += ['amtLoans', 'amtWorkingLoans']\n",
    "money_columns += ['mfi', 'median_home_value']\n",
    "money_columns += ['amtLoans1_per_totaljob', 'amtLoans100k_per_totaljob']\n",
    "money_columns += ['amtLoans250k_per_totaljob', 'amtLoansToSmallest_per_totaljob']\n",
    "money_columns += ['amtLoans_per_totaljob', 'amtWorkingLoans_per_totaljob']\n",
    "money_columns += ['amtLoans1_per_sbjob', 'amtLoans100k_per_sbjob']\n",
    "money_columns += ['amtLoans250k_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "money_columns += ['amtLoans_per_sbjob', 'amtWorkingLoans_per_sbjob']\n",
    "\n",
    "print('getting inflation data...')\n",
    "cpi_1913_2017_df = pandas.read_csv(inflation_dir+'cpi-1913-2017.csv', index_col='Year')\n",
    "cpi_annual_s = cpi_1913_2017_df['Jan']\n",
    "cpi_annual_s.name = 'rawfactor'\n",
    "value_in_2017 = cpi_annual_s.loc[2017]\n",
    "\n",
    "annual_inflator_s = 1 / (cpi_annual_s / value_in_2017)\n",
    "print('inflating pre-2017 monetary values...')\n",
    "inflate_these_df = baltimore_tracts_years_df[money_columns]\n",
    "newcolnames = [x+'_adj' for x in inflate_these_df.columns.tolist()]\n",
    "inflate_these_df.columns = newcolnames\n",
    "\n",
    "inflated_df = pandas.DataFrame()\n",
    "for i in inflate_these_df.index.get_level_values(1).drop_duplicates().tolist():\n",
    "    inflated_df_i = inflate_these_df.xs(i, level=1).apply(lambda x: x * annual_inflator_s.loc[i])\n",
    "    inflated_df_i['activity_year'] = i\n",
    "    inflated_df = pandas.concat((inflated_df, inflated_df_i), axis=0)\n",
    "inflated_df = inflated_df.reset_index().set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('joining inflated money columns to the rest of the columns...')\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.join(inflated_df, how='left')\n",
    "\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add codes (e.g. CSA, income group...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add community statistical area names\n",
    "print('Matching community statistical areas...')\n",
    "tract_to_csa_df = pandas.read_csv(baltimore_dir+'census_tract_to_neighborhood.csv', index_col='NAME10')\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.reset_index().merge(tract_to_csa_df.reset_index(), how='left', left_on='census_tract', right_on='NAME10').set_index(['census_tract', 'activity_year'])\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.drop(['NAME10', 'TRACTCE10', 'GEOID10'], axis=1)\n",
    "\n",
    "print('Decoding income group names...')\n",
    "# Get income group names\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.rename(columns = {'income_group_total': 'income_group_code'})\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(income_group = np.nan)\n",
    "\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "baltimore_tracts_years_df.loc[baltimore_tracts_years_df['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "\n",
    "print('Decoding income levels (low/moderate/middle/upper/unknown)...')\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "baltimore_tracts_years_df = baltimore_tracts_years_df.assign(cra_level = np.nan)\n",
    "baltimore_tracts_years_df.loc[(baltimore_tracts_years_df['income_group_code'] >= 1) & (baltimore_tracts_years_df['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "baltimore_tracts_years_df.loc[(baltimore_tracts_years_df['income_group_code'] >= 6) & (baltimore_tracts_years_df['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "baltimore_tracts_years_df.loc[(baltimore_tracts_years_df['income_group_code'] >= 9) & (baltimore_tracts_years_df['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "baltimore_tracts_years_df.loc[(baltimore_tracts_years_df['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "baltimore_tracts_years_df.loc[(baltimore_tracts_years_df['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "print('Writing out...')\n",
    "baltimore_tracts_years_df.to_csv(baltimore_dir+'baltimore_alldata.csv', encoding='utf-8')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
