{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "Now in directory: /home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "debug = 1\n",
    "city = \"Baltimore\" # Possible values: Baltimore, Washington DC, Detroit, Newark, St. Louis, Richmond, San Francisco, Cleveland, Philadelphia, Pittsburgh\n",
    "g = 0\n",
    "\n",
    "latest_year = 2019\n",
    "earliest_year = 2010\n",
    "\n",
    "check_tract_and_city_boundaries = False\n",
    "check_tract_consistency = False\n",
    "show_water = False\n",
    "\n",
    "print('Importing packages...')\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "#import zipfile\n",
    "import geopandas\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.patches as mpatches\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "# Directories to look in\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch/'\n",
    "jobs_dir = data_dir + 'lodes_wac/'\n",
    "\n",
    "#census_dir = data_dir + 'acs5/'\n",
    "\n",
    "output_data_dir = thisdir + 'final_data/'\n",
    "#baltimore_dir = thisdir + 'baltimore/'\n",
    "\n",
    "census_shapefile_tiger_basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/shapefiles/'\n",
    "\n",
    "#shapefile_dir = census_shapefile_tiger_basedir + '{0:.0f}/TRACT/'.format(thisyear)\n",
    "\n",
    "acs5_basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "\n",
    "code_lookup_dir = thisdir + 'code_guide_lookups/'\n",
    "inflation_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/inflation/'\n",
    "extrasdir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "city_data_dir = thisdir + 'city_data/'\n",
    "scale = 1\n",
    "\n",
    "equal_area_epsg = 5070\n",
    "\n",
    "os.chdir(thisdir)\n",
    "g = 0 # global time\n",
    "\n",
    "print('Now in directory: {0:}'.format(os.getcwd()))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Baltimore!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "years = np.arange(latest_year, earliest_year-1, -1)\n",
    "\n",
    "if (city == 'Baltimore'):\n",
    "    thestate = 24\n",
    "    state_abbrev = 'md'\n",
    "    citycode = 4000\n",
    "    baltimore_shapefile_dir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "    plotlimits = {'N': 39.38, 'S': 39.195, 'W': -76.745, 'E': -76.505}\n",
    "\n",
    "elif (city == 'Washington DC'):\n",
    "    thestate = 11   # state_codes_df[state_codes_df['STATE_NAME'] == 'Missouri']\n",
    "    state_abbrev = 'dc'\n",
    "    citycode = 50000\n",
    "    plotlimits = {'N': 39.01, 'S': 38.79, 'E': -76.9, 'W': -77.13}\n",
    "\n",
    "elif (city == 'Detroit'):\n",
    "    thestate = 26   # state_codes_df[state_codes_df['STATE_NAME'] == 'Missouri']\n",
    "    state_abbrev = 'mi'\n",
    "    citycode = 22000\n",
    "    plotlimits = {'N': 42.5, 'S': 42.2, 'E': -82.8, 'W': -83.3}\n",
    "    \n",
    "elif (city == 'Newark'):\n",
    "    thestate = 34\n",
    "    state_abbrev = 'nj'\n",
    "    citycode = 51000\n",
    "    \n",
    "elif (city == 'St. Louis'):\n",
    "    thestate = 29   # state_codes_df[state_codes_df['STATE_NAME'] == 'Missouri']\n",
    "    state_abbrev = 'mo'\n",
    "    citycode = 65000\n",
    "    plotlimits = {'N': 38.8, 'S': 38.5, 'E': -90.1, 'W': -90.4}\n",
    "#    cityname_file = 'st_louis'\n",
    "    \n",
    "elif (city == 'Richmond'):\n",
    "    thestate = 47   # state_codes_df[state_codes_df['STATE_NAME'] == 'Missouri']\n",
    "    state_abbrev = 'va'\n",
    "    citycode = 67000\n",
    "    #thecounty = 760\n",
    "#    cityname_file = 'richmond'\n",
    "    \n",
    "elif (city == 'San Francisco'):\n",
    "    thestate = 5   # state_codes_df[state_codes_df['STATE_NAME'] == 'California']\n",
    "    state_abbrev = 'ca'\n",
    "    #thecounty = 75\n",
    "    citycode = 67000\n",
    "    cityname_file = 'san_francisco'\n",
    "    \n",
    "elif (city == 'Pittsburgh'):\n",
    "    thestate = 42\n",
    "    state_abbrev = 'pa'\n",
    "    citycode = 61000\n",
    "    plotlimits = {'N': 40.55, 'S': 40.3, 'E': -79.85, 'W': -80.15}\n",
    "\n",
    "elif (city == 'Cleveland'):\n",
    "    thestate = 39\n",
    "    state_abbrev = 'oh'\n",
    "    citycode = 16000\n",
    "    plotlimits = {'N': 41.65, 'S': 41.35, 'E': -81.5, 'W': -81.9}\n",
    "    \n",
    "elif (city == 'Philadelphia'):\n",
    "    thestate = 42\n",
    "    state_abbrev = 'pa'\n",
    "    #thecounty = 101\n",
    "    citycode = 60000\n",
    "    plotlimits = {'N': 40.15, 'S': 39.85, 'E': -74.93, 'W': -75.3}\n",
    "else:\n",
    "    print('ERROR: Select city from list!')\n",
    "\n",
    "cityname_file = city.lower().replace(' ','_')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Selected {0:}!'.format(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do city boundaries line up with census tract boundaries?\n",
    "\n",
    "Baltimore: Yes\n",
    "Washington, DC: Yes\n",
    "Detroit: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 2019 census tracts and places in md...\n",
      "\tMatching Baltimore 2019 data (city area = 238.4 square km)...\n",
      "Parsing 2018 census tracts and places in md...\n",
      "\tMatching Baltimore 2018 data (city area = 238.4 square km)...\n",
      "Parsing 2017 census tracts and places in md...\n",
      "\tMatching Baltimore 2017 data (city area = 238.4 square km)...\n",
      "Parsing 2016 census tracts and places in md...\n",
      "\tMatching Baltimore 2016 data (city area = 238.4 square km)...\n",
      "Parsing 2015 census tracts and places in md...\n",
      "\tMatching Baltimore 2015 data (city area = 238.4 square km)...\n",
      "Parsing 2014 census tracts and places in md...\n",
      "\tMatching Baltimore 2014 data (city area = 238.4 square km)...\n",
      "Parsing 2013 census tracts and places in md...\n",
      "\tMatching Baltimore 2013 data (city area = 238.4 square km)...\n",
      "Parsing 2012 census tracts and places in md...\n",
      "\tMatching Baltimore 2012 data (city area = 238.4 square km)...\n",
      "Parsing 2011 census tracts and places in md...\n",
      "\tMatching Baltimore 2011 data (city area = 238.4 square km)...\n",
      "Parsing 2010 census tracts and places in md...\n",
      "\tMatching Baltimore 2010 data (city area = 238.4 square km)...\n",
      "Found 2,000 tract-years in 33 seconds!\n"
     ]
    }
   ],
   "source": [
    "# city = \"Baltimore\"\n",
    "#     thestate = 24\n",
    "#     state_abbrev = 'md'\n",
    "#     citycode = 4000\n",
    "#     baltimore_shapefile_dir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "#     plotlimits = {'N': 39.4, 'S': 39.15, 'E': -76.5, 'W': -76.75}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "show_year = 2010\n",
    "city_tracts_years_gdf = geopandas.GeoDataFrame()#data=None, columns=state_tracts_this_year_gdf, crs=state_tracts_this_year_gdf.crs, geometry='geometry')\n",
    "\n",
    "for thisyear in years:\n",
    "    print('Parsing {0:.0f} census tracts and places in {1:}...'.format(thisyear, state_abbrev))\n",
    "    if (thisyear == 2010):\n",
    "        state_tracts_this_year_gdf = geopandas.read_file(census_shapefile_tiger_basedir +'{0:.0f}/TRACT/tl_{0:.0f}_{1:02d}_tract10.shp'.format(thisyear, thestate))#.set_index('GEOID')\n",
    "        for x in state_tracts_this_year_gdf.columns[:-1]:\n",
    "            state_tracts_this_year_gdf = state_tracts_this_year_gdf.rename(columns = {x: x[:-2]})\n",
    "        state_tracts_this_year_gdf = state_tracts_this_year_gdf.set_index('GEOID')\n",
    "    else:\n",
    "        state_tracts_this_year_gdf = geopandas.read_file(census_shapefile_tiger_basedir +'{0:.0f}/TRACT/tl_{0:.0f}_{1:02d}_tract.shp'.format(thisyear, thestate)).set_index('GEOID')\n",
    "\n",
    "    if (check_tract_and_city_boundaries):\n",
    "        if (thisyear == show_year):    \n",
    "            state_tracts_show_year_gdf = state_tracts_this_year_gdf\n",
    "        \n",
    "    ntracts_this_state_year = len(state_tracts_this_year_gdf)    \n",
    "    city_tracts_this_year_gdf = geopandas.GeoDataFrame(data=None, columns=state_tracts_this_year_gdf.columns, crs=state_tracts_this_year_gdf.crs, geometry='geometry')\n",
    "    if (thisyear == 2010):\n",
    "        state_places_this_year_gdf = geopandas.read_file(census_shapefile_tiger_basedir + '{0:.0f}/PLACE/tl_{0:.0f}_{1:.0f}_place10.shp'.format(thisyear, thestate))#.set_index('GEOID')\n",
    "        for x in state_places_this_year_gdf.columns[:-1]:\n",
    "            state_places_this_year_gdf = state_places_this_year_gdf.rename(columns = {x: x[:-2]})\n",
    "        state_places_this_year_gdf = state_places_this_year_gdf.set_index('GEOID')\n",
    "    else:\n",
    "        state_places_this_year_gdf = geopandas.read_file(census_shapefile_tiger_basedir + '{0:.0f}/PLACE/tl_{0:.0f}_{1:.0f}_place.shp'.format(thisyear, thestate)).set_index('GEOID')\n",
    "\n",
    "    if (check_tract_and_city_boundaries):\n",
    "        if (thisyear == show_year):    \n",
    "            state_places_show_year_gdf = state_places_this_year_gdf\n",
    "    \n",
    "    if (len(state_places_this_year_gdf[state_places_this_year_gdf['PLACEFP'] == '{0:05d}'.format(citycode)].geometry.values) == 1):\n",
    "        city_year_geo = state_places_this_year_gdf[state_places_this_year_gdf['PLACEFP'] == '{0:05d}'.format(citycode)].geometry.values[0]\n",
    "        city_year_area_sq_m = state_places_this_year_gdf[state_places_this_year_gdf['PLACEFP'] == '{0:05d}'.format(citycode)].to_crs(epsg=equal_area_epsg).geometry.area.values[0]\n",
    "        print('\\tMatching {0:} {1:.0f} data (city area = {2:,.1f} square km)...'.format(city, thisyear, city_year_area_sq_m/(1000**2)))\n",
    "    else:\n",
    "        print('wtf, this city has more than one geometry included?')\n",
    "\n",
    "    cnt = 0\n",
    "    for ix, thisrow in state_tracts_this_year_gdf.iterrows():\n",
    "#         if (np.mod(cnt,100) == 0):\n",
    "#             print('\\t\\tMatching tract {0:,.0f} of {1:,.0f}...'.format(cnt, ntracts_this_state_year))\n",
    "        if (thisrow.geometry.intersects(city_year_geo)):        \n",
    "            intersection_geo = state_tracts_this_year_gdf.loc[ix].geometry.intersection(city_year_geo)\n",
    "            pct_overlap = intersection_geo.area / thisrow.geometry.area\n",
    "            if (pct_overlap >= 0.995):\n",
    "                city_tracts_this_year_gdf = pandas.concat((city_tracts_this_year_gdf, state_tracts_this_year_gdf[state_tracts_this_year_gdf.index == ix]), axis=0)\n",
    "            elif (pct_overlap >= 0.01):\n",
    "                intersection_gdf = geopandas.GeoDataFrame(data=[[intersection_geo]], columns=['geometry'], crs=state_tracts_this_year_gdf.crs, geometry='geometry')\n",
    "                tract_total_area_sq_m = state_tracts_this_year_gdf.to_crs(epsg=equal_area_epsg).loc[ix].geometry.area\n",
    "                intersection_area_sq_m = intersection_gdf.to_crs(epsg=equal_area_epsg).geometry.apply(lambda x: x.area).values[0]\n",
    "                pct_overlap_sq_m = intersection_area_sq_m / tract_total_area_sq_m        \n",
    "                print('PARTIAL overlap found: County {0:} Tract {1:}\\n\\tTotal area {2:,.1f} sq km, overlap area {3:,.1f} sq km ({4:})'.format(thisrow['COUNTYFP'], thisrow['TRACTCE'], tract_total_area_sq_m/1000000, intersection_area_sq_m/1000000, pct_overlap_sq_m))\n",
    "        cnt += 1\n",
    "    city_tracts_this_year_gdf = city_tracts_this_year_gdf.assign(year = thisyear)\n",
    "    city_tracts_years_gdf = pandas.concat((city_tracts_years_gdf, city_tracts_this_year_gdf), axis=0)\n",
    "\n",
    "city_tracts_years_gdf.loc[:, 'STATEFP'] = pandas.to_numeric(city_tracts_years_gdf['STATEFP'], errors='coerce')\n",
    "city_tracts_years_gdf.loc[:, 'COUNTYFP'] = pandas.to_numeric(city_tracts_years_gdf['COUNTYFP'], errors='coerce')\n",
    "city_tracts_years_gdf.loc[:, 'TRACTCE'] = pandas.to_numeric(city_tracts_years_gdf['TRACTCE'].apply(lambda x: '{0:}.{1:}'.format(x[0:-2],x[-2:])), errors='coerce')\n",
    "for x in ['ALAND', 'AWATER', 'INTPTLAT','INTPTLON']:\n",
    "    city_tracts_years_gdf.loc[:, x] = pandas.to_numeric(city_tracts_years_gdf[x], errors='coerce')\n",
    "\n",
    "city_tracts_years_gdf = city_tracts_years_gdf.rename(columns={'COUNTYFP': 'county', 'TRACTCE': 'census_tract'})\n",
    "city_tracts_years_gdf.index.name = 'GEOID'\n",
    "city_tracts_years_gdf = city_tracts_years_gdf.reset_index()\n",
    "city_tracts_years_gdf.loc[:, 'GEOID'] = city_tracts_years_gdf['GEOID'].apply(lambda x: '14000US'+x)\n",
    "city_tracts_years_gdf = city_tracts_years_gdf.set_index(['GEOID','year'])\n",
    "\n",
    "\n",
    "if (check_tract_and_city_boundaries):\n",
    "    print('plotting tract vs city for {0:.0f}...'.format(show_year))\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "    state_tracts_show_year_gdf.plot(color='none', edgecolor='black', ax=ax)    \n",
    "    state_places_show_year_gdf[state_places_show_year_gdf['PLACEFP'] == '{0:05d}'.format(citycode)].plot(ax=ax, color='none', edgecolor='yellow', lw=5)\n",
    "\n",
    "    city_tracts_years_gdf.xs(show_year, level='year').plot(ax=ax, color='pink', alpha=0.5)\n",
    "    if (show_water):\n",
    "        print('\\treading water files...')\n",
    "        water_dir = census_shapefile_tiger_basedir+\"{0:.0f}/AREAWATER/\".format(show_year)\n",
    "        water_files = [water_dir+x for x in os.listdir(water_dir) if ('tl_{0:.0f}_{1:02d}'.format(show_year,thestate) in x) and (x[-3:] == 'shp')]\n",
    "        water_gdf = geopandas.GeoDataFrame()\n",
    "        for i in range(0, len(water_files)):\n",
    "            if ((np.mod(i,10) == 0) | (i == len(water_files)-1)):\n",
    "                print('\\t\\treading water file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_files)))\n",
    "            water_gdf = pandas.concat((water_gdf, geopandas.read_file(water_files[i])))\n",
    "        water_gdf.plot(ax=ax, color='blue')\n",
    "\n",
    "    plt.xlim([plotlimits['W'], plotlimits['E']])\n",
    "    plt.ylim([plotlimits['S'], plotlimits['N']])\n",
    "    plt.title('{0:.0f}'.format(show_year), size=24)\n",
    "    \n",
    "    plt.show()\n",
    "#city_tracts_years_gdf\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Found {0:,.0f} tract-years in {1:,.0f} seconds!'.format(len(city_tracts_years_gdf), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure that tract boundaries remain constant throughout the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicated or unique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County 510 contains 2,000 tract-years:\n",
      "2019: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2018: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2017: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2016: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2015: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2014: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2013: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2012: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2011: 200 tracts\n",
      "\tAll census tracts match!\n",
      "2010: 200 tracts\n",
      "\tAll census tracts match!\n",
      "Checked consistency of 2,000 tract-years in 0 minutes 2 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "test_year = 2010\n",
    "test_color = 'cyan'\n",
    "control_year = 2019\n",
    "control_edge_color = 'red'\n",
    "\n",
    "legend_location = 'lower left'\n",
    "\n",
    "# print('getting from backup...')\n",
    "# city_tracts_years_gdf = city_tracts_years_gdf_bk\n",
    "\n",
    "\n",
    "counties_list = city_tracts_years_gdf['county'].drop_duplicates().tolist()\n",
    "\n",
    "#print('{0:} covers {1:,.0f} county...'.format(city, len(counties_list)))\n",
    "#city_tracts_years_gdf.head(1).T\n",
    "for x in counties_list:\n",
    "    print('County {0:,.0f} contains {1:,.0f} tract-years:'.format(x, len(city_tracts_years_gdf.reset_index()[city_tracts_years_gdf.reset_index()['county'] == x])))\n",
    "    for i in years:\n",
    "        print('{0:.0f}: {1:,.0f} tracts'.format(\n",
    "            i, \n",
    "            len(city_tracts_years_gdf.reset_index()[\n",
    "                (city_tracts_years_gdf.reset_index()['county'] == x) \n",
    "                & (city_tracts_years_gdf.reset_index()['year'] == i)])\n",
    "        ))\n",
    "        county_x_year_control_census_tracts_list = city_tracts_years_gdf.reset_index()[\n",
    "            (city_tracts_years_gdf.reset_index()['county'] == x) \n",
    "            & (city_tracts_years_gdf.reset_index()['year'] == control_year)\n",
    "        ]['NAME'].tolist()\n",
    "        \n",
    "        county_x_year_i_census_tracts_list = city_tracts_years_gdf.reset_index()[\n",
    "            (city_tracts_years_gdf.reset_index()['county'] == x) \n",
    "            & (city_tracts_years_gdf.reset_index()['year'] == i)\n",
    "        ]['NAME'].tolist()\n",
    "        #print(county_x_year_i_census_tracts_list)\n",
    "        \n",
    "        new_census_tracts = []\n",
    "        missing_census_tracts = []\n",
    "        \n",
    "        for n in county_x_year_i_census_tracts_list:\n",
    "            if (n not in county_x_year_control_census_tracts_list):\n",
    "                new_census_tracts.append(n)\n",
    "            for p in county_x_year_control_census_tracts_list:\n",
    "                if (p not in county_x_year_i_census_tracts_list):\n",
    "                    missing_census_tracts.append(n)\n",
    "        for y in new_census_tracts:\n",
    "            print('Found census tract in {0:.0f} that is not present in 2018: {1:}'.format(i,y))\n",
    "        for z in missing_census_tracts:\n",
    "            print('Found census tract from 2018 that was not present in {0:.0f}: {1:}'.format(i,z))\n",
    "        if (len(new_census_tracts) + len(missing_census_tracts) == 0):\n",
    "            print('\\tAll census tracts match!')\n",
    "        else:\n",
    "            print('\\n')\n",
    "legend_list = []\n",
    "if (check_tract_consistency):\n",
    "    print('Plotting tracts for potential border differences...')\n",
    "    fig, ax = plt.subplots(1,1, figsize=(48*scale,48*scale))\n",
    "    \n",
    "    city_tracts_years_gdf.xs(test_year, level='year').plot(ax=ax, color=test_color, edgecolor='black')\n",
    "    city_tracts_years_gdf.xs(control_year, level='year').plot(ax=ax, color='none', edgecolor=control_edge_color, lw=3*scale)\n",
    "    \n",
    "    \n",
    "    legend_list.append(mpatches.Patch(facecolor=test_color, edgecolor='black', lw=3*scale, label='{0:}'.format(test_year)))\n",
    "    legend_list.append(mpatches.Patch(facecolor='none', edgecolor=control_edge_color, lw=3*scale, label='{0:}'.format(control_year)))\n",
    "    \n",
    "    if (show_water):\n",
    "        print('\\treading water files...')\n",
    "        water_dir = census_shapefile_tiger_basedir+\"{0:.0f}/AREAWATER/\".format(show_year)\n",
    "        water_files = [water_dir+x for x in os.listdir(water_dir) if ('tl_{0:.0f}_{1:02d}'.format(show_year,thestate) in x) and (x[-3:] == 'shp')]\n",
    "        water_gdf = geopandas.GeoDataFrame()\n",
    "        for i in range(0, len(water_files)):\n",
    "            if ((np.mod(i,10) == 0) | (i == len(water_files)-1)):\n",
    "                print('\\t\\treading water file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_files)))\n",
    "            water_gdf = pandas.concat((water_gdf, geopandas.read_file(water_files[i])))\n",
    "        water_gdf.plot(ax=ax, color='blue')\n",
    "    \n",
    "#     # #city_tracts_years_gdf.loc[[2012, 35, 1711.03]].geometry.plot()#.plot(color='red')\n",
    "#     for ix, thisrow in city_tracts_years_gdf.xs(otheryear, level=-1).iterrows():\n",
    "#         if (ix[1] in new_census_tracts):\n",
    "#             annotator = ix[1]\n",
    "#             ax.annotate(annotator, \n",
    "#                        xy=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "#                        xytext=(thisrow.geometry.centroid.x,#+0.01*np.random.rand(), \n",
    "#                                thisrow.geometry.centroid.y),#+0.01*np.random.rand()), \n",
    "#                        backgroundcolor = 'white', horizontalalignment='center', verticalalignment='center',\n",
    "#                        fontsize=24*scale)\n",
    "\n",
    "    \n",
    "    ax.legend(handles=legend_list, fontsize=48*scale, loc=legend_location)\n",
    "    plt.title('{0:.0f} compared to {1:.0f}'.format(test_year, control_year), fontsize=48*scale)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24*scale)\n",
    "    plt.xlim([plotlimits['W'], plotlimits['E']])\n",
    "    plt.ylim([plotlimits['S'], plotlimits['N']])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Checked consistency of {0:,.0f} tract-years in {1:,.0f} minutes {2:,.0f} seconds!'.format(len(city_tracts_years_gdf), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Have the centroids or areas of any tracts changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for this_oneyear_index in tracts_to_label:\n",
    "#     print('county {0:.0f}, tract {1:.2f}:'.format(this_oneyear_index[0],this_oneyear_index[1]))\n",
    "#     print('\\tcentroids differ by {0:.2e}'.format(city_tracts_years_gdf.xs(oneyear, level=-1).loc[this_oneyear_index].geometry.centroid.distance(city_tracts_years_gdf.xs(otheryear, level=-1).loc[this_oneyear_index].geometry.centroid)))\n",
    "#     print('\\tareas differ by {0:.2e}'.format(np.abs(city_tracts_years_gdf.xs(oneyear, level=-1).loc[this_oneyear_index].geometry.area - city_tracts_years_gdf.xs(otheryear, level=-1).loc[this_oneyear_index].geometry.area)))\n",
    "#     print('\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# fig, ax = plt.subplots(1,1, figsize=(48*scale, 48*scale))\n",
    "# city_tracts_years_gdf.xs(oneyear, level=-1).plot(ax=ax, color='none', edgecolor='black')\n",
    "# city_tracts_years_gdf.xs(otheryear, level=-1).plot(ax=ax, color='none', edgecolor='red')\n",
    "# # if (show_water):\n",
    "# #     print('reading water files...')\n",
    "# #     water_dir = census_shapefile_tiger_basedir+\"{0:.0f}/AREAWATER/\".format(show_year)\n",
    "# #     water_files = [water_dir+x for x in os.listdir(water_dir) if ('tl_{0:.0f}_{1:02d}'.format(show_year,thestate) in x) and (x[-3:] == 'shp')]\n",
    "# #     water_gdf = geopandas.GeoDataFrame()\n",
    "# #     for i in range(0, len(water_files)):\n",
    "# #         if ((np.mod(i,10) == 0) | (i == len(water_files)-1)):\n",
    "# #             print('\\treading water file {0:,.0f} of {1:,.0f}...'.format(i+1, len(water_files)))\n",
    "# #     water_gdf = pandas.concat((water_gdf, geopandas.read_file(water_files[i])))\n",
    "# #     water_gdf.plot(ax=ax)\n",
    "\n",
    "# # for ix, thisrow in city_tracts_years_gdf.xs(oneyear, level=-1).loc[tracts_to_label].iterrows():\n",
    "# #     annotator = ix\n",
    "# #     ax.annotate(annotator, \n",
    "# #                 xy=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "# #                 xytext=(thisrow.geometry.centroid.x,#+0.01*np.random.rand(), \n",
    "# #                         thisrow.geometry.centroid.y),#+0.01*np.random.rand()), \n",
    "# #                 backgroundcolor = 'white', horizontalalignment='center', verticalalignment='center',\n",
    "# #                 fontsize=24*scale)\n",
    "\n",
    "# plt.xlim([plotlimits['W'], plotlimits['E']])\n",
    "# plt.ylim([plotlimits['S'], plotlimits['N']])\n",
    "# plt.title('{0:.0f} (black) vs {1:.0f} (red)'.format(oneyear, otheryear), size=48*scale)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('finding tracts with different centroids and/or areas...')\n",
    "\n",
    "# centroid_tolerance_meters = 100\n",
    "# area_tolerance_square__meters = 1000\n",
    "\n",
    "# tracts_to_label = []\n",
    "# cnt = 1\n",
    "# for this_oneyear_index in city_tracts_years_gdf.xs(oneyear, level=-1).index.values:\n",
    "#     if (np.mod(cnt-1,50) == 0):\n",
    "#         print('Checking tract {0:.0f} of {1:.0f}...'.format(cnt, len(city_tracts_years_gdf.xs(oneyear, level=-1).index.values)))\n",
    "#     centroid_offset_meters = city_tracts_years_gdf.xs(oneyear, level=-1).to_crs(epsg=2272).loc[this_oneyear_index].geometry.centroid.distance(city_tracts_years_gdf.xs(otheryear, level=-1).to_crs(epsg=2272).loc[this_oneyear_index].geometry.centroid)\n",
    "#     area_difference_square_meters = np.abs(city_tracts_years_gdf.xs(oneyear, level=-1).to_crs(epsg=2272).loc[this_oneyear_index].geometry.area - city_tracts_years_gdf.xs(otheryear, level=-1).to_crs(epsg=2272).loc[this_oneyear_index].geometry.area)\n",
    "#     #print(this_oneyear_index)\n",
    "#     if ((centroid_offset_meters >= centroid_tolerance_meters) | (area_difference_square_meters >= area_tolerance_square__meters)):\n",
    "#         print('\\tCounty {0:} tract {1:} ({2:} vs. {3:}): centroid offset is {4:.1f} meters; area difference is {5:,.0f} square meters..'.format(this_oneyear_index[0], this_oneyear_index[1], oneyear, otheryear, centroid_offset_meters, area_difference_square_meters))\n",
    "#     cnt = cnt + 1\n",
    "# #     oneyear_tract_centroid = city_tracts_years_gdf.xs(oneyear, level=-1).loc[this_oneyear_index].geometry.centroid\n",
    "# #     otheryear_tract_centroid = city_tracts_years_gdf.xs(otheryear, level=-1).loc[this_oneyear_index].geometry.centroid\n",
    "# #     oneyear_tract_area = city_tracts_years_gdf.xs(oneyear, level=-1).loc[this_oneyear_index].geometry.area\n",
    "# #     otheryear_tract_area = city_tracts_years_gdf.xs(otheryear, level=-1).loc[this_oneyear_index].geometry.area\n",
    "# #     if ((oneyear_tract_centroid.distance(otheryear_tract_centroid) > centroid_tolerance) & (np.abs(oneyear_tract_area - otheryear_tract_area) > area_tolerance)):\n",
    "# #         if (this_oneyear_index not in tracts_to_label):\n",
    "# #             tracts_to_label.append(this_oneyear_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get geo-aggregated loans for this city\n",
    "\n",
    "and join the tract data onto the loans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading nationwide data...\n",
      "Read 3,046,200 nationwide tract-years in 12 seconds...\n",
      "converting columns to numeric...\n",
      "calculating total loans...\n",
      "Kept 2,000 tract-years in 15 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# city_tracts_years_gdf = city_tracts_years_gdf_bk\n",
    "\n",
    "print('reading nationwide data...')\n",
    "agg_loans_all_df = pandas.read_csv(data_dir+'agg_loans.csv', encoding='utf-8', low_memory=False, index_col='rownumber', keep_default_na=False)\n",
    "e = time.time()\n",
    "print('Read {0:,.0f} nationwide tract-years in {1:,.0f} seconds...'.format(len(agg_loans_all_df), e-s))\n",
    "\n",
    "# Keep only business loans\n",
    "agg_loans_all_df = agg_loans_all_df[agg_loans_all_df['loan_type'] == 4]\n",
    "# Keep only loan originations\n",
    "agg_loans_all_df = agg_loans_all_df[agg_loans_all_df['action_taken_type'] == 1]\n",
    "# Keep only this state\n",
    "agg_loans_all_df = agg_loans_all_df[agg_loans_all_df['state'] == thestate]\n",
    "\n",
    "\n",
    "#agg_loans_all_df.apply(lambda row: '{0:02d}'.format(row['state'], axis=1))\n",
    "#agg_loans_all_df = agg_loans_all_df.assign(zzz = '{0:,.0f}{1:,.0f}'.format(agg_loans_all_df\n",
    "agg_loans_all_df = agg_loans_all_df.assign(\n",
    "    GEOID = agg_loans_all_df.apply(lambda row: '14000US{0:02d}{1:03d}{2:04d}{3:02d}'.format(\n",
    "        row['state'], \n",
    "        row['county'], \n",
    "        int(str(row['census_tract'])[0:str(row['census_tract']).find('.')]),\n",
    "        int(str(row['census_tract'])[str(row['census_tract']).find('.')+1:])\n",
    "    ), axis=1))\n",
    "agg_loans_all_df = agg_loans_all_df.rename(columns={'activity_year': 'year'})\n",
    "agg_loans_all_df = agg_loans_all_df.set_index(['GEOID','year'])\n",
    "\n",
    "\n",
    "\n",
    "data_gdf = city_tracts_years_gdf.join(agg_loans_all_df[[x for x in agg_loans_all_df.columns if x not in city_tracts_years_gdf.columns]], how='left')\n",
    "# # data_gdf[['county_geodata','county_loandata']]\n",
    "\n",
    "print('converting columns to numeric...')\n",
    "numeric_columns = []\n",
    "numeric_columns += ['nLoans1', 'amtLoans1', 'nLoans100k', 'amtLoans100k']\n",
    "numeric_columns += ['nLoans250k', 'amtLoans250k', 'nLoansToSmallest', 'amtLoansToSmallest']\n",
    "\n",
    "# for x in numeric_columns:\n",
    "#     data_gdf.loc[:, x] = pandas.to_numeric(x, errors='coerce')\n",
    "print('calculating total loans...')\n",
    "data_gdf = data_gdf.assign(nLoans = data_gdf['nLoans1'] + data_gdf['nLoans100k'] + data_gdf['nLoans250k'])\n",
    "data_gdf = data_gdf.assign(amtLoans = data_gdf['amtLoans1'] + data_gdf['amtLoans100k'] + data_gdf['amtLoans250k'])\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Kept {0:,.0f} tract-years in {1:,.0f} seconds!'.format(len(data_gdf), e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add income groups, CRA levels, working loans for each tract-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking up income group names from income_group_total...\n",
      "Adding CRA income levels (low/moderate/middle/upper/unknown)...\n",
      "Getting CRA income levels for tracts where only CRA level was reported...\n",
      "calculating working loans...\n",
      "backing up...\n",
      "Kept 2,000 tract-years in Baltimore in 0.11 seconds!\n",
      "income_group\n",
      "10% to 20% of MFI                       28\n",
      "100% to 110% of MFI                     38\n",
      "110% to 120% of MFI                     23\n",
      "20% to 30% of MFI                      116\n",
      "30% to 40% of MFI                      278\n",
      "40% to 50% of MFI                      392\n",
      "50% to 60% of MFI                      328\n",
      "60% to 70% of MFI                      204\n",
      "70% to 80% of MFI                      189\n",
      "80% to 90% of MFI                      113\n",
      "90% to 100% of MFI                      71\n",
      "< 10% of Median Family Income (MFI)      5\n",
      "> 120% of MFI                          162\n",
      "unknown                                 19\n",
      "dtype: int64\n",
      "cra_level\n",
      "low         819\n",
      "middle      245\n",
      "moderate    721\n",
      "unknown      19\n",
      "upper       162\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "\n",
    "print('looking up income group names from income_group_total...')\n",
    "\n",
    "data_gdf = data_gdf.rename(columns = {'income_group_total': 'income_group_code'})\n",
    "data_gdf = data_gdf.assign(income_group = np.nan)\n",
    "\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 14, 'income_group'] = 'unknown'\n",
    "\n",
    "print('Adding CRA income levels (low/moderate/middle/upper/unknown)...')\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "data_gdf = data_gdf.assign(cra_level = np.nan)\n",
    "data_gdf.loc[(data_gdf['income_group_code'] >= 1) & (data_gdf['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "data_gdf.loc[(data_gdf['income_group_code'] >= 6) & (data_gdf['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "data_gdf.loc[(data_gdf['income_group_code'] >= 9) & (data_gdf['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "data_gdf.loc[(data_gdf['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "data_gdf.loc[(data_gdf['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "print('Getting CRA income levels for tracts where only CRA level was reported...')\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 101, 'cra_level'] = 'low'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 102, 'cra_level'] = 'moderate'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 103, 'cra_level'] = 'middle'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 104, 'cra_level'] = 'upper'\n",
    "data_gdf.loc[data_gdf['income_group_code'] == 105, 'cra_level'] = 'unknown'\n",
    "\n",
    "print('calculating working loans...')\n",
    "data_gdf = data_gdf.assign(avgSmallLoan = data_gdf['amtLoans1'] / data_gdf['nLoans1'])\n",
    "\n",
    "data_gdf = data_gdf.assign(nWorkingLoans = 0)\n",
    "data_gdf.loc[data_gdf['avgSmallLoan'] < 10000, \n",
    "                           'nWorkingLoans'] = data_gdf['nLoans'][data_gdf['avgSmallLoan'] < 10000] - data_gdf['nLoans1'][data_gdf['avgSmallLoan'] < 10000]\n",
    "data_gdf.loc[data_gdf['avgSmallLoan'] >= 10000, \n",
    "                           'nWorkingLoans'] = data_gdf['nLoans'][data_gdf['avgSmallLoan'] >= 10000]\n",
    "\n",
    "data_gdf = data_gdf.assign(amtWorkingLoans = 0)\n",
    "data_gdf.loc[data_gdf['avgSmallLoan'] < 10000, \n",
    "                           'amtWorkingLoans'] = data_gdf['amtLoans'][data_gdf['avgSmallLoan'] < 10000] - data_gdf['amtLoans1'][data_gdf['avgSmallLoan'] < 10000]\n",
    "data_gdf.loc[data_gdf['avgSmallLoan'] >= 10000, \n",
    "                           'amtWorkingLoans'] = data_gdf['amtLoans'][data_gdf['avgSmallLoan'] >= 10000]\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('backing up...')\n",
    "data_gdf_bk = data_gdf\n",
    "print('Kept {0:,.0f} tract-years in {1:} in {2:,.2f} seconds!'.format(len(data_gdf), city, e-s))\n",
    "print(data_gdf.groupby('income_group').size())\n",
    "print(data_gdf.groupby('cra_level').size())\n",
    "#print('\\n')\n",
    "#data_gdf[data_gdf['cra_level'] == 'unknown']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to jobs data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw jobs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading state jobs data for MD...\n",
      "Reading /home/idies/workspace/Temporary/raddick/cra_scratch/lodes_wac/jobs_data_md.csv...\n",
      "constructing GEOIDs...\n",
      "selecting raw jobs from Baltimore...\n",
      "Read jobs for 2,004,138 block-group-years in Baltimore in 5 minutes 11 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_geocode</th>\n",
       "      <th>C000</th>\n",
       "      <th>CA01</th>\n",
       "      <th>CA02</th>\n",
       "      <th>CA03</th>\n",
       "      <th>CE01</th>\n",
       "      <th>CE02</th>\n",
       "      <th>CE03</th>\n",
       "      <th>CNS01</th>\n",
       "      <th>CNS02</th>\n",
       "      <th>...</th>\n",
       "      <th>CFA04</th>\n",
       "      <th>CFA05</th>\n",
       "      <th>CFS01</th>\n",
       "      <th>CFS02</th>\n",
       "      <th>CFS03</th>\n",
       "      <th>CFS04</th>\n",
       "      <th>CFS05</th>\n",
       "      <th>createdate</th>\n",
       "      <th>year</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40668</th>\n",
       "      <td>245100101001001</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160228</td>\n",
       "      <td>2004</td>\n",
       "      <td>14000US24510010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40669</th>\n",
       "      <td>245100101001002</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160228</td>\n",
       "      <td>2004</td>\n",
       "      <td>14000US24510010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40670</th>\n",
       "      <td>245100101001007</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160228</td>\n",
       "      <td>2004</td>\n",
       "      <td>14000US24510010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40671</th>\n",
       "      <td>245100101001018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160228</td>\n",
       "      <td>2004</td>\n",
       "      <td>14000US24510010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40672</th>\n",
       "      <td>245100101002000</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160228</td>\n",
       "      <td>2004</td>\n",
       "      <td>14000US24510010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081803</th>\n",
       "      <td>245102801021017</td>\n",
       "      <td>1938</td>\n",
       "      <td>107</td>\n",
       "      <td>1212</td>\n",
       "      <td>619</td>\n",
       "      <td>8</td>\n",
       "      <td>136</td>\n",
       "      <td>1794</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20201120</td>\n",
       "      <td>2018</td>\n",
       "      <td>14000US24510280102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081804</th>\n",
       "      <td>245102801021023</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20201120</td>\n",
       "      <td>2018</td>\n",
       "      <td>14000US24510280102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081805</th>\n",
       "      <td>245102801021037</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20201120</td>\n",
       "      <td>2018</td>\n",
       "      <td>14000US24510280102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081806</th>\n",
       "      <td>245102804033016</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20201120</td>\n",
       "      <td>2018</td>\n",
       "      <td>14000US24510280403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081807</th>\n",
       "      <td>245102805002000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20201120</td>\n",
       "      <td>2018</td>\n",
       "      <td>14000US24510280500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2004138 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 w_geocode  C000  CA01  CA02  CA03  CE01  CE02  CE03  CNS01  \\\n",
       "rownumber                                                                     \n",
       "40668      245100101001001     7     0     7     0     2     4     1      0   \n",
       "40669      245100101001002     8     1     5     2     5     3     0      0   \n",
       "40670      245100101001007    51    11    32     8     9    29    13      0   \n",
       "40671      245100101001018     3     1     2     0     2     0     1      0   \n",
       "40672      245100101002000    14     2     9     3     3     9     2      0   \n",
       "...                    ...   ...   ...   ...   ...   ...   ...   ...    ...   \n",
       "19081803   245102801021017  1938   107  1212   619     8   136  1794      0   \n",
       "19081804   245102801021023    45     4    30    11     0     2    43      0   \n",
       "19081805   245102801021037     3     1     1     1     0     0     3      0   \n",
       "19081806   245102804033016     9     0     4     5     1     0     8      0   \n",
       "19081807   245102805002000     7     0     5     2     0     0     7      0   \n",
       "\n",
       "           CNS02  ...  CFA04  CFA05  CFS01  CFS02  CFS03  CFS04  CFS05  \\\n",
       "rownumber         ...                                                    \n",
       "40668          0  ...      0      0      0      0      0      0      0   \n",
       "40669          0  ...      0      0      0      0      0      0      0   \n",
       "40670          0  ...      0      0      0      0      0      0      0   \n",
       "40671          0  ...      0      0      0      0      0      0      0   \n",
       "40672          0  ...      0      0      0      0      0      0      0   \n",
       "...          ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "19081803       0  ...      0      0      0      0      0      0      0   \n",
       "19081804       0  ...      0      0      0      0      0      0      0   \n",
       "19081805       0  ...      0      0      0      0      0      0      0   \n",
       "19081806       0  ...      0      0      0      0      0      0      0   \n",
       "19081807       0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "           createdate  year               GEOID  \n",
       "rownumber                                        \n",
       "40668        20160228  2004  14000US24510010100  \n",
       "40669        20160228  2004  14000US24510010100  \n",
       "40670        20160228  2004  14000US24510010100  \n",
       "40671        20160228  2004  14000US24510010100  \n",
       "40672        20160228  2004  14000US24510010100  \n",
       "...               ...   ...                 ...  \n",
       "19081803     20201120  2018  14000US24510280102  \n",
       "19081804     20201120  2018  14000US24510280102  \n",
       "19081805     20201120  2018  14000US24510280102  \n",
       "19081806     20201120  2018  14000US24510280403  \n",
       "19081807     20201120  2018  14000US24510280500  \n",
       "\n",
       "[2004138 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# IMPORTANT NOTE ABOUT JOBS VARIABLES\n",
    "# Race, ethnicity, education, sex reported 2009 t.e.m. 2018\n",
    "# Firm age reported 2011 t.e.m. 2017\n",
    "\n",
    "print('reading state jobs data for {0:}...'.format(state_abbrev.upper()))\n",
    "\n",
    "statejobfiles = sorted([jobs_dir+x for x in os.listdir(jobs_dir) if '{0:}'.format(state_abbrev) in x and '{0:}.'.format(state_abbrev) in x])\n",
    "#print(statejobfiles)\n",
    "state_raw_jobs_df = pandas.DataFrame()\n",
    "for thisfile in statejobfiles:\n",
    "    print('Reading {0:}...'.format(thisfile))\n",
    "    state_raw_jobs_df = pandas.concat((state_raw_jobs_df,pandas.read_csv(thisfile, index_col='rownumber', low_memory=False, keep_default_na=False)), axis=0)\n",
    "\n",
    "    \n",
    "print('constructing GEOIDs...')\n",
    "if (thestate < 10):\n",
    "    state_raw_jobs_df = state_raw_jobs_df.assign(GEOID = state_raw_jobs_df['w_geocode'].apply(lambda x: '14000US{0:02d}{1:}'.format(thestate,str(x)[1:10])))\n",
    "else:\n",
    "    state_raw_jobs_df = state_raw_jobs_df.assign(GEOID = state_raw_jobs_df['w_geocode'].apply(lambda x: '14000US{0:02d}{1:}'.format(thestate,str(x)[2:11])))\n",
    "\n",
    "    \n",
    "print('selecting raw jobs from {0:}...'.format(city))\n",
    "\n",
    "city_raw_jobs_df = state_raw_jobs_df[state_raw_jobs_df['GEOID'].isin(data_gdf.index.get_level_values('GEOID').tolist())]\n",
    "\n",
    "# print('backing up...')\n",
    "# city_raw_jobs_df_bk = city_raw_jobs_df\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read jobs for {0:,.0f} block-group-years in {1:} in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(city_raw_jobs_df), city, np.floor((e-s)/60), np.floor((e-s)%60)))\n",
    "city_raw_jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum jobs over census tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding columns to sum over...\n",
      "summing those jobs into census tracts...\n",
      "Summed 51 jobs across 3,396 tract-years in 0 minutes 32 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# print('getting from backup...')\n",
    "# city_raw_jobs_df = city_raw_jobs_df_bk\n",
    "\n",
    "#sum_columns = [x for x in city_raw_jobs_df.columns if x[0] == 'C']\n",
    "\n",
    "print('finding columns to sum over...')\n",
    "jobs_metadata_df = pandas.read_csv(code_lookup_dir+'wac_jobs_metadata.csv', encoding='utf-8', index_col='varnum')\n",
    "\n",
    "jobs_total_columns = jobs_metadata_df[jobs_metadata_df['variable'] == 'C000']['variable'].tolist()\n",
    "jobs_age_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CA')]['variable'].tolist()\n",
    "jobs_earnings_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CE')]['variable'].tolist()\n",
    "jobs_sector_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:3] == 'CNS')]['variable'].tolist()\n",
    "jobs_race_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CR')]['variable'].tolist()\n",
    "jobs_ethnicity_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CT')]['variable'].tolist()\n",
    "jobs_education_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CD')]['variable'].tolist()\n",
    "jobs_sex_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:2] == 'CS')]['variable'].tolist()\n",
    "jobs_firm_age_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:3] == 'CFA')]['variable'].tolist()\n",
    "jobs_firm_size_columns = jobs_metadata_df[jobs_metadata_df['variable'].apply(lambda x: x[0:3] == 'CFS')]['variable'].tolist()\n",
    "\n",
    "jobs_columns = jobs_total_columns + jobs_age_columns + jobs_earnings_columns + jobs_sector_columns\n",
    "jobs_columns += jobs_race_columns + jobs_ethnicity_columns + jobs_education_columns + jobs_sex_columns\n",
    "jobs_columns += jobs_firm_age_columns + jobs_firm_size_columns\n",
    "\n",
    "jobs_metadata_df = jobs_metadata_df.set_index('variable')\n",
    "\n",
    "print('summing those jobs into census tracts...')\n",
    "city_jobs_df = pandas.DataFrame(data=None, columns=['GEOID','year']+jobs_columns)\n",
    "city_jobs_df = city_jobs_df.set_index(['GEOID','year'])\n",
    "\n",
    "\n",
    "\n",
    "for x in jobs_columns:\n",
    "#    print('summing {0:} across census tracts...'.format(x))\n",
    "    city_jobs_df.loc[:,:][x] = city_raw_jobs_df.groupby(['GEOID', 'year'])[x].sum()\n",
    "\n",
    "    \n",
    "# Which variables appear in which years?    \n",
    "\n",
    "# city_jobs_df.xs(\n",
    "#     city_jobs_df.sample(1).index.get_level_values('GEOID').values[0], level='GEOID'\n",
    "# )[jobs_ethnicity_columns]#.sum()\n",
    "\n",
    "# for thiscol in jobs_firm_size_columns:\n",
    "#     print(thiscol)\n",
    "#     print('----')\n",
    "#     for this_one_year in city_jobs_df.index.get_level_values('year').drop_duplicates().tolist():\n",
    "\n",
    "#         print('{0:.0f}: {1:,.0f}'.format(this_one_year, city_jobs_df.xs(this_one_year, level='year')[thiscol].sum()))\n",
    "#     print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print('copying 2017 jobs into 2018 and 2019...')\n",
    "# # city_jobs_2018_df = city_jobs_df.xs(2017, level='year').reset_index()\n",
    "# # city_jobs_2018_df = city_jobs_2018_df.assign(year = 2018).set_index(['GEOID', 'year'])\n",
    "# # city_jobs_df = pandas.concat((city_jobs_df, city_jobs_2018_df), axis=0)\n",
    "\n",
    "# # city_jobs_2019_df = city_jobs_df.xs(2018, level='year').reset_index()\n",
    "# # city_jobs_2019_df = city_jobs_2019_df.assign(year = 2019).set_index(['GEOID', 'year'])\n",
    "# # city_jobs_df = pandas.concat((city_jobs_df, city_jobs_2019_df), axis=0)\n",
    "# # city_jobs_df\n",
    "\n",
    "# #for x in baltimore_agg_loans_df[jobs_columns].columns:\n",
    "# #    print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # print('backing up...')\n",
    "# # city_jobs_df_bk = city_jobs_df\n",
    "\n",
    "# e = time.time()\n",
    "# g = g + (e-s)\n",
    "# for x in city_jobs_df[jobs_columns_we_want].columns:\n",
    "#     print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n",
    "\n",
    "\n",
    "jobs_columns_we_want = ['C000', 'CFS01']   # later we will focus on total and small business jobs\n",
    "\n",
    "\n",
    "\n",
    "# city_jobs_df.xs(\n",
    "#     city_jobs_df.sample(1).index.get_level_values('GEOID').values[0], level='GEOID'\n",
    "# )[jobs_sector_columns]\n",
    "\n",
    "#jobs_metadata_df\n",
    "\n",
    "\n",
    "# print('backing up...')\n",
    "# city_jobs_df_bk = city_jobs_df\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Summed {0:,.0f} jobs across {1:,.0f} tract-years in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(jobs_columns), len(city_jobs_df), np.floor((e-s)/60), np.floor((e-s)%60)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firm age and firm size: copying 2017 jobs into 2018...\n",
      "All columns: copying 2018 jobs into 2019...\n",
      "\n",
      "Summed 51 jobs across 3,596 tract-years in 0 minutes 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# city_jobs_df = city_jobs_df_bk\n",
    "\n",
    "print('Firm age and firm size: copying 2017 jobs into 2018...')\n",
    "city_age_size_jobs_2018_df = city_jobs_df.xs(2017, level='year')#.reset_index()\n",
    "city_age_size_jobs_2018_df = city_age_size_jobs_2018_df.assign(year = 2018).reset_index().set_index(['GEOID', 'year'])\n",
    "\n",
    "\n",
    "for thisgeoid in city_jobs_df.xs(2017, level='year').index.values.tolist():\n",
    "    city_jobs_df.loc[thisgeoid, 2018][jobs_firm_age_columns+jobs_firm_size_columns] = city_age_size_jobs_2018_df.loc[thisgeoid, 2018][jobs_firm_age_columns+jobs_firm_size_columns]\n",
    "\n",
    "print('All columns: copying 2018 jobs into 2019...')\n",
    "city_jobs_2019_df = city_jobs_df.xs(2018, level='year').reset_index()\n",
    "city_jobs_2019_df = city_jobs_2019_df.assign(year = 2019)#.set_index(['GEOID', 'year'])\n",
    "\n",
    "\n",
    "city_jobs_df = city_jobs_df.reset_index()\n",
    "city_jobs_2019_df = city_jobs_2019_df[city_jobs_df.columns.tolist()]\n",
    "city_jobs_df = pandas.concat(\n",
    "    (city_jobs_df, city_jobs_2019_df), axis=0).sort_values(['GEOID', 'year']\n",
    "                                                          ).reset_index(drop=True).set_index(['GEOID', 'year'])\n",
    "\n",
    "#city_jobs_df\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('\\nSummed {0:,.0f} jobs across {1:,.0f} tract-years in {2:,.0f} minutes {3:,.0f} seconds!'.format(len(jobs_columns), len(city_jobs_df), np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge jobs with rest of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Added jobs data for 1,999 tract-years!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th>14000US24510280500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STATEFP</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_tract</th>\n",
       "      <td>2805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <td>2805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAMELSAD</th>\n",
       "      <td>Census Tract 2805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS01</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS02</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS03</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFS05</th>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "GEOID        14000US24510280500\n",
       "year                       2019\n",
       "STATEFP                      24\n",
       "county                      510\n",
       "census_tract               2805\n",
       "NAME                       2805\n",
       "NAMELSAD      Census Tract 2805\n",
       "...                         ...\n",
       "CFS01                       163\n",
       "CFS02                       361\n",
       "CFS03                       349\n",
       "CFS04                         4\n",
       "CFS05                       602\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "# city_jobs_df = city_jobs_df_bk\n",
    "\n",
    "\n",
    "#data_gdf.head(1).T #['COUNTYFP','NAME','year']\n",
    "data_gdf = data_gdf.join(city_jobs_df)\n",
    "\n",
    "# for x in jobs_columns_we_want:\n",
    "#     data_gdf.loc[:, x] = data_gdf[x].fillna(0)\n",
    "\n",
    "data_gdf = data_gdf.sort_index()\n",
    "\n",
    "print('done')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Added jobs data for {0:,.0f} tract-years!'.format(len(data_gdf[data_gdf['CFS01'].notnull()])))\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "\n",
    "data_gdf.tail(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get loans per job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calulating loans per job (total and with firm size 0-19)...\n",
      "recoding zero/zero values to zero and infinite values to NaN...\n",
      "Done in 0.2 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "#sbjobs_column = jobs_varnames_df[jobs_varnames_df['description'].apply(lambda x: '0-19' in x)].index.values[0]\n",
    "#loans_columns = []\n",
    "#data_gdf[sbjobs_column]\n",
    "print('Calulating loans per job (total and with firm size 0-19)...')\n",
    "\n",
    "data_gdf = data_gdf.assign(nLoans1_per_totaljob = data_gdf['nLoans1'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtLoans1_per_totaljob = data_gdf['amtLoans1'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(nLoans100k_per_totaljob = data_gdf['nLoans100k'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtLoans100k_per_totaljob = data_gdf['amtLoans100k'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(nLoans250k_per_totaljob = data_gdf['nLoans250k'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtLoans250k_per_totaljob = data_gdf['amtLoans250k'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(nLoansToSmallest_per_totaljob = data_gdf['nLoansToSmallest'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtLoansToSmallest_per_totaljob = data_gdf['amtLoansToSmallest'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(nLoans_per_totaljob = data_gdf['nLoans'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtLoans_per_totaljob = data_gdf['amtLoans'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(nWorkingLoans_per_totaljob = data_gdf['nWorkingLoans'] / data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(amtWorkingLoans_per_totaljob = data_gdf['amtWorkingLoans'] / data_gdf['C000'])\n",
    "\n",
    "data_gdf = data_gdf.assign(nLoans1_per_sbjob = data_gdf['nLoans1'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtLoans1_per_sbjob = data_gdf['amtLoans1'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(nLoans100k_per_sbjob = data_gdf['nLoans100k'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtLoans100k_per_sbjob = data_gdf['amtLoans100k'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(nLoans250k_per_sbjob = data_gdf['nLoans250k'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtLoans250k_per_sbjob = data_gdf['amtLoans250k'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(nLoansToSmallest_per_sbjob = data_gdf['nLoansToSmallest'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtLoansToSmallest_per_sbjob = data_gdf['amtLoansToSmallest'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(nLoans_per_sbjob = data_gdf['nLoans'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtLoans_per_sbjob = data_gdf['amtLoans'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(nWorkingLoans_per_sbjob = data_gdf['nWorkingLoans'] / data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(amtWorkingLoans_per_sbjob = data_gdf['amtWorkingLoans'] / data_gdf['CFS01'])\n",
    "\n",
    "\n",
    "per_job_columns = ['nLoans1_per_totaljob', 'amtLoans1_per_totaljob', 'nLoans100k_per_totaljob']\n",
    "per_job_columns += ['amtLoans100k_per_totaljob', 'nLoans250k_per_totaljob', 'amtLoans250k_per_totaljob']\n",
    "per_job_columns += ['nLoansToSmallest_per_totaljob', 'amtLoansToSmallest_per_totaljob']\n",
    "per_job_columns += ['nLoans_per_totaljob', 'amtLoans_per_totaljob', 'nWorkingLoans_per_totaljob']\n",
    "per_job_columns += ['amtWorkingLoans_per_totaljob', 'nLoans1_per_sbjob', 'amtLoans1_per_sbjob']\n",
    "per_job_columns += ['nLoans100k_per_sbjob', 'amtLoans100k_per_sbjob', 'nLoans250k_per_sbjob']\n",
    "per_job_columns += ['amtLoans250k_per_sbjob', 'nLoansToSmallest_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "per_job_columns += ['nLoans_per_sbjob', 'amtLoans_per_sbjob', 'nWorkingLoans_per_sbjob']\n",
    "per_job_columns += ['amtWorkingLoans_per_sbjob']\n",
    "\n",
    "\n",
    "print('recoding zero/zero values to zero and infinite values to NaN...')\n",
    "for x in data_gdf[per_job_columns]:\n",
    "    data_gdf.loc[:, x] = data_gdf[x].fillna(0)\n",
    "    data_gdf.loc[data_gdf[x] == np.inf, x] = np.nan\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.1f} seconds!'.format(e-s)) \n",
    "# data_gdf[(data_gdf['nWorkingLoans'] == 0) | (data_gdf['CFS01'] == 0)][\n",
    "#     ['nWorkingLoans', 'amtWorkingLoans', 'C000', 'CFS01', 'nWorkingLoans_per_totaljob', 'amtWorkingLoans_per_totaljob', 'nWorkingLoans_per_sbjob', 'amtWorkingLoans_per_sbjob']\n",
    "# ].sample(4).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting ACS 5-year census data...\n",
      "\t2019 estimates...\n",
      "\t2019 margins of error...\n",
      "\t2018 estimates...\n",
      "\t2018 margins of error...\n",
      "\t2017 estimates...\n",
      "\t2017 margins of error...\n",
      "\t2016 estimates...\n",
      "\t2016 margins of error...\n",
      "\t2015 estimates...\n",
      "\t2015 margins of error...\n",
      "\t2014 estimates...\n",
      "\t2014 margins of error...\n",
      "\t2013 estimates...\n",
      "\t2013 margins of error...\n",
      "\t2012 estimates...\n",
      "\t2012 margins of error...\n",
      "\t2011 estimates...\n",
      "\t2011 margins of error...\n",
      "\t2010 estimates...\n",
      "\t2010 margins of error...\n",
      "discarding block groups, keeping census tracts...\n",
      "converting to numeric...\n",
      "renaming error columns...\n",
      "joining to the rest of the data...\n",
      "Baltimore: Kept 2,000 tract-years in 2 minutes 11 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "\n",
    "acs5_estimates_df = pandas.DataFrame()\n",
    "acs5_margins_of_error_df = pandas.DataFrame()\n",
    "\n",
    "print('Getting ACS 5-year census data...')\n",
    "\n",
    "\n",
    "for thisyear in years:\n",
    "    print('\\t{0:.0f} estimates...'.format(thisyear))\n",
    "    acs5_estimates_this_year_df = pandas.read_csv(acs5_basedir+'{0:.0f}/estimates/estimates_acs{0:.0f}_tract_for_cra_analysis_mac.csv'.format(thisyear), low_memory=False, encoding='utf-8', index_col='GEOID')\n",
    "    acs5_estimates_this_year_df = acs5_estimates_this_year_df.drop([x for x in acs5_estimates_this_year_df.columns.tolist() if 'unnamed' in x.lower()], axis=1)\n",
    "\n",
    "    acs5_estimates_this_year_df = acs5_estimates_this_year_df.assign(year = thisyear)\n",
    "    acs5_estimates_df = pandas.concat((acs5_estimates_df, acs5_estimates_this_year_df), axis=0, sort=False)\n",
    "        \n",
    "    print('\\t{0:.0f} margins of error...'.format(thisyear))\n",
    "    acs5_margins_of_error_this_year_df = pandas.read_csv(acs5_basedir+'{0:.0f}/margins_of_error/margins_of_error_acs{0:.0f}_tract_for_cra_analysis_mac.csv'.format(thisyear), low_memory=False, encoding='utf-8', index_col='GEOID')\n",
    "    if (thisyear <= 2014):\n",
    "        acs5_margins_of_error_this_year_df = acs5_margins_of_error_this_year_df.drop([x for x in acs5_margins_of_error_this_year_df.columns.tolist() if 'unnamed' in x.lower()], axis=1)\n",
    "    acs5_margins_of_error_this_year_df = acs5_margins_of_error_this_year_df.assign(year = thisyear)\n",
    "    acs5_margins_of_error_df = pandas.concat((acs5_margins_of_error_df, acs5_margins_of_error_this_year_df), axis=0, sort=False)\n",
    "\n",
    "    \n",
    "    \n",
    "print('discarding block groups, keeping census tracts...')\n",
    "acs5_estimates_df = acs5_estimates_df.reset_index()\n",
    "acs5_margins_of_error_df = acs5_margins_of_error_df.reset_index()\n",
    "\n",
    "acs5_estimates_df = acs5_estimates_df[acs5_estimates_df['GEOID'].apply(lambda x: x[0:3] == '140')]\n",
    "acs5_margins_of_error_df = acs5_margins_of_error_df[acs5_margins_of_error_df['GEOID'].apply(lambda x: x[0:3] == '140')]\n",
    "\n",
    "\n",
    "print('converting to numeric...')\n",
    "for x in ['B08013_001', 'B19013_001', 'B19013A_001', 'B19013B_001', 'B19113_001', 'B25077_001', 'B25035_001']:\n",
    "    acs5_estimates_df.loc[:, x] = pandas.to_numeric(acs5_estimates_df[x], errors='coerce')\n",
    "    acs5_margins_of_error_df.loc[:, x] = pandas.to_numeric(acs5_margins_of_error_df[x], errors='coerce')\n",
    "\n",
    "print('renaming error columns...')\n",
    "orig_column_names = acs5_margins_of_error_df.columns.tolist()[6:-6]\n",
    "err_column_names = []\n",
    "for x in orig_column_names:\n",
    "    err_column_names.append(x+'_err')\n",
    "acs5_margins_of_error_df.columns = acs5_margins_of_error_df.columns.tolist()[0:6]+err_column_names+acs5_margins_of_error_df.columns.tolist()[-6:]\n",
    "\n",
    "print('joining to the rest of the data...')\n",
    "acs5_estimates_df = acs5_estimates_df.set_index(['GEOID', 'year'])\n",
    "acs5_margins_of_error_df = acs5_margins_of_error_df.set_index(['GEOID', 'year'])\n",
    "\n",
    "\n",
    "data_gdf = data_gdf.join(acs5_estimates_df[acs5_estimates_df.index.isin(data_gdf.index)][acs5_estimates_df.columns.tolist()[:-5]+acs5_estimates_df.columns.tolist()[-1:]], how='left', lsuffix='_loans_jobs', rsuffix='_acs5')\n",
    "data_gdf = data_gdf.join(acs5_margins_of_error_df[acs5_margins_of_error_df.index.isin(data_gdf.index)][acs5_margins_of_error_df.columns.tolist()[6:-3]+acs5_margins_of_error_df.columns.tolist()[-1:]], how='left', lsuffix='_loans_jobs', rsuffix='_acs5')\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('{0:}: Kept {1:,.0f} tract-years in {2:,.0f} minutes {3:.0f} seconds!'.format(city, len(data_gdf), np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate composite demographic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>B01001_040</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%50 to 54 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>B01001_041</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%55 to 59 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>B01001_042</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%60 and 61 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>B01001_043</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%62 to 64 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>B01001_044</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%65 and 66 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>B01001_045</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%67 to 69 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>B01001_046</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%70 to 74 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>B01001_047</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%75 to 79 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>B01001_048</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%80 to 84 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>B01001_049</td>\n",
       "      <td>SEX BY AGE%Total population%Total%Female%85 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>B02001_001</td>\n",
       "      <td>RACE% Total population%Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>B02001_002</td>\n",
       "      <td>RACE%Total population%Total%White alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>B02001_003</td>\n",
       "      <td>RACE%Total population%Total%Black or African American alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>B08013_001</td>\n",
       "      <td>AGGREGATE TRAVEL TIME TO WORK (IN MINUTES) OF WORKERS BY SEX% Workers 16 years and over who did not work at home%Aggregate travel time to work (in minutes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>B11001_001</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE)% Households%Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>B11001_002</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Family households</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>B11001_006</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Family households%Other family%Female householder no husband present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>B11001_007</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Nonfamily households</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>B11001A_001</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE) (WHITE ALONE)% Households with a householder who is White alone%Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>B11001B_001</td>\n",
       "      <td>HOUSEHOLD TYPE (INCLUDING LIVING ALONE) (BLACK OR AFRICAN AMERICAN ALONE)% Households with a householder who is Black or African American alone%Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>B15003_001</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER% Population 25 years and over%Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>B15003_002</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%No schooling completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>B15003_003</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%Nursery school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>B15003_004</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%Kindergarten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>B15003_005</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%1st grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>B15003_006</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%2nd grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>B15003_007</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%3rd grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>B15003_008</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%4th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>B15003_009</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%5th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>B15003_010</td>\n",
       "      <td>EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%6th grade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variable  \\\n",
       "rownumber                \n",
       "47          B01001_040   \n",
       "48          B01001_041   \n",
       "49          B01001_042   \n",
       "50          B01001_043   \n",
       "51          B01001_044   \n",
       "52          B01001_045   \n",
       "53          B01001_046   \n",
       "54          B01001_047   \n",
       "55          B01001_048   \n",
       "56          B01001_049   \n",
       "367         B02001_001   \n",
       "368         B02001_002   \n",
       "369         B02001_003   \n",
       "4211        B08013_001   \n",
       "6600        B11001_001   \n",
       "6601        B11001_002   \n",
       "6605        B11001_006   \n",
       "6606        B11001_007   \n",
       "6609       B11001A_001   \n",
       "6618       B11001B_001   \n",
       "8137        B15003_001   \n",
       "8138        B15003_002   \n",
       "8139        B15003_003   \n",
       "8140        B15003_004   \n",
       "8141        B15003_005   \n",
       "8142        B15003_006   \n",
       "8143        B15003_007   \n",
       "8144        B15003_008   \n",
       "8145        B15003_009   \n",
       "8146        B15003_010   \n",
       "\n",
       "                                                                                                                                                           description  \n",
       "rownumber                                                                                                                                                               \n",
       "47                                                                                                             SEX BY AGE%Total population%Total%Female%50 to 54 years  \n",
       "48                                                                                                             SEX BY AGE%Total population%Total%Female%55 to 59 years  \n",
       "49                                                                                                            SEX BY AGE%Total population%Total%Female%60 and 61 years  \n",
       "50                                                                                                             SEX BY AGE%Total population%Total%Female%62 to 64 years  \n",
       "51                                                                                                            SEX BY AGE%Total population%Total%Female%65 and 66 years  \n",
       "52                                                                                                             SEX BY AGE%Total population%Total%Female%67 to 69 years  \n",
       "53                                                                                                             SEX BY AGE%Total population%Total%Female%70 to 74 years  \n",
       "54                                                                                                             SEX BY AGE%Total population%Total%Female%75 to 79 years  \n",
       "55                                                                                                             SEX BY AGE%Total population%Total%Female%80 to 84 years  \n",
       "56                                                                                                          SEX BY AGE%Total population%Total%Female%85 years and over  \n",
       "367                                                                                                                                       RACE% Total population%Total  \n",
       "368                                                                                                                            RACE%Total population%Total%White alone  \n",
       "369                                                                                                        RACE%Total population%Total%Black or African American alone  \n",
       "4211       AGGREGATE TRAVEL TIME TO WORK (IN MINUTES) OF WORKERS BY SEX% Workers 16 years and over who did not work at home%Aggregate travel time to work (in minutes)  \n",
       "6600                                                                                                         HOUSEHOLD TYPE (INCLUDING LIVING ALONE)% Households%Total  \n",
       "6601                                                                                        HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Family households  \n",
       "6605                                     HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Family households%Other family%Female householder no husband present  \n",
       "6606                                                                                     HOUSEHOLD TYPE (INCLUDING LIVING ALONE)%Households%Total%Nonfamily households  \n",
       "6609                                                     HOUSEHOLD TYPE (INCLUDING LIVING ALONE) (WHITE ALONE)% Households with a householder who is White alone%Total  \n",
       "6618             HOUSEHOLD TYPE (INCLUDING LIVING ALONE) (BLACK OR AFRICAN AMERICAN ALONE)% Households with a householder who is Black or African American alone%Total  \n",
       "8137                                                                   EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER% Population 25 years and over%Total  \n",
       "8138                                             EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%No schooling completed  \n",
       "8139                                                     EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%Nursery school  \n",
       "8140                                                       EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%Kindergarten  \n",
       "8141                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%1st grade  \n",
       "8142                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%2nd grade  \n",
       "8143                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%3rd grade  \n",
       "8144                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%4th grade  \n",
       "8145                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%5th grade  \n",
       "8146                                                          EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER%Population 25 years and over%Total%6th grade  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs5_columns = [x for x in data_gdf.columns.tolist() if x[0] == 'B']\n",
    "acs5_metadata_df = pandas.read_csv(acs5_basedir+'2018/variables/variables_acs_5yr_all.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "\n",
    "acs5_metadata_df[acs5_metadata_df['variable'].isin(acs5_columns)][['variable','description']][30:60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating and renaming estimates columns for IVs...\n",
      "population 25 and older with bachelors degree or higher (B15003_022 t.e.m. B15003_025...\n",
      "...population 25 years and older...\n",
      "...householder sex & race, unempoyment, poverty, household type, home value, home age, travel time...\n",
      "...race, owner-occupied units, mfi, vacants...\n",
      "....comparison variables: total population, total households, poverty status, rentage...\n",
      "MFI & median home value: substituting \".\" with np.nan, converting to numeric...\n",
      "median home value: substituting \".\" with np.nan, converting to numeric...\n",
      "Done in 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "\n",
    "print('\\ncalculating and renaming estimates columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('population 25 and older with bachelors degree or higher (B15003_022 t.e.m. B15003_025...')\n",
    "h = data_gdf['B15003_022'] + data_gdf['B15003_023'] + data_gdf['B15003_024']  + data_gdf['B15003_025']\n",
    "data_gdf = data_gdf.assign(educated = pandas.to_numeric(h, errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...population 25 years and older...')\n",
    "data_gdf = data_gdf.rename(columns={'B15003_001': 'pop_25plus'})\n",
    "\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...householder sex & race, unempoyment, poverty, household type, home value, home age, travel time...')\n",
    "data_gdf = data_gdf.rename(columns = {  \n",
    "    'B11001_006': 'female_householders',\n",
    "    'B11001A_001': 'white_householders',\n",
    "    'B11001B_001': 'black_householders',\n",
    "    'B23025_005': 'unemployed_16plus',\n",
    "    'B17001_002': 'poverty_past_12_months',\n",
    "    'B25077_001': 'median_home_value',\n",
    "    'B25035_001': 'median_year_built',\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi, vacants...')\n",
    "data_gdf = data_gdf.rename(columns = {    \n",
    "    'B02001_002': 'pop_white',\n",
    "    'B02001_003': 'pop_black',\n",
    "    'B25003_002': 'owner_occ_housing_units',\n",
    "    'B19113_001': 'mfi',\n",
    "    'B25002_002': 'occupied_housing_units',\n",
    "    'B25002_003': 'vacant_housing_units',\n",
    "    'B11001_002': 'household_type_family',\n",
    "    'B11001_007': 'household_type_nonfamily',\n",
    "    'B25003_003': 'tenure_rent',\n",
    "    'B25034_001': 'year_built'\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('....comparison variables: total population, total households, poverty status, rentage...')\n",
    "data_gdf = data_gdf.rename(columns = {\n",
    "    'B01001_001': 'pop_total',\n",
    "    'B02001_001': 'pop_by_race_total',\n",
    "    'B11001_001': 'total_households',\n",
    "    'B25002_001': 'total_housing_units',\n",
    "    'B23025_002': 'labor_force_16plus',\n",
    "    'B17001_001': 'poverty_status_known',\n",
    "    'B25003_001': 'tenure_total'\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('MFI & median home value: substituting \".\" with np.nan, converting to numeric...')\n",
    "    print('median home value: substituting \".\" with np.nan, converting to numeric...')\n",
    "data_gdf.loc[data_gdf['mfi'] == '.', 'mfi'] = pandas.to_numeric(data_gdf['mfi'][data_gdf['mfi'] == '.'], errors='coerce')\n",
    "data_gdf.loc[data_gdf['median_home_value'] == '.', 'median_home_value'] = pandas.to_numeric(data_gdf['median_home_value'][data_gdf['median_home_value'] == '.'], errors='coerce')\n",
    "\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "\n",
    "print('Done in {0:,.0f} seconds!'.format(e-s))\n",
    "\n",
    "\n",
    "# unrenamed_columns = []\n",
    "# for x in data_gdf.columns:\n",
    "#     if ((x[0] == 'B') and ('_err' not in x)):\n",
    "#         unrenamed_columns.append(x)\n",
    "# acs5_metadata_df[acs5_metadata_df['variable'].isin(unrenamed_columns)][-9:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create error calculating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined standard-error-calculating functions!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "### Guide on how to calculate errors in percentages:\n",
    "# https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "    \n",
    "## Aggregating Data Across Population Subgroups: add error for each group in quadrature, divide by 1.645 for serr\n",
    "s = time.time()\n",
    "\n",
    "def find_serr_educated(row):\n",
    "\n",
    "    return pandas.to_numeric(np.sqrt(row['B15003_022_err']**2 + row['B15003_023_err']**2 + row['B15003_024_err']**2 + row['B15003_025_err']**2\n",
    "                                ) / 1.645, errors='coerce')\n",
    "\n",
    "# def find_serr_householders(row):\n",
    "#     return pandas.to_numeric(np.sqrt(row['B11001_002_err']**2 + row['B11001_007_err']**2 \n",
    "#                                 ) / 1.645, errors='coerce')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Defined standard-error-calculating functions!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...standard errors for hs graduates 25 and older (using custom serr-finding function...\n",
      "...margins of error for householder sex & race, unempoyment, poverty, home value, home age...\n",
      "MFI & median home value: substituting \".\" with np.nan, converting to numeric...\n",
      "\n",
      "calculating and renaming margins of error for comparison variables...\n",
      "...race, owner-occupied units, mfi...\n",
      "Done in 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# print('getting from backup..')\n",
    "# data_gdf = data_gdf_bk\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...standard errors for hs graduates 25 and older (using custom serr-finding function...')\n",
    "data_gdf = data_gdf.assign(educated_serr = pandas.to_numeric(data_gdf.apply(lambda row: find_serr_educated(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins of error for householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "data_gdf = data_gdf.rename(columns = {     \n",
    "    'B11001_001_err': 'total_households_err',\n",
    "    'B11001_006_err': 'female_householders_err',\n",
    "    'B11001A_001_err': 'black_householders_err',\n",
    "    'B11001B_001_err': 'white_householders_err',\n",
    "    'B23025_005_err': 'unemployed_16plus_err',\n",
    "    'B17001_002_err': 'poverty_past_12_months_err',\n",
    "    'B25077_001_err': 'median_home_value_err',\n",
    "    'B25035_001_err': 'median_year_built_err',\n",
    "    'B25003_002_err': 'owner_occ_housing_units_err',\n",
    "    'B19113_001_err': 'mfi_err',\n",
    "    'B25002_002_err': 'occupied_housing_units_err',\n",
    "    'B25002_003_err': 'vacant_housing_units_err',\n",
    "    'B11001_002_err': 'household_type_family_err',\n",
    "    'B11001_007_err': 'household_type_nonfamily_err',\n",
    "    'B25003_003_err': 'tenure_rent_err',\n",
    "    'B15003_001_err': 'pop_25plus_err'\n",
    "})\n",
    "\n",
    "data_gdf = data_gdf.assign(household_type_total = data_gdf['household_type_family'] + data_gdf['household_type_nonfamily'])\n",
    "data_gdf = data_gdf.assign(household_type_total_err = data_gdf['household_type_family_err'] + data_gdf['household_type_nonfamily_err'])\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('MFI & median home value: substituting \".\" with np.nan, converting to numeric...')\n",
    "data_gdf.loc[data_gdf['mfi_err'] == '.', 'mfi_err'] = pandas.to_numeric(data_gdf['mfi_err'][data_gdf['mfi_err'] == '.'], errors='coerce')\n",
    "data_gdf.loc[data_gdf['median_home_value_err'] == '.', 'median_home_value_err'] = pandas.to_numeric(data_gdf['median_home_value_err'][data_gdf['median_home_value_err'] == '.'], errors='coerce')\n",
    "\n",
    "\n",
    "print('\\ncalculating and renaming margins of error for comparison variables...')\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "data_gdf = data_gdf.rename(columns = {\n",
    "    'B01001_001_err': 'pop_total_err',\n",
    "    'B02001_002_err': 'pop_white_err',\n",
    "    'B02001_003_err': 'pop_black_err',\n",
    "    'B02001_001_err': 'pop_by_race_total',\n",
    "    'B17001_001_err': 'poverty_status_known_err',\n",
    "    'B02001_001_err': 'pop_by_race_total_err',\n",
    "    'B25002_001_err': 'total_housing_units_err',\n",
    "    'B23025_002_err': 'labor_force_16plus_err',\n",
    "    'B25003_001_err': 'tenure_total_err',\n",
    "    \n",
    "    \n",
    "})\n",
    "\n",
    "# if (debug >= 1):\n",
    "#     print('...total householders...')\n",
    "# data_gdf = data_gdf.assign(total_householders_serr = pandas.to_numeric(data_gdf.apply(lambda row: find_serr_householders(row), axis=1), errors='coerce'))\n",
    "\n",
    "\n",
    "#print('dropping columns we do not care about...')\n",
    "# columns_do_not_care = []\n",
    "# columns_do_not_care += ['B11001_002', 'B11001_007']\n",
    "# columns_do_not_care += ['B11001_002_err', 'B11001_007_err']\n",
    "# columns_do_not_care += ['B01001_048_err','B01001_049_err']#,'STATE']\n",
    "#data_gdf = data_gdf.drop(columns_do_not_care, axis=1)\n",
    "\n",
    "\n",
    "# print('Calculated errors for all columns!')\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "unrenamed_columns_with_errs = []\n",
    "\n",
    "for x in data_gdf.columns:\n",
    "#    print(x)\n",
    "    if ((x[0] == 'B') and ('_err' in x)):\n",
    "        unrenamed_columns_with_errs.append(x)\n",
    "\n",
    "unrenamed_columns = []        \n",
    "for y in unrenamed_columns_with_errs:\n",
    "    unrenamed_columns.append(y[:-4])\n",
    "#acs5_metadata_df[acs5_metadata_df['variable'].isin(unrenamed_columns)][80:]\n",
    "#print(unrenamed_columns)\n",
    "\n",
    "e = time.time()\n",
    "print('Done in {0:,.0f} seconds!'.format(e-s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare to percentify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "vars_for_percentification = ['pop_white', 'pop_black', 'black_householders', 'white_householders']\n",
    "vars_for_percentification += ['owner_occ_housing_units', 'educated', 'female_householders']\n",
    "vars_for_percentification += ['unemployed_16plus', 'poverty_past_12_months']\n",
    "vars_for_percentification += ['tenure_rent', 'household_type_family']\n",
    "\n",
    "vars_for_percentification += ['pop_white_err', 'pop_black_err', 'black_householders_err', 'white_householders_err']\n",
    "vars_for_percentification += ['owner_occ_housing_units_err', 'educated_serr', 'female_householders_err']\n",
    "vars_for_percentification += ['unemployed_16plus_err', 'poverty_past_12_months_err']\n",
    "vars_for_percentification += ['tenure_rent_err', 'household_type_family_err']\n",
    "\n",
    "vars_for_percentification += ['pop_total', 'total_householders', 'pop_by_race_total', 'pop_25plus', 'labor_force_16plus']\n",
    "vars_for_percentification += ['poverty_status_known', 'vacant_housing_units', 'total_housing_units']\n",
    "vars_for_percentification += ['tenure_total', 'household_type_total']\n",
    "\n",
    "vars_for_percentification += ['pop_totatl_err', 'total_householders_serr', 'pop_by_race_total_err', 'pop_25plus_err', 'labor_force_16plus_err']\n",
    "vars_for_percentification += ['poverty_status_known_err', 'vacant_housing_units_err', 'total_housing_units_err']\n",
    "vars_for_percentification += ['tenure_total_err', 'household_type_total_err']\n",
    "#vars_for_percentification\n",
    "#city_tracts_years_df[vars_for_percentification].columns.tolist()\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate percentages for needed demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th>14000US24510230100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STATEFP</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_tract</th>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAMELSAD</th>\n",
       "      <td>Census Tract 2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_unemployed</th>\n",
       "      <td>0.0502984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_poverty</th>\n",
       "      <td>0.181622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_vacant</th>\n",
       "      <td>0.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_rent</th>\n",
       "      <td>0.614379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_household_family</th>\n",
       "      <td>0.420915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "GEOID                14000US24510230100\n",
       "year                               2016\n",
       "STATEFP                              24\n",
       "county                              510\n",
       "census_tract                       2301\n",
       "NAME                               2301\n",
       "NAMELSAD              Census Tract 2301\n",
       "...                                 ...\n",
       "pct_unemployed                0.0502984\n",
       "pct_poverty                    0.181622\n",
       "pct_vacant                     0.163934\n",
       "pct_rent                       0.614379\n",
       "pct_household_family           0.420915\n",
       "\n",
       "[340 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "data_gdf = data_gdf.assign(pct_white = pandas.to_numeric((data_gdf['pop_white'] / data_gdf['pop_by_race_total']), errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_black = pandas.to_numeric((data_gdf['pop_black'] / data_gdf['pop_by_race_total']), errors='coerce'))\n",
    "\n",
    "data_gdf = data_gdf.assign(pct_white_householders = pandas.to_numeric((data_gdf['white_householders'] / data_gdf['total_households']), errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_black_householders = pandas.to_numeric((data_gdf['black_householders'] / data_gdf['total_households']), errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_female_householders = pandas.to_numeric((data_gdf['female_householders'] / data_gdf['total_households']), errors='coerce'))\n",
    "\n",
    "data_gdf = data_gdf.assign(peducated = pandas.to_numeric(data_gdf['educated'], errors='coerce') / pandas.to_numeric(data_gdf['pop_25plus'], errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_unemployed = pandas.to_numeric(data_gdf['unemployed_16plus'], errors='coerce') / pandas.to_numeric(data_gdf['labor_force_16plus'], errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_poverty = pandas.to_numeric(data_gdf['poverty_past_12_months'], errors='coerce') / pandas.to_numeric(data_gdf['poverty_status_known'], errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_vacant = pandas.to_numeric(data_gdf['vacant_housing_units'], errors='coerce') / pandas.to_numeric(data_gdf['total_housing_units'], errors='coerce'))\n",
    "\n",
    "data_gdf = data_gdf.assign(pct_rent = pandas.to_numeric(data_gdf['tenure_rent'], errors='coerce') / pandas.to_numeric(data_gdf['tenure_total'], errors='coerce'))\n",
    "data_gdf = data_gdf.assign(pct_household_family = pandas.to_numeric(data_gdf['household_type_family'], errors='coerce') / pandas.to_numeric(data_gdf['household_type_total'], errors='coerce'))\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('ok')\n",
    "#data_gdf.columns.tolist()\n",
    "\n",
    "data_gdf.sample(1).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to calculate errors in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined functions to calculate standard errors in percentages!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Guide on how to do this:\n",
    "#### https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "\n",
    "# X and Y are the measured values (not the errors) - X for the subsgroup and Y for the whole sample\n",
    "# Let P = X/Y  (the proportion we calculated in the last step)\n",
    "# dX and dY are the measured errors\n",
    "# dP = (1/Y) * np.sqrt(dX**2 - (P**2 * dY**2))\n",
    "# Standard error of P is dP/1.645\n",
    "#### this calculation is done verbosely in fnid_pop_white_serr, quickly in other functions\n",
    "\n",
    "s = time.time()\n",
    "def find_errors_in_pct(X, Y, dX, dY, verboselevel = 0):\n",
    "    try:\n",
    "        P = X / Y\n",
    "        oneoverY = 1 / Y\n",
    "        dXsq = dX**2\n",
    "        dYsq = dY**2\n",
    "        Psq = P**2\n",
    "        PsqdYsq = Psq * dYsq\n",
    "        if (PsqdYsq <= dXsq):\n",
    "            underroot = dXsq - PsqdYsq\n",
    "        else:\n",
    "            underroot = dXsq + PsqdYsq\n",
    "        rooty = np.sqrt(underroot)\n",
    "        dP = oneoverY * rooty\n",
    "        SE = dP / 1.645\n",
    "        if (verboselevel >= 2):\n",
    "#            print('X = pop_white, Y = pop_total')\n",
    "            print('X = {0:.0f}, dX = {1:.0f} ({2:.1%} error)'.format(X, dX, dX/X))\n",
    "            print('Y = {0:.0f}, dY = {1:.0f} ({2:.1%} error)'.format(Y, dY, dY/Y))\n",
    "        if (verboselevel >= 3):\n",
    "            print('P = {0:.3f}'.format(P))\n",
    "            print('dXsq = {0:.0f}, dYsq = {1:.0f}, Psq = {2:.3f}'.format(dXsq, dYsq, Psq))\n",
    "            print('PsqdYsq = {0:.0f}, underroot = {1:.0f}, rooty = {2:.3f}'.format(PsqdYsq, underroot, rooty))\n",
    "            print('dP = {0:.3f}'.format(dP))\n",
    "            print('SE = {0:.3f}'.format(SE))\n",
    "        if (verboselevel >= 2):\n",
    "            print('RESULT: {0:.2%} +/- {1:.2%}'.format(P, SE)) \n",
    "            print('\\n')\n",
    "        return pandas.to_numeric(SE, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "    \n",
    "e = time.time()\n",
    "g = g + (e-s)    \n",
    "print('Defined functions to calculate standard errors in percentages!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate errors in percntages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating errors in percentages...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "verboselevel = 0\n",
    "s = time.time()\n",
    "\n",
    "print('Calculating errors in percentages...')\n",
    "data_gdf = data_gdf.assign(pct_white_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_black_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_white_householders_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_black_householders_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_female_householders_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(peducated_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_unemployed_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_poverty_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_vacant_serr = np.nan)\n",
    "\n",
    "\n",
    "data_gdf = data_gdf.assign(pct_rent_serr = np.nan)\n",
    "data_gdf = data_gdf.assign(pct_household_family_serr = np.nan)\n",
    "\n",
    "\n",
    "#data_gdf.loc[:, \n",
    "#              'poverty_status_known_last12months_total_err'] = pandas.to_numeric(data_gdf['poverty_status_known_last12months_total_err'], errors='coerce')\n",
    "\n",
    "\n",
    "for ix, thisrow in data_gdf.iterrows():\n",
    "    if (verboselevel >= 2):\n",
    "        print('Census tract {0:}...'.format(ix))\n",
    "    #print('pct_white_serr...')\n",
    "    data_gdf.loc[ix, 'pct_white_serr'] = find_errors_in_pct(thisrow['pop_white'], thisrow['pop_by_race_total'], thisrow['pop_white_err'], thisrow['pop_by_race_total_err'], verboselevel)\n",
    "    #print('pct_black_serr...')\n",
    "    data_gdf.loc[ix, 'pct_black_serr'] = find_errors_in_pct(thisrow['pop_black'], thisrow['pop_by_race_total'], thisrow['pop_black_err'], thisrow['pop_by_race_total_err'], verboselevel)\n",
    "    #print('pct_white_householders_serr...')\n",
    "    data_gdf.loc[ix, 'pct_white_householders_serr'] = find_errors_in_pct(thisrow['white_householders'], thisrow['total_households'], thisrow['white_householders_err'], thisrow['total_households_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_black_householders_serr'] = find_errors_in_pct(thisrow['white_householders'], thisrow['total_households'], thisrow['white_householders_err'], thisrow['total_households_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_female_householders_serr'] = find_errors_in_pct(thisrow['white_householders'], thisrow['total_households'], thisrow['white_householders_err'], thisrow['total_households_err'], verboselevel)\n",
    "    \n",
    "    data_gdf.loc[ix, 'peducated_serr'] = find_errors_in_pct(thisrow['educated'], thisrow['pop_25plus'], thisrow['educated_serr'], thisrow['pop_25plus_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_unemployed_serr'] = find_errors_in_pct(thisrow['unemployed_16plus'], thisrow['unemployed_16plus_err'], thisrow['labor_force_16plus_err'], thisrow['labor_force_16plus_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_poverty_serr'] = find_errors_in_pct(thisrow['poverty_past_12_months'], thisrow['poverty_status_known'], thisrow['poverty_past_12_months_err'], thisrow['poverty_status_known_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_vacant_serr'] = find_errors_in_pct(thisrow['vacant_housing_units'], thisrow['total_housing_units'], thisrow['vacant_housing_units_err'], thisrow['total_housing_units_err'], verboselevel)\n",
    "\n",
    "    data_gdf.loc[ix, 'pct_rent_serr'] = find_errors_in_pct(thisrow['tenure_rent'], thisrow['tenure_total'], thisrow['tenure_rent_err'], thisrow['tenure_total_err'], verboselevel)\n",
    "    data_gdf.loc[ix, 'pct_household_family_serr'] = find_errors_in_pct(thisrow['household_type_family'], thisrow['household_type_total'], thisrow['household_type_family_err'], thisrow['household_type_total_err'], verboselevel)\n",
    "\n",
    "if (verboselevel >= 1):\n",
    "    for ix, thisrow in data_gdf.iterrows():\n",
    "        print('Census tract {0:,.0f}'.format(ix))\n",
    "        print('{0:,.0f} +/- {1:,.0f} white'.format(\n",
    "            thisrow['pop_white'], thisrow['pop_white_err']\n",
    "        ))\n",
    "        print('{0:,.0f} +/- {1:,.0f} total'.format(\n",
    "            thisrow['pop_total'], thisrow['pop_total_err']\n",
    "        ))\n",
    "        print('{0:.1%} +/- {1:.1%}'.format(\n",
    "            thisrow['pct_white'], thisrow['pct_white_serr']\n",
    "        ))\n",
    "        print('\\n')\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "    \n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct for inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inflation values from Board of Labor Statistics Consumer Price Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thevalue</th>\n",
       "      <th>thefactor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theyear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>252.441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>248.721</td>\n",
       "      <td>1.01496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>243.62</td>\n",
       "      <td>1.03621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>237.652</td>\n",
       "      <td>1.06223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>234.747</td>\n",
       "      <td>1.07537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>235.288</td>\n",
       "      <td>1.0729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>231.679</td>\n",
       "      <td>1.08962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>227.842</td>\n",
       "      <td>1.10797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>221.187</td>\n",
       "      <td>1.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>217.488</td>\n",
       "      <td>1.16071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        thevalue thefactor\n",
       "theyear                   \n",
       "2019     252.441         1\n",
       "2018     248.721   1.01496\n",
       "2017      243.62   1.03621\n",
       "2016     237.652   1.06223\n",
       "2015     234.747   1.07537\n",
       "2014     235.288    1.0729\n",
       "2013     231.679   1.08962\n",
       "2012     227.842   1.10797\n",
       "2011     221.187    1.1413\n",
       "2010     217.488   1.16071"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "baseline_year = latest_year\n",
    "\n",
    "inflator_df = pandas.DataFrame(data=None, columns=['theyear','themonth','thevalue'])\n",
    "\n",
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": ['CUSR0000SA0'],\"startyear\":earliest_year, \"endyear\":latest_year})  # All items in U.S. city average, all urban consumers, seasonally adjusted: https://www.bls.gov/cpi/tables/supplemental-files/historical-cpi-u-202007.pdf\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "json_data = json.loads(p.text)\n",
    "\n",
    "if (json_data['status'] == 'REQUEST_NOT_PROCESSED'):\n",
    "    print('Request not processed, setting manually...')\n",
    "    inflator_df.loc[0, ['theyear', 'themonth', 'thevalue']] = [2019, 1, 251.712]\n",
    "    inflator_df.loc[1, ['theyear', 'themonth', 'thevalue']] = [2018, 1, 247.867]\n",
    "    inflator_df.loc[2, ['theyear', 'themonth', 'thevalue']] = [2017, 1, 242.839]\n",
    "else:\n",
    "    cnt = 0\n",
    "    for series in json_data['Results']['series']:\n",
    "        seriesId = series['seriesID']\n",
    "#        print(seriesId)\n",
    "        for item in series['data']:\n",
    "            inflator_df.loc[cnt, ['theyear', 'themonth', 'thevalue']] = [int(item['year']), int(item['period'][1:]), float(item['value'])]\n",
    "            cnt += 1 \n",
    "inflator_df = inflator_df[inflator_df['themonth'] == 1]\n",
    "inflator_df = inflator_df.drop('themonth', axis=1)\n",
    "\n",
    "baseline_value = inflator_df[inflator_df['theyear'] == baseline_year]['thevalue'].values[0]\n",
    "inflator_df = inflator_df.assign(thefactor = baseline_value / inflator_df['thevalue'])\n",
    "inflator_df = inflator_df.set_index('theyear')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "inflator_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baltimore: Kept 2,000 tract-years in 0 minutes 0 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "\n",
    "money_columns = []\n",
    "money_columns += ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest']\n",
    "money_columns += ['avgSmallLoan', 'amtLoans', 'amtWorkingLoans']\n",
    "money_columns += ['amtLoans1_per_totaljob', 'amtLoans100k_per_totaljob', 'amtLoans250k_per_totaljob']\n",
    "money_columns += ['amtLoansToSmallest_per_totaljob', 'amtLoans_per_totaljob', 'amtWorkingLoans_per_totaljob']\n",
    "money_columns += ['amtLoans1_per_sbjob', 'amtLoans100k_per_sbjob', 'amtLoans250k_per_sbjob']\n",
    "money_columns += ['amtLoansToSmallest_per_sbjob', 'amtLoans_per_sbjob', 'amtWorkingLoans_per_sbjob']\n",
    "money_columns += ['mfi', 'median_home_value', 'mfi_err', 'median_home_value_err']\n",
    "\n",
    "\n",
    "\n",
    "adjusted_money_df = pandas.DataFrame(data=None, columns=['GEOID']+money_columns).set_index('GEOID')\n",
    "\n",
    "for thisyear in years:\n",
    "    thefactor = inflator_df.loc[thisyear]['thefactor']\n",
    "    adjusted_money_df_i = data_gdf.xs(thisyear, level='year')[money_columns].apply(lambda x: x*thefactor)\n",
    "    adjusted_money_df_i = adjusted_money_df_i.assign(year = thisyear).reset_index()\n",
    "    adjusted_money_df = pandas.concat((adjusted_money_df, adjusted_money_df_i), axis=0)\n",
    "\n",
    "for x in money_columns:\n",
    "    adjusted_money_df = adjusted_money_df.rename(columns={x: x+'_adj'})\n",
    "# adjusted_money_df = adjusted_money_df.reset.set_index(['GEOID', 'year'])\n",
    "    \n",
    "# # data_gdf = pandas.concat((data_gdf, adjusted_money_df), axis=1)\n",
    "#.set_index(['GEOID', 'year'])\n",
    "adjusted_money_df = adjusted_money_df.set_index(['GEOID', 'year'])\n",
    "data_gdf = pandas.concat((data_gdf,  adjusted_money_df), axis=1)\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('{0:}: Kept {1:,.0f} tract-years in {2:,.0f} minutes {3:.0f} seconds!'.format(city, len(data_gdf), np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add community statistical areas (Baltimore only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "if (city == 'Baltimore'):\n",
    "    tract_to_csa_df = pandas.read_csv(code_lookup_dir+'census_tract_to_neighborhood.csv')\n",
    "    tract_to_csa_df.loc[:, 'GEOID10'] = tract_to_csa_df['GEOID10'].apply(lambda x: '14000US'+str(x))\n",
    "    data_gdf = data_gdf.reset_index().merge(tract_to_csa_df[['GEOID10','TRACTCE10','NAME10','CSA2010']], left_on='GEOID', right_on='GEOID10').set_index(['GEOID', 'year'])\n",
    "\n",
    "# print('backing up...')\n",
    "# data_gdf_bk = data_gdf\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get only the columns we need, in the right order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renaming variables describing this tract's state...\n",
      "creating new jobs columns...\n",
      "selecting column order...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "# print('getting from backup...')\n",
    "# data_gdf = data_gdf_bk\n",
    "print('renaming variables describing this tract\\'s state...')\n",
    "data_gdf = data_gdf.rename(columns = {'STATE': 'state_acs5', 'state': 'state_loans', 'STATEFP': 'state'})\n",
    "print('creating new jobs columns...')\n",
    "data_gdf = data_gdf.assign(total_jobs = data_gdf['C000'])\n",
    "data_gdf = data_gdf.assign(sb_jobs = data_gdf['CFS01'])\n",
    "data_gdf = data_gdf.assign(city_name = city)\n",
    "\n",
    "print('selecting column order...')\n",
    "new_columns = []\n",
    "#new_columns += ['state', 'county', 'census_tract']\n",
    "new_columns += ['city_name', 'msa'] # city name, metropolitan statistical area (MSA) number\n",
    "new_columns += ['loan_type', 'action_taken_type'] # loan type (always 4 for business) and action taken (always 1 for origination)\n",
    "new_columns += ['income_group_code'] # income group code (1 to 14 or 101 to 105)\n",
    "new_columns += ['income_group', 'cra_level'] # income group and CRA level (human-readable)\n",
    "new_columns += ['nLoans1','amtLoans1','nLoans100k','amtLoans100k','nLoans250k','amtLoans250k','nLoansToSmallest','amtLoansToSmallest'] # number and amount of loans (directly from CRA data)\n",
    "new_columns += ['nLoans', 'amtLoans', 'avgSmallLoan', 'nWorkingLoans', 'amtWorkingLoans'] # calculated total and working loans\n",
    "new_columns += ['total_jobs', 'sb_jobs'] # total and small business jobs\n",
    "\n",
    "# all jobs columns under original names\n",
    "new_columns += ['C000','CA01','CA02','CA03','CE01','CE02','CE03']\n",
    "new_columns += ['CNS01','CNS02','CNS03','CNS04','CNS05','CNS06','CNS07','CNS08','CNS09','CNS10','CNS11','CNS12','CNS13','CNS14','CNS15','CNS16','CNS17','CNS18','CNS19','CNS20']\n",
    "new_columns += ['CR01','CR02','CR03','CR04','CR05','CR07','CT01','CT02','CD01','CD02','CD03','CD04','CS01','CS02']\n",
    "new_columns += ['CFA01','CFA02','CFA03','CFA04','CFA05','CFS01','CFS02','CFS03','CFS04','CFS05']\n",
    "\n",
    "# loans per job\n",
    "new_columns += ['nLoans1_per_totaljob','amtLoans1_per_totaljob','nLoans100k_per_totaljob','amtLoans100k_per_totaljob']\n",
    "new_columns += ['nLoans250k_per_totaljob','amtLoans250k_per_totaljob','nLoansToSmallest_per_totaljob','amtLoansToSmallest_per_totaljob']\n",
    "new_columns += ['nLoans_per_totaljob','amtLoans_per_totaljob','nWorkingLoans_per_totaljob','amtWorkingLoans_per_totaljob']\n",
    "new_columns += ['nLoans1_per_sbjob','amtLoans1_per_sbjob','nLoans100k_per_sbjob','amtLoans100k_per_sbjob','nLoans250k_per_sbjob','amtLoans250k_per_sbjob']\n",
    "new_columns += ['nLoansToSmallest_per_sbjob','amtLoansToSmallest_per_sbjob','nLoans_per_sbjob','amtLoans_per_sbjob','nWorkingLoans_per_sbjob','amtWorkingLoans_per_sbjob']\n",
    "\n",
    "# census count estimates\n",
    "new_columns += ['pop_total','pop_by_race_total','pop_white','pop_black']\n",
    "new_columns += ['total_households','white_householders','black_householders','female_householders']\n",
    "new_columns += ['total_housing_units','occupied_housing_units','vacant_housing_units']\n",
    "new_columns += ['educated','unemployed_16plus','poverty_past_12_months','mfi'] # high school graduates (ages 25+), unemployed, in poverty, MFI, travel time to work\n",
    "new_columns += ['owner_occ_housing_units','median_home_value','year_built', 'median_year_built'] # home\n",
    "new_columns += ['pop_25plus','labor_force_16plus','poverty_status_known']\n",
    "new_columns += ['household_type_family', 'household_type_nonfamily','household_type_total', 'tenure_rent', 'tenure_total']\n",
    "\n",
    "\n",
    "# census count errors\n",
    "new_columns += ['pop_total_err','pop_by_race_total_err','pop_white_err','pop_black_err']\n",
    "new_columns += ['total_households_err','white_householders_err','black_householders_err','female_householders_err']\n",
    "new_columns += ['total_housing_units_err','occupied_housing_units_err','vacant_housing_units_err']\n",
    "new_columns += ['educated_serr','unemployed_16plus_err','poverty_past_12_months_err','mfi_err'] # high school graduates (ages 25+), unemployed, in poverty, MFI, travel time to work\n",
    "new_columns += ['owner_occ_housing_units_err','median_home_value_err', 'median_year_built_err'] # home\n",
    "new_columns += ['pop_25plus_err','labor_force_16plus_err','poverty_status_known_err']\n",
    "new_columns += ['household_type_family_err', 'household_type_nonfamily_err', 'household_type_total_err', 'tenure_rent_err', 'tenure_total_err']\n",
    "\n",
    "# census percentages and their errors\n",
    "new_columns += ['pct_white','pct_black','pct_white_householders','pct_black_householders','pct_female_householders']\n",
    "new_columns += ['peducated','pct_unemployed','pct_poverty','pct_vacant', 'pct_household_family', 'pct_rent']\n",
    "new_columns += ['pct_white_serr','pct_black_serr','pct_white_householders_serr','pct_black_householders_serr','pct_female_householders_serr']\n",
    "new_columns += ['peducated_serr','pct_unemployed_serr','pct_poverty_serr','pct_vacant_serr', 'pct_household_family_serr', 'pct_rent_serr']\n",
    "\n",
    "# # inflation-adjusted money values\n",
    "new_columns += ['amtLoans1_adj','amtLoans100k_adj','amtLoans250k_adj','amtLoansToSmallest_adj']\n",
    "new_columns += ['avgSmallLoan_adj','amtLoans_adj','amtWorkingLoans_adj']\n",
    "new_columns += ['amtLoans1_per_totaljob_adj','amtLoans100k_per_totaljob_adj','amtLoans250k_per_totaljob_adj','amtLoansToSmallest_per_totaljob_adj']\n",
    "new_columns += ['amtLoans_per_totaljob_adj','amtWorkingLoans_per_totaljob_adj']\n",
    "new_columns += ['amtLoans1_per_sbjob_adj','amtLoans100k_per_sbjob_adj','amtLoans250k_per_sbjob_adj','amtLoansToSmallest_per_sbjob_adj','amtLoans_per_sbjob_adj','amtWorkingLoans_per_sbjob_adj']\n",
    "new_columns += ['mfi_adj','median_home_value_adj','mfi_err_adj','median_home_value_err_adj']\n",
    "\n",
    "## geographic information about the census tract\n",
    "#data_gdf = data_gdf.rename(columns={'STATEFP': 'state_tractdata'})\n",
    "new_columns += ['state', 'county', 'census_tract', 'NAME', 'NAMELSAD', 'MTFCC', 'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON']\n",
    "\n",
    "## more info from loans data\n",
    "#data_gdf = data_gdf.rename(columns =  {'Geography Name_loans_jobs': 'geography_name_loans_jobs'})\n",
    "new_columns += ['state_loans', 'split_county_indicator', 'population_classification', 'split_county_indicator', 'population_classification']#, 'geography_name_loans_jobs']\n",
    "\n",
    "## ACS5 raw census data under original variable names\n",
    "new_columns += [x for x in data_gdf.columns if (x not in new_columns) and (x[0] == 'B')]\n",
    "## ACS5 tract metadata\n",
    "#data_gdf = data_gdf.rename(columns =  {'Geography Name_acs5': 'geography_name_acs5'})\n",
    "new_columns += ['FILEID', 'FILETYPE', 'STUSAB', 'CHARITER', 'SEQUENCE', 'LOGRECNO', 'state_acs5',  'Name']#, 'geography_name_acs5']\n",
    "\n",
    "if (city == 'Baltimore'):\n",
    "    new_columns += ['GEOID10', 'TRACTCE10', 'NAME10', 'CSA2010']\n",
    "\n",
    "# # as traditional, geometry goes last\n",
    "# new_columns += ['geometry']\n",
    "\n",
    "# check that we got them all\n",
    "#pprint([x for x in data_gdf.columns if x not in new_columns])\n",
    "\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done!')\n",
    "#print('Done in {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor((e-s)/60), np.floor((e-s)%60)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputting without shapefile data...\n",
      "\tWrote 2,000 tract-years by 378 columns (without geometry data) to:\n",
      "\t\t/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/final_data/baltimore_2010_2019_no_geo.csv\n",
      "\n",
      "\n",
      "outputting shapefile data separately...\n",
      "\tWrote 2,000 tract-years by 1 columns (SHAPEFILE DATA ONLY) to \n",
      "\t/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/final_data/baltimore_2010_2019_shapefiles.shp\n",
      "Done in 0 minutes 3 seconds!\n"
     ]
    }
   ],
   "source": [
    "print('outputting without shapefile data...')\n",
    "s = time.time()\n",
    "city_name_for_output = city.replace(\".\",\"\").replace(\" \",\"_\").lower()\n",
    "outfilename_no_geo = '{0:}_{1:.0f}_{2:.0f}_no_geo.csv'.format(city_name_for_output, earliest_year, latest_year)\n",
    "\n",
    "data_gdf[new_columns].to_csv(output_data_dir+outfilename_no_geo)\n",
    "\n",
    "print('\\tWrote {0:,.0f} tract-years by {1:,.0f} columns (without geometry data) to:\\n\\t\\t{2:}'.format(\n",
    "    data_gdf[new_columns].shape[0], data_gdf[new_columns].shape[1], output_data_dir+outfilename_no_geo\n",
    "     ))\n",
    "print('\\n')\n",
    "\n",
    "print('outputting shapefile data separately...')\n",
    "outfilename_shapefiles_geo = '{0:}_{1:.0f}_{2:.0f}_shapefiles.shp'.format(city_name_for_output, earliest_year, latest_year)\n",
    "shapefile_writer_gdf = geopandas.GeoDataFrame(data=data_gdf['geometry'], columns=['geometry'], crs=data_gdf.crs, geometry='geometry')\n",
    "shapefile_writer_gdf.to_file(output_data_dir+outfilename_shapefiles_geo)\n",
    "\n",
    "print('\\tWrote {0:,.0f} tract-years by {1:,.0f} columns (SHAPEFILE DATA ONLY) to \\n\\t{2:}'.format(shapefile_writer_gdf.shape[0], shapefile_writer_gdf.shape[1], output_data_dir+outfilename_shapefiles_geo))\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor((e-s)/60), np.floor((e-s)%60)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Total time: 9 minutes 13 seconds!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = time.time()\n",
    "q = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/final_data/baltimore_2017_2019_no_geo.csv'\n",
    "qdf = pandas.read_csv(q)\n",
    "qdf = qdf.set_index(['GEOID', 'year'], drop=True)\n",
    "\n",
    "\n",
    "r = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/final_data/baltimore_2017_2019_shapefiles.shp'\n",
    "rgdf = geopandas.read_file(r)\n",
    "rgdf = rgdf.set_index(['GEOID', 'year'], drop=True)\n",
    "\n",
    "gdf = geopandas.GeoDataFrame(data=pandas.concat((qdf, rgdf), axis=1), columns=pandas.concat((qdf, rgdf), axis=1).columns, crs=rgdf.crs, geometry='geometry')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('DONE! Total time: {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor(g/60), np.floor(g%60)))\n",
    "\n",
    "gdf.plot(column='amtLoans1_adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
