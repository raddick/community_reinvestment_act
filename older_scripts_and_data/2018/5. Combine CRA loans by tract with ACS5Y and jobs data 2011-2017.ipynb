{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages, set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import pandas\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "debug = 2    # debug = 2 means also show maps\n",
    "\n",
    "#basedir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/acs5/'\n",
    "#census_data_basedir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/acs5/'\n",
    "\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "datadir = thisdir + 'datasets/'\n",
    "census_data_dir = datadir + 'acs5/'\n",
    "census_acs5_rawdata_basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "\n",
    "shapefile_basedir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "census_shapefile_tiger_basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/shapefiles/'\n",
    "\n",
    "inflation_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/inflation/'\n",
    "\n",
    "figdir = thisdir + 'figures/'\n",
    "outdir = thisdir + 'datasets_for_analysis/'\n",
    "\n",
    "for x in [datadir, figdir]:\n",
    "    if not(os.path.exists(x)):\n",
    "        os.makedirs(x)\n",
    "\n",
    "os.chdir(thisdir)\n",
    "os.getcwd()\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CRA loan data by census tract 2010-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping only 2011-2017 data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_tract</th>\n",
       "      <th>activity_year</th>\n",
       "      <th>income_group_code</th>\n",
       "      <th>nLoans1</th>\n",
       "      <th>amtLoans1</th>\n",
       "      <th>nLoans100k</th>\n",
       "      <th>amtLoans100k</th>\n",
       "      <th>nLoans250k</th>\n",
       "      <th>amtLoans250k</th>\n",
       "      <th>nLoansToSmallest</th>\n",
       "      <th>amtLoansToSmallest</th>\n",
       "      <th>nLoansTotal</th>\n",
       "      <th>amtLoansTotal</th>\n",
       "      <th>CSA2010</th>\n",
       "      <th>income_group</th>\n",
       "      <th>cra_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>1047000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>621000</td>\n",
       "      <td>73</td>\n",
       "      <td>1047000</td>\n",
       "      <td>Canton</td>\n",
       "      <td>&gt; 120% of MFI</td>\n",
       "      <td>upper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_tract  activity_year  income_group_code  nLoans1  amtLoans1  \\\n",
       "0  101.0         2017           13                 73       1047000     \n",
       "\n",
       "   nLoans100k  amtLoans100k  nLoans250k  amtLoans250k  nLoansToSmallest  \\\n",
       "0  0           0             0           0             43                 \n",
       "\n",
       "   amtLoansToSmallest  nLoansTotal  amtLoansTotal CSA2010   income_group  \\\n",
       "0  621000              73           1047000        Canton  > 120% of MFI   \n",
       "\n",
       "  cra_level  \n",
       "0  upper     "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read aggregate data\n",
    "agg_tracts_df = pandas.read_csv(datadir+'loans_by_census_tract_2010_2017.csv', encoding='utf-8', low_memory=False)\n",
    "#agg_tracts_df = agg_tracts_df[agg_tracts_df['activity_year'] >= 2012]\n",
    "\n",
    "# parse amounts in dollars into numerics\n",
    "for thiscol in ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest', 'amtLoansTotal']:\n",
    "    agg_tracts_df.loc[:, thiscol] = pandas.to_numeric(agg_tracts_df[thiscol].apply(lambda x: str(x).replace(',','')[1:]), errors='coerce')\n",
    "\n",
    "# Add community statistical area names\n",
    "tract_to_csa_df = pandas.read_csv('census_tract_to_neighborhood.csv', index_col='NAME10')\n",
    "agg_tracts_df = agg_tracts_df.assign(CSA2010 = agg_tracts_df.join(tract_to_csa_df, how='left', on='census_tract')['CSA2010'])\n",
    "\n",
    "# Get income group names\n",
    "agg_tracts_df = agg_tracts_df.assign(income_group = np.nan)\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "agg_tracts_df.loc[agg_tracts_df['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "agg_tracts_df = agg_tracts_df.assign(cra_level = np.nan)\n",
    "agg_tracts_df.loc[(agg_tracts_df['income_group_code'] >= 1) & (agg_tracts_df['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "agg_tracts_df.loc[(agg_tracts_df['income_group_code'] >= 6) & (agg_tracts_df['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "agg_tracts_df.loc[(agg_tracts_df['income_group_code'] >= 9) & (agg_tracts_df['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "agg_tracts_df.loc[(agg_tracts_df['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "agg_tracts_df.loc[(agg_tracts_df['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "#agg_tracts_df = agg_tracts_df.merge(tract_shapes_gdf, how='left', left_on='census_tract', right_on='NAME')\n",
    "\n",
    "#agg_tracts_gdf = geopandas.GeoDataFrame(agg_tracts_df, crs=tract_shapes_gdf.crs, geometry='geometry')\n",
    "\n",
    "#agg_tracts_df.groupby('activity_year').size()\n",
    "#print('Done')\n",
    "\n",
    "print('Keeping only 2011-2017 data...')\n",
    "agg_tracts_df = agg_tracts_df[agg_tracts_df['activity_year'] >= 2011]\n",
    "agg_tracts_df.head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: how many census tracts reported each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of census tracts with loans per year, 2011-2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activity_year\n",
       "2011    197\n",
       "2012    198\n",
       "2013    197\n",
       "2014    198\n",
       "2015    199\n",
       "2016    200\n",
       "2017    199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of census tracts with loans per year, 2011-2017\")\n",
    "agg_tracts_df.groupby('activity_year').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add census data (ACS 5-year estimates for Macvars 2011-2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting loans for year 2017...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2016...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2015...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2014...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2013...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2012...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "Getting loans for year 2011...\n",
      "reading ACS5 data...\n",
      "keeping census data only for Baltimore City tracts...\n",
      "merging census data with loan data...\n",
      "Assembling years into one dataframe...\n",
      "indexing by tract and year...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "reinvestment_df = pandas.DataFrame()\n",
    "\n",
    "for thisyear in range(2017,2010,-1):\n",
    "    #agg_tracts_gdf = agg_tracts_gdf.set_index(['census_tract', 'activity_year'])\n",
    "    xdf = agg_tracts_df[agg_tracts_df['activity_year'] == thisyear]\n",
    "    xdf = xdf.set_index('census_tract')\n",
    "    if (debug > 0):\n",
    "        print('Getting loans for year {0:.0f}...'.format(thisyear))\n",
    "    if (debug > 1):\n",
    "        print('reading ACS5 data...')\n",
    "    metadata_df = pandas.read_csv(census_data_dir+'acs5_metadata_md_2017.csv', encoding='utf-8', index_col='varnum')\n",
    "    metadata_df = metadata_df.sort_index()\n",
    "    acs5_x_df = pandas.read_csv(census_data_dir+'acs5_md_2017.csv', encoding='utf-8')\n",
    "    numeric_columns = [x for x in acs5_x_df.columns.tolist() if '_' in x]\n",
    "    for x in numeric_columns:\n",
    "        acs5_x_df.loc[:, x] = pandas.to_numeric(acs5_x_df[x], errors='coerce')\n",
    "\n",
    "    if (debug > 1):\n",
    "        print('keeping census data only for Baltimore City tracts...')\n",
    "    acs5_x_df = acs5_x_df[acs5_x_df['GEOID'].apply(lambda x: '14000US24510' in x)]\n",
    "    \n",
    "    if (debug > 1):\n",
    "        print('merging census data with loan data...')\n",
    "    acs5_x_df = acs5_x_df.assign(census_tract = pandas.to_numeric(acs5_x_df['GEOID'].apply(lambda x: x[12:16]+'.'+x[16:]), errors='coerce'))\n",
    "    xdf = xdf.reset_index().merge(acs5_x_df, how='left', on='census_tract').set_index('census_tract')\n",
    "\n",
    "    if (debug > 1):\n",
    "        print('Assembling years into one dataframe...')\n",
    "    reinvestment_df = pandas.concat((reinvestment_df, xdf), axis=0)\n",
    "\n",
    "print('indexing by tract and year...')\n",
    "reinvestment_df = reinvestment_df.reset_index()\n",
    "reinvestment_df = reinvestment_df.set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "metadata_df_bk = metadata_df\n",
    "\n",
    "#reinvestment_df.sample(1).T\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give ACS5 census variables human-readable names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "\n",
      "calculating and renaming estimates columns for IVs...\n",
      "...race, owner-occupied units, mfi...\n",
      "...high school graduates 25 years and older...\n",
      "...householder sex & race, unempoyment, poverty, home value, home age...\n",
      "\n",
      "calculating and renaming estimates columns for comparison variables...\n",
      "...race, owner-occupied units, mfi...\n",
      "...population 25plus...\n",
      "...labor force, poverty status known...\n",
      "\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# IV: population by race; owner-occupied units; MFI; hs grad pct (age 25 and older); \n",
    "### female hoh pct; unemployment pct (age 18 and older); poverty pct; median home value;\n",
    "### median home year built\n",
    "\n",
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "#metadata_df = metadata_df_bk\n",
    "#metadata_df = metadata_df.set_index('variable')\n",
    "\n",
    "print('\\ncalculating and renaming estimates columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B02001_002': 'pop_white',\n",
    "    'B02001_003': 'pop_black',\n",
    "    'B25003_002': 'owner_occ_housing_units',\n",
    "    'B19113_001': 'mfi'    \n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...high school graduates 25 years and older...')\n",
    "reinvestment_df = reinvestment_df.assign(hs_grad_25plus = pandas.to_numeric(reinvestment_df['B15002_011'] + reinvestment_df['B15002_028'], errors='coerce'))\n",
    "if (debug >= 1):\n",
    "    print('...householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {     \n",
    "    'B11001_006': 'female_householder',\n",
    "    'B11001B_001': 'black_householder',\n",
    "    'B11001H_001': 'white_householder',\n",
    "    'B23025_005': 'unemployed_16plus',\n",
    "    'B17001_002': 'poverty_past_12_months',\n",
    "    'B25077_001': 'median_home_value',\n",
    "    'B25035_001': 'median_year_built'\n",
    "})\n",
    "\n",
    "print('\\ncalculating and renaming estimates columns for comparison variables...')\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B01001_001': 'pop_total',\n",
    "    'B11001_001': 'total_householders',\n",
    "    'B17001_001': 'poverty_status_known_last12months_total'\n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_25plus = \n",
    "                                         pandas.to_numeric(\n",
    "                                             (reinvestment_df['B01001_011'] + reinvestment_df['B01001_012'] + reinvestment_df['B01001_013'] \n",
    "                                              + reinvestment_df['B01001_014'] + reinvestment_df['B01001_015'] + reinvestment_df['B01001_016']\n",
    "                                              + reinvestment_df['B01001_017'] + reinvestment_df['B01001_018'] + reinvestment_df['B01001_019']\n",
    "                                              + reinvestment_df['B01001_020'] + reinvestment_df['B01001_021'] + reinvestment_df['B01001_022']\n",
    "                                              + reinvestment_df['B01001_023'] + reinvestment_df['B01001_024'] + reinvestment_df['B01001_025']\n",
    "                                              + reinvestment_df['B01001_035'] + reinvestment_df['B01001_036'] + reinvestment_df['B01001_037']\n",
    "                                              + reinvestment_df['B01001_038'] + reinvestment_df['B01001_039'] + reinvestment_df['B01001_040']\n",
    "                                              + reinvestment_df['B01001_041'] + reinvestment_df['B01001_042'] + reinvestment_df['B01001_043']\n",
    "                                              + reinvestment_df['B01001_044'] + reinvestment_df['B01001_045'] + reinvestment_df['B01001_046']\n",
    "                                              + reinvestment_df['B01001_047'] + reinvestment_df['B01001_048'] + reinvestment_df['B01001_049']\n",
    "                                             ), errors='coerce'\n",
    "                                         )\n",
    "                                        )\n",
    "if (debug >= 1):\n",
    "    print('...labor force, poverty status known...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B23025_002': 'labor_force_16plus',\n",
    "    'B17001_001': 'poverty_status_known'\n",
    "})\n",
    "\n",
    "print('\\nbacking up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margins of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to calculate standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined standard-error-calculating functions!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "### Guide on how to calculate errors in percentages:\n",
    "# https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "    \n",
    "## Aggregating Data Across Population Subgroups: add error for each group in quadrature, divide by 1.645 for serr\n",
    "\n",
    "def find_serr_hsgrad25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B15002_011_err']**2 + row['B15002_028_err']**2) / 1.645, errors='coerce')\n",
    "\n",
    "def find_serr_pop25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B01001_011_err']**2 + row['B01001_012_err']**2 + row['B01001_013_err']**2 \n",
    "                                     + row['B01001_014_err']**2 + row['B01001_015_err']**2 + row['B01001_016_err']**2 \n",
    "                                     + row['B01001_017_err']**2 + row['B01001_018_err']**2 + row['B01001_019_err']**2 \n",
    "                                     + row['B01001_020_err']**2 + row['B01001_021_err']**2 + row['B01001_022_err']**2 \n",
    "                                     + row['B01001_023_err']**2 + row['B01001_024_err']**2 + row['B01001_025_err']**2 \n",
    "                                     + row['B01001_035_err']**2 + row['B01001_036_err']**2 + row['B01001_037_err']**2 \n",
    "                                     + row['B01001_038_err']**2 + row['B01001_039_err']**2 + row['B01001_040_err']**2 \n",
    "                                     + row['B01001_041_err']**2 + row['B01001_042_err']**2 + row['B01001_043_err']**2 \n",
    "                                     + row['B01001_044_err']**2 + row['B01001_045_err']**2 + row['B01001_046_err']**2 \n",
    "                                     + row['B01001_047_err']**2 + row['B01001_048_err']**2 + row['B01001_049_err']**2 \n",
    "                                    ) / 1.645, errors='coerce')\n",
    "print('Defined standard-error-calculating functions!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get margins of error for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "\n",
      "calculating and renaming margins of error columns for IVs...\n",
      "...margins for race, owner-occupied units, mfi...\n",
      "...standard errors for hs graduates 25 and older (using custom serr-finding function...\n",
      "...margins of error for householder sex & race, unempoyment, poverty, home value, home age...\n",
      "\n",
      "calculating and renaming margins of error for comparison variables...\n",
      "...race, owner-occupied units, mfi...\n",
      "...population 25plus...\n",
      "...labor force, poverty status known...\n",
      "\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "#metadata_df = metadata_df_bk\n",
    "#metadata_df = metadata_df.set_index('variable')\n",
    "\n",
    "print('\\ncalculating and renaming margins of error columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins for race, owner-occupied units, mfi...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B02001_002_err': 'pop_white_err',\n",
    "    'B02001_003_err': 'pop_black_err',\n",
    "    'B25003_002_err': 'owner_occ_housing_units_err',\n",
    "    'B19113_001_err': 'mfi_err'    \n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...standard errors for hs graduates 25 and older (using custom serr-finding function...')\n",
    "reinvestment_df = reinvestment_df.assign(hs_grad_25plus_serr = pandas.to_numeric(reinvestment_df.apply(lambda row: find_serr_hsgrad25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins of error for householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {     \n",
    "    'B11001_006_err': 'female_householder_err',\n",
    "    'B11001B_001_err': 'black_householder_err',\n",
    "    'B11001H_001_err': 'white_householder_err',\n",
    "    'B23025_005_err': 'unemployed_16plus_err',\n",
    "    'B17001_002_err': 'poverty_past_12_months_err',\n",
    "    'B25077_001_err': 'median_home_value_err',\n",
    "    'B25035_001_err': 'median_year_built_err'\n",
    "})\n",
    "\n",
    "print('\\ncalculating and renaming margins of error for comparison variables...')\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B01001_001_err': 'pop_total_err',\n",
    "    'B11001_001_err': 'total_householders_err',\n",
    "    'B17001_001_err': 'poverty_status_known_last12months_total_err'\n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_25plus_serr = pandas.to_numeric(reinvestment_df.apply(lambda row: find_serr_pop25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...labor force, poverty status known...')\n",
    "reinvestment_df = reinvestment_df.rename(columns = {\n",
    "    'B23025_002_err': 'labor_force_16plus_err',\n",
    "    'B17001_001_err': 'poverty_status_known_err'\n",
    "})\n",
    "\n",
    "print('\\nbacking up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "\n",
    "print('ok')\n",
    "#reinvestment_df.sample(1).T\n",
    "\n",
    "#reinvestment_df[['hs_grad_25plus', 'hs_grad_25plus_serr', 'pop_25plus', 'pop_25plus_serr']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional for later: drop partial variables used in calculations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "print('\\ndropping partial variables used in calculations...')\n",
    "reinvestment_df = reinvestment_df.drop(\n",
    "    [\n",
    "     'B15002_011', 'B15002_028', 'B01001_011', 'B01001_012', 'B01001_013', 'B01001_014', 'B01001_015', 'B01001_016', \n",
    "     'B01001_017', 'B01001_018', 'B01001_019', 'B01001_020', 'B01001_021', 'B01001_022', 'B01001_023', 'B01001_024', 'B01001_025', \n",
    "     'B01001_035', 'B01001_036', 'B01001_037', 'B01001_038', 'B01001_039', 'B01001_040', 'B01001_041', 'B01001_042',\n",
    "     'B01001_043', 'B01001_044', 'B01001_045', 'B01001_046', 'B01001_047', 'B01001_048', 'B01001_049'\n",
    "    ]\n",
    ", axis=1)\n",
    "reinvestment_df = reinvestment_df.drop(\n",
    "    [\n",
    "     'B15002_011', 'B15002_028', 'B01001_011', 'B01001_012', 'B01001_013', 'B01001_014', 'B01001_015', 'B01001_016', \n",
    "     'B01001_017', 'B01001_018', 'B01001_019', 'B01001_020', 'B01001_021', 'B01001_022', 'B01001_023', 'B01001_024', 'B01001_025', \n",
    "     'B01001_035', 'B01001_036', 'B01001_037', 'B01001_038', 'B01001_039', 'B01001_040', 'B01001_041', 'B01001_042',\n",
    "     'B01001_043', 'B01001_044', 'B01001_045', 'B01001_046', 'B01001_047', 'B01001_048', 'B01001_049'\n",
    "    ]\n",
    ", axis=1)\n",
    "\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "\n",
    "print('ok')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate percentages of each ACS5 variable \n",
    "\n",
    "For better direct comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pop_white',\n",
       " 'pop_black',\n",
       " 'black_householder',\n",
       " 'white_householder',\n",
       " 'owner_occ_housing_units',\n",
       " 'hs_grad_25plus',\n",
       " 'female_householder',\n",
       " 'unemployed_16plus',\n",
       " 'poverty_past_12_months',\n",
       " 'pop_white_err',\n",
       " 'pop_black_err',\n",
       " 'black_householder_err',\n",
       " 'white_householder_err',\n",
       " 'owner_occ_housing_units_err',\n",
       " 'hs_grad_25plus_serr',\n",
       " 'female_householder_err',\n",
       " 'unemployed_16plus_err',\n",
       " 'poverty_past_12_months_err',\n",
       " 'pop_total',\n",
       " 'total_householders',\n",
       " 'pop_25plus',\n",
       " 'labor_force_16plus',\n",
       " 'poverty_status_known_last12months_total',\n",
       " 'pop_total_err',\n",
       " 'total_householders_err',\n",
       " 'pop_25plus_serr',\n",
       " 'labor_force_16plus_err',\n",
       " 'poverty_status_known_last12months_total_err']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_for_percentification = ['pop_white', 'pop_black', 'black_householder', 'white_householder']\n",
    "vars_for_percentification += ['owner_occ_housing_units', 'hs_grad_25plus', 'female_householder']\n",
    "vars_for_percentification += ['unemployed_16plus', 'poverty_past_12_months']\n",
    "\n",
    "vars_for_percentification += ['pop_white_err', 'pop_black_err', 'black_householder_err', 'white_householder_err']\n",
    "vars_for_percentification += ['owner_occ_housing_units_err', 'hs_grad_25plus_serr', 'female_householder_err']\n",
    "vars_for_percentification += ['unemployed_16plus_err', 'poverty_past_12_months_err']\n",
    "\n",
    "vars_for_percentification += ['pop_total', 'total_householders', 'pop_25plus', 'labor_force_16plus']\n",
    "vars_for_percentification += ['poverty_status_known_last12months_total']\n",
    "\n",
    "vars_for_percentification += ['pop_total_err', 'total_householders_err', 'pop_25plus_serr', 'labor_force_16plus_err']\n",
    "vars_for_percentification += ['poverty_status_known_last12months_total_err']\n",
    "\n",
    "reinvestment_df[vars_for_percentification].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to calculate percentages in estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined functions to calculate percentages!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "def find_pop_white_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['pop_white'] / row['pop_total'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_pop_black_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['pop_black'] / row['pop_total'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_white_householder_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['white_householder'] / row['total_householders'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_black_householder_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['black_householder'] / row['total_householders'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_female_householder_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['female_householder'] / row['total_householders'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_hs_grad_25plus_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['hs_grad_25plus'] / row['pop_25plus'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_unemployed_16plus_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['unemployed_16plus'] / row['labor_force_16plus'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_poverty_past_12_months_pct(row):\n",
    "    try:\n",
    "        return pandas.to_numeric(row['poverty_past_12_months'] / row['poverty_status_known_last12months_total'], errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "    \n",
    "print('Defined functions to calculate percentages!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "\n",
      "calculating percentages...\n",
      "...white...\n",
      "...black...\n",
      "...white householder...\n",
      "...black householder...\n",
      "...female householder...\n",
      "...hs graduates age 25 and over...\n",
      "...unemployed age 16 and over...\n",
      "...poverty status last 12 months...\n",
      "\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "# compare to pop_total: pop_white, pop_black\n",
    "# compare to total_householders: black_householder, white_householder, female_householder\n",
    "# compare to pop_25plus: hs_grad_25plus\n",
    "# compare to labor_force_16plus: unemployed_16plus\n",
    "# compare to poverty_status_known_last12months_total: poverty_past_12_months\n",
    "\n",
    "print('\\ncalculating percentages...')\n",
    "print('...white...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_white_pct = reinvestment_df.apply(lambda row: find_pop_white_pct(row), axis=1))\n",
    "print('...black...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_black_pct = reinvestment_df.apply(lambda row: find_pop_black_pct(row), axis=1))\n",
    "print('...white householder...')\n",
    "reinvestment_df = reinvestment_df.assign(white_householder_pct = reinvestment_df.apply(lambda row: find_white_householder_pct(row), axis=1))\n",
    "print('...black householder...')\n",
    "reinvestment_df = reinvestment_df.assign(black_householder_pct = reinvestment_df.apply(lambda row: find_black_householder_pct(row), axis=1))\n",
    "print('...female householder...')\n",
    "reinvestment_df = reinvestment_df.assign(female_householder_pct = reinvestment_df.apply(lambda row: find_female_householder_pct(row), axis=1))\n",
    "\n",
    "print('...hs graduates age 25 and over...')\n",
    "reinvestment_df = reinvestment_df.assign(hs_grad_25plus_pct = reinvestment_df.apply(lambda row: find_hs_grad_25plus_pct(row), axis=1))\n",
    "print('...unemployed age 16 and over...')\n",
    "reinvestment_df = reinvestment_df.assign(unemployed_16plus_pct = reinvestment_df.apply(lambda row: find_unemployed_16plus_pct(row), axis=1))\n",
    "print('...poverty status last 12 months...')\n",
    "reinvestment_df = reinvestment_df.assign(poverty_past_12_months_pct = reinvestment_df.apply(lambda row: find_poverty_past_12_months_pct(row), axis=1))\n",
    "\n",
    "print('\\nbacking up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "\n",
    "percentified_vars = ['pop_white_pct', 'pop_black_pct', 'white_householder_pct', 'black_householder_pct', 'hs_grad_25plus_pct', 'unemployed_16plus_pct', 'poverty_past_12_months_pct']\n",
    "#reinvestment_df[percentified_vars]\n",
    "print('ok')\n",
    "#reinvestment_df[vars_for_percentification].sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margins of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to calculate standard errors in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined functions to calculate standard errors in percentages!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Guide on how to do this:\n",
    "#### https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "\n",
    "# X and Y are the measured values (not the errors) - X for the subsgroup and Y for the whole sample\n",
    "# Let P = X/Y  (the proportion we calculated in the last step)\n",
    "# dX and dY are the measured errors\n",
    "# dP = (1/Y) * np.sqrt(dX**2 - (P**2 * dY**2))\n",
    "# Standard error of P is dP/1.645\n",
    "#### this calculation is done verbosely in fnid_pop_white_serr, quickly in other functions\n",
    "\n",
    "def find_pop_white_pct_serr(row, verboselevel = 0):\n",
    "    X = row['pop_white']\n",
    "    dX = row['pop_white_err']\n",
    "    Y = row['pop_total']\n",
    "    dY = row['pop_total_err']\n",
    "    try:\n",
    "        P = X / Y\n",
    "        oneoverY = 1 / Y\n",
    "        dXsq = dX**2\n",
    "        dYsq = dY**2\n",
    "        Psq = P**2\n",
    "        PsqdYsq = Psq * dYsq\n",
    "        if (PsqdYsq <= dXsq):\n",
    "            underroot = dXsq - PsqdYsq\n",
    "        else:\n",
    "            underroot = dXsq + PsqdYsq\n",
    "        rooty = np.sqrt(underroot)\n",
    "        dP = oneoverY * rooty\n",
    "        SE = dP / 1.645\n",
    "        if (verboselevel >= 2):\n",
    "            print('\\n')\n",
    "            print('Census tract {0:} in year {1:.0f}:'.format(row.name[0], row.name[1]))\n",
    "            print('X = pop_white, Y = pop_total')\n",
    "            print('X = {0:.0f}, dX = {1:.0f} ({2:.1%} error)'.format(X, dX, dX/X))\n",
    "            print('Y = {0:.0f}, dY = {1:.0f} ({2:.1%} error)'.format(Y, dY, dY/Y))\n",
    "            print('P = {0:.3f}'.format(P))\n",
    "            print('dXsq = {0:.0f}, dYsq = {1:.0f}, Psq = {2:.3f}'.format(dXsq, dYsq, Psq))\n",
    "            print('PsqdYsq = {0:.0f}, underroot = {1:.0f}, rooty = {2:.3f}'.format(PsqdYsq, underroot, rooty))\n",
    "            print('dP = {0:.3f}'.format(dP))\n",
    "            print('SE = {0:.3f}'.format(SE))\n",
    "        if (verboselevel >= 1):\n",
    "            print('RESULT: {0:.2%} +/- {1:.2%}'.format(P, SE)) \n",
    "        return pandas.to_numeric(SE, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_pop_black_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['pop_black'] / row['pop_total'])**2) * (row['pop_total_err']**2)) <= (row['pop_black_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['pop_total']) * np.sqrt((row['pop_black_err']**2) - (((row['pop_black'] / row['pop_total'])**2) * (row['pop_total_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['pop_total']) * np.sqrt((row['pop_black_err']**2) + (((row['pop_black'] / row['pop_total'])**2) * (row['pop_total_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "    \n",
    "def find_white_householder_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['white_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)) <= (row['white_householder_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['white_householder_err']**2) - (((row['white_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['white_householder_err']**2) + (((row['white_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_black_householder_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['black_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)) <= (row['black_householder_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['black_householder_err']**2) - (((row['black_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['black_householder_err']**2) + (((row['black_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "def find_female_householder_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['female_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)) <= (row['female_householder_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['female_householder_err']**2) - (((row['female_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['total_householders']) * np.sqrt((row['female_householder_err']**2) + (((row['female_householder'] / row['total_householders'])**2) * (row['total_householders_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_hs_grad_25plus_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['hs_grad_25plus'] / row['pop_25plus'])**2) * (row['pop_25plus_serr']**2)) <= (row['hs_grad_25plus_serr']**2)):\n",
    "            return pandas.to_numeric(((1 / row['pop_25plus']) * np.sqrt((row['hs_grad_25plus_serr']**2) - (((row['hs_grad_25plus'] / row['pop_25plus'])**2) * (row['pop_25plus_serr']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['pop_25plus']) * np.sqrt((row['hs_grad_25plus_serr']**2) + (((row['hs_grad_25plus'] / row['pop_25plus'])**2) * (row['pop_25plus_serr']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_unemployed_16plus_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['unemployed_16plus'] / row['labor_force_16plus'])**2) * (row['labor_force_16plus_err']**2)) <= (row['unemployed_16plus_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['labor_force_16plus']) * np.sqrt((row['unemployed_16plus_err']**2) - (((row['unemployed_16plus'] / row['labor_force_16plus'])**2) * (row['labor_force_16plus_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['labor_force_16plus']) * np.sqrt((row['unemployed_16plus_err']**2) + (((row['unemployed_16plus'] / row['labor_force_16plus'])**2) * (row['labor_force_16plus_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "def find_poverty_past_12_months_pct_serr(row):\n",
    "    try:\n",
    "        if ((((row['poverty_past_12_months'] / row['poverty_status_known_last12months_total'])**2) * (row['poverty_status_known_last12months_total_err']**2)) <= (row['poverty_past_12_months_err']**2)):\n",
    "            return pandas.to_numeric(((1 / row['poverty_status_known_last12months_total']) * np.sqrt((row['poverty_past_12_months']**2) - (((row['poverty_past_12_months'] / row['poverty_status_known_last12months_total'])**2) * (row['poverty_status_known_last12months_total_err']**2)))) / 1.645, errors='coerce')\n",
    "        else:\n",
    "            return pandas.to_numeric(((1 / row['poverty_status_known_last12months_total']) * np.sqrt((row['poverty_past_12_months']**2) + (((row['poverty_past_12_months'] / row['poverty_status_known_last12months_total'])**2) * (row['poverty_status_known_last12months_total_err']**2)))) / 1.645, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "# compare to poverty_status_known_last12months_total: poverty_past_12_months\n",
    "\n",
    "print('Defined functions to calculate standard errors in percentages!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate standard errors in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "\n",
      "calculating standard errors in percentages...\n",
      "...white...\n",
      "...black...\n",
      "...white householder...\n",
      "...black householder...\n",
      "...female householder...\n",
      "...high school graduate 25 years or over...\n",
      "...unemployed 16 years or over...\n",
      "...in poverty last 12 months...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "print('\\ncalculating standard errors in percentages...')\n",
    "\n",
    "print('...white...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_white_pct_serr = reinvestment_df.apply(lambda row: find_pop_white_pct_serr(row, verboselevel=0), axis=1))\n",
    "print('...black...')\n",
    "reinvestment_df = reinvestment_df.assign(pop_black_pct_serr = reinvestment_df.apply(lambda row: find_pop_black_pct_serr(row), axis=1))\n",
    "\n",
    "print('...white householder...')\n",
    "reinvestment_df = reinvestment_df.assign(white_householder_pct_serr = reinvestment_df.apply(lambda row: find_white_householder_pct_serr(row), axis=1))\n",
    "print('...black householder...')\n",
    "reinvestment_df = reinvestment_df.assign(black_householder_pct_serr = reinvestment_df.apply(lambda row: find_black_householder_pct_serr(row), axis=1))\n",
    "print('...female householder...')\n",
    "reinvestment_df = reinvestment_df.assign(female_householder_pct_serr = reinvestment_df.apply(lambda row: find_female_householder_pct_serr(row), axis=1))\n",
    "\n",
    "print('...high school graduate 25 years or over...')\n",
    "reinvestment_df = reinvestment_df.assign(hs_grad_25plus_pct_serr = reinvestment_df.apply(lambda row: find_hs_grad_25plus_pct_serr(row), axis=1))\n",
    "print('...unemployed 16 years or over...')\n",
    "reinvestment_df = reinvestment_df.assign(unemployed_16plus_pct_serr = reinvestment_df.apply(lambda row: find_unemployed_16plus_pct_serr(row), axis=1))\n",
    "print('...in poverty last 12 months...')\n",
    "reinvestment_df = reinvestment_df.assign(poverty_past_12_months_pct_serr = reinvestment_df.apply(lambda row: find_poverty_past_12_months_pct_serr(row), axis=1))\n",
    "\n",
    "#reinvestment_df[['pop_total', 'pop_total_err', 'pop_white', 'pop_white_err', 'pop_white_pct', 'pop_white_pct_serr']]\n",
    "#reinvestment_df[['poverty_past_12_months_pct', 'poverty_past_12_months_pct_serr']]\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add working loans column (ask Mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "reinvestment_df = reinvestment_df.assign(avgSmallLoan = reinvestment_df['amtLoans1'] / reinvestment_df['nLoans1'])\n",
    "\n",
    "reinvestment_df = reinvestment_df.assign(nWorkingLoans = reinvestment_df['nLoansTotal'][reinvestment_df['avgSmallLoan'] < 10000] - reinvestment_df['nLoans1'][reinvestment_df['avgSmallLoan'] < 10000])\n",
    "reinvestment_df.loc[reinvestment_df['nWorkingLoans'].isnull(), 'nWorkingLoans'] = reinvestment_df['nLoansTotal']\n",
    "\n",
    "reinvestment_df = reinvestment_df.assign(amtWorkingLoans = reinvestment_df['amtLoansTotal'][reinvestment_df['avgSmallLoan'] < 10000] - reinvestment_df['amtLoans1'][reinvestment_df['avgSmallLoan'] < 10000])\n",
    "reinvestment_df.loc[reinvestment_df['amtWorkingLoans'].isnull(), 'amtWorkingLoans'] = reinvestment_df['amtLoansTotal']\n",
    "\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add number of jobs per census tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading job data...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "raw_jobs_df = pandas.read_csv(datadir+'md_wac_S000_JT02_2010_to_2015.csv')\n",
    "raw_jobs_df.columns = [x.strip() for x in raw_jobs_df.columns.tolist()]\n",
    "\n",
    "# GeoID format is STATE+COUNTY+TRACT+BLOCK (2+3+6+4 = 15 characters)\n",
    "raw_jobs_df = raw_jobs_df.assign(census_tract = pandas.to_numeric(raw_jobs_df['Workplace Census Block Code'].apply(lambda x: str(x)[5:9] + '.' + str(x)[9:11]), errors='coerce'))\n",
    "sum_columns = [x for x in raw_jobs_df.columns.tolist() if x not in ('Workplace Census Block Code', 'Year')]\n",
    "\n",
    "jobs_df = pandas.DataFrame()\n",
    "for i in range(2010,2018):\n",
    "    jobs_i_df = raw_jobs_df[sum_columns][raw_jobs_df['Year'] == i].groupby('census_tract', as_index=False).sum()\n",
    "    if (i >= 2016):\n",
    "        jobs_i_df = raw_jobs_df[sum_columns][raw_jobs_df['Year'] == 2015].groupby('census_tract', as_index=False).sum()\n",
    "    jobs_i_df = jobs_i_df.assign(Year = i)\n",
    "    jobs_df = pandas.concat((jobs_df, jobs_i_df), axis=0)\n",
    "\n",
    "jobs_df = jobs_df.rename(columns={'Year': 'activity_year'})\n",
    "jobs_df = jobs_df.set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('backing up...')\n",
    "jobs_df_bk = jobs_df\n",
    "print('ok')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge reinvestment data with jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieiving from backup...\n",
      "backing up...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('retrieiving from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "reinvestment_df = reinvestment_df.reset_index().merge(jobs_df.reset_index(), how='left').set_index(['census_tract', 'activity_year'])\n",
    "#    #(reinvestment_df['activity_year'] == 2015) & \n",
    "#    #(reinvestment_df['census_tract'] <= 900)\n",
    "#    jobs_df, how='left'\n",
    "#)[['census_tract', 'activity_year', 'nWorkingLoans', 'Total number of jobs']]\n",
    "#reinvestment_df\n",
    "#jobs_df\n",
    "\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "#reinvestment_df.sample(1).T\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize loans by number of jobs at firms with firms of 0-19 employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "reinvestment_df = reinvestment_df.assign(nLoans1_per_sbjob = reinvestment_df['nLoans1'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtLoans1_per_sbjob = reinvestment_df['amtLoans1'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(nLoans100k_per_sbjob = reinvestment_df['nLoans100k'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtLoans100k_per_sbjob = reinvestment_df['amtLoans100k'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(nLoans250k_per_sbjob = reinvestment_df['nLoans250k'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtLoans250k_per_sbjob = reinvestment_df['amtLoans250k'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(nLoansToSmallest_per_sbjob = reinvestment_df['nLoansToSmallest'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtLoansToSmallest_per_sbjob = reinvestment_df['amtLoansToSmallest'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(nLoansTotal_per_sbjob = reinvestment_df['nLoansTotal'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtLoansTotal_per_sbjob = reinvestment_df['amtLoansTotal'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(nWorkingLoans_per_sbjob = reinvestment_df['nWorkingLoans'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "reinvestment_df = reinvestment_df.assign(amtWorkingLoans_per_sbjob = reinvestment_df['amtWorkingLoans'] / reinvestment_df['Number of jobs for workers at firms with Firm Size: 0-19 Employees'])\n",
    "\n",
    "\n",
    "#reinvestment_df['amtWorkingLoans_per_job']\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from backup...\n",
      "getting inflation data...\n",
      "inflating pre-2017 monetary values...\n",
      "joining...\n",
      "backing up...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#reinvestment_df.columns.tolist()\n",
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest']\n",
    "money_columns += ['amtLoansTotal', 'amtWorkingLoans']\n",
    "money_columns += ['mfi', 'median_home_value']\n",
    "money_columns += ['amtLoans1_per_sbjob', 'amtLoans100k_per_sbjob', 'amtLoans250k_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "money_columns += ['amtLoansTotal_per_sbjob', 'amtWorkingLoans_per_sbjob']\n",
    "\n",
    "print('getting inflation data...')\n",
    "cpi_1913_2017_df = pandas.read_csv(inflation_dir+'cpi-1913-2017.csv', index_col='Year')\n",
    "cpi_annual_s = cpi_1913_2017_df['Jan']\n",
    "cpi_annual_s.name = 'rawfactor'\n",
    "value_in_2017 = cpi_annual_s.loc[2017]\n",
    "annual_inflator_s = 1 / (cpi_annual_s / value_in_2017)\n",
    "annual_inflator_s\n",
    "\n",
    "print('inflating pre-2017 monetary values...')\n",
    "inflate_these_df = reinvestment_df[money_columns]\n",
    "\n",
    "newcolnames = [x+'_adj' for x in inflate_these_df.columns.tolist()]\n",
    "inflate_these_df.columns = newcolnames\n",
    "\n",
    "inflated_df = pandas.DataFrame()\n",
    "\n",
    "#inflate_these_df.xs(2017, level=1).apply(lambda x: x * annual_inflator_s.loc[2017])\n",
    "#annual_inflator_s\n",
    "for i in inflate_these_df.index.get_level_values(1).drop_duplicates().tolist():\n",
    "    inflated_df_i = inflate_these_df.xs(i, level=1).apply(lambda x: x * annual_inflator_s.loc[i])\n",
    "    inflated_df_i['activity_year'] = i\n",
    "    inflated_df = pandas.concat((inflated_df, inflated_df_i), axis=0)\n",
    "inflated_df = inflated_df.reset_index().set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('joining...')\n",
    "reinvestment_df = reinvestment_df.join(inflated_df, how='left')\n",
    "\n",
    "print('backing up...')\n",
    "reinvestment_df_bk = reinvestment_df\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing outfile...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('writing outfile...')\n",
    "reinvestment_df.to_csv(outdir+'reinvestment_by_census_tract_for_smallest_businesses.csv', encoding='utf-8')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income_group_code',\n",
       " 'nLoans1',\n",
       " 'amtLoans1',\n",
       " 'nLoans100k',\n",
       " 'amtLoans100k',\n",
       " 'nLoans250k',\n",
       " 'amtLoans250k',\n",
       " 'nLoansToSmallest',\n",
       " 'amtLoansToSmallest',\n",
       " 'nLoansTotal',\n",
       " 'amtLoansTotal',\n",
       " 'CSA2010',\n",
       " 'income_group',\n",
       " 'cra_level',\n",
       " 'GEOID',\n",
       " 'STUSAB',\n",
       " 'LOGRECNO',\n",
       " 'pop_total',\n",
       " 'total_householders',\n",
       " 'pop_white',\n",
       " 'pop_black',\n",
       " 'black_householder',\n",
       " 'white_householder',\n",
       " 'owner_occ_housing_units',\n",
       " 'mfi',\n",
       " 'B15002_011',\n",
       " 'B15002_028',\n",
       " 'female_householder',\n",
       " 'unemployed_16plus',\n",
       " 'poverty_past_12_months',\n",
       " 'median_home_value',\n",
       " 'median_year_built',\n",
       " 'B01001_011',\n",
       " 'B01001_012',\n",
       " 'B01001_013',\n",
       " 'B01001_014',\n",
       " 'B01001_015',\n",
       " 'B01001_016',\n",
       " 'B01001_017',\n",
       " 'B01001_018',\n",
       " 'B01001_019',\n",
       " 'B01001_020',\n",
       " 'B01001_021',\n",
       " 'B01001_022',\n",
       " 'B01001_023',\n",
       " 'B01001_024',\n",
       " 'B01001_025',\n",
       " 'B01001_035',\n",
       " 'B01001_036',\n",
       " 'B01001_037',\n",
       " 'B01001_038',\n",
       " 'B01001_039',\n",
       " 'B01001_040',\n",
       " 'B01001_041',\n",
       " 'B01001_042',\n",
       " 'B01001_043',\n",
       " 'B01001_044',\n",
       " 'B01001_045',\n",
       " 'B01001_046',\n",
       " 'B01001_047',\n",
       " 'B01001_048',\n",
       " 'B01001_049',\n",
       " 'labor_force_16plus',\n",
       " 'poverty_status_known_last12months_total',\n",
       " 'pop_total_err',\n",
       " 'total_householders_err',\n",
       " 'pop_white_err',\n",
       " 'pop_black_err',\n",
       " 'black_householder_err',\n",
       " 'white_householder_err',\n",
       " 'owner_occ_housing_units_err',\n",
       " 'mfi_err',\n",
       " 'B15002_011_err',\n",
       " 'B15002_028_err',\n",
       " 'female_householder_err',\n",
       " 'unemployed_16plus_err',\n",
       " 'poverty_past_12_months_err',\n",
       " 'median_home_value_err',\n",
       " 'median_year_built_err',\n",
       " 'B01001_011_err',\n",
       " 'B01001_012_err',\n",
       " 'B01001_013_err',\n",
       " 'B01001_014_err',\n",
       " 'B01001_015_err',\n",
       " 'B01001_016_err',\n",
       " 'B01001_017_err',\n",
       " 'B01001_018_err',\n",
       " 'B01001_019_err',\n",
       " 'B01001_020_err',\n",
       " 'B01001_021_err',\n",
       " 'B01001_022_err',\n",
       " 'B01001_023_err',\n",
       " 'B01001_024_err',\n",
       " 'B01001_025_err',\n",
       " 'B01001_035_err',\n",
       " 'B01001_036_err',\n",
       " 'B01001_037_err',\n",
       " 'B01001_038_err',\n",
       " 'B01001_039_err',\n",
       " 'B01001_040_err',\n",
       " 'B01001_041_err',\n",
       " 'B01001_042_err',\n",
       " 'B01001_043_err',\n",
       " 'B01001_044_err',\n",
       " 'B01001_045_err',\n",
       " 'B01001_046_err',\n",
       " 'B01001_047_err',\n",
       " 'B01001_048_err',\n",
       " 'B01001_049_err',\n",
       " 'labor_force_16plus_err',\n",
       " 'poverty_status_known_last12months_total_err',\n",
       " 'State',\n",
       " 'Logical Record Number',\n",
       " 'Geography Name',\n",
       " 'hs_grad_25plus',\n",
       " 'pop_25plus',\n",
       " 'hs_grad_25plus_serr',\n",
       " 'pop_25plus_serr',\n",
       " 'pop_white_pct',\n",
       " 'pop_black_pct',\n",
       " 'white_householder_pct',\n",
       " 'black_householder_pct',\n",
       " 'female_householder_pct',\n",
       " 'hs_grad_25plus_pct',\n",
       " 'unemployed_16plus_pct',\n",
       " 'poverty_past_12_months_pct',\n",
       " 'pop_white_pct_serr',\n",
       " 'pop_black_pct_serr',\n",
       " 'white_householder_pct_serr',\n",
       " 'black_householder_pct_serr',\n",
       " 'female_householder_pct_serr',\n",
       " 'hs_grad_25plus_pct_serr',\n",
       " 'unemployed_16plus_pct_serr',\n",
       " 'poverty_past_12_months_pct_serr',\n",
       " 'avgSmallLoan',\n",
       " 'nWorkingLoans',\n",
       " 'amtWorkingLoans',\n",
       " 'Total number of jobs',\n",
       " 'Number of jobs for workers age 29 or younger',\n",
       " 'Number of jobs for workers age 30 to 54',\n",
       " 'Number of jobs for workers age 55 or older',\n",
       " 'Number of jobs with earnings $1250/month or less',\n",
       " 'Number of jobs with earnings $1251/month to $3333/month',\n",
       " 'Number of jobs with earnings greater than $3333/month',\n",
       " 'Number of jobs in NAICS sector 11 (Agriculture, Forestry, Fishing and Hunting)',\n",
       " 'Number of jobs in NAICS sector 21 (Mining, Quarrying, and Oil and Gas Extraction)',\n",
       " 'Number of jobs in NAICS sector 22 (Utilities)',\n",
       " 'Number of jobs in NAICS sector 23 (Construction)',\n",
       " 'Number of jobs in NAICS sector 31-33 (Manufacturing)',\n",
       " 'Number of jobs in NAICS sector 42 (Wholesale Trade)',\n",
       " 'Number of jobs in NAICS sector 44-45 (Retail Trade)',\n",
       " 'Number of jobs in NAICS sector 48-49 (Transportation and Warehousing)',\n",
       " 'Number of jobs in NAICS sector 51 (Information)',\n",
       " 'Number of jobs in NAICS sector 52 (Finance and Insurance)',\n",
       " 'Number of jobs in NAICS sector 53 (Real Estate and Rental and Leasing)',\n",
       " 'Number of jobs in NAICS sector 54 (Professional, Scientific, and Technical Services)',\n",
       " 'Number of jobs in NAICS sector 55 (Management of Companies and Enterprises)',\n",
       " 'Number of jobs in NAICS sector 56 (Administrative and Support and Waste Management and Remediation Services)',\n",
       " 'Number of jobs in NAICS sector 61 (Educational Services)',\n",
       " 'Number of jobs in NAICS sector 62 (Health Care and Social Assistance)',\n",
       " 'Number of jobs in NAICS sector 71 (Arts, Entertainment, and Recreation)',\n",
       " 'Number of jobs in NAICS sector 72 (Accommodation and Food Services)',\n",
       " 'Number of jobs in NAICS sector 81 (Other Services [except Public Administration])',\n",
       " 'Number of jobs in NAICS sector 92 (Public Administration)',\n",
       " 'Number of jobs for workers with Race: White, Alone',\n",
       " 'Number of jobs for workers with Race: Black or African American Alone',\n",
       " 'Number of jobs for workers with Race: American Indian or Alaska Native Alone',\n",
       " 'Number of jobs for workers with Race: Asian Alone',\n",
       " 'Number of jobs for workers with Race: Native Hawaiian or Other Pacific Islander Alone',\n",
       " 'Number of jobs for workers with Race: Two or More Race Groups',\n",
       " 'Number of jobs for workers with Ethnicity: Not Hispanic or Latino',\n",
       " 'Number of jobs for workers with Ethnicity: Hispanic or Latino',\n",
       " 'Number of jobs for workers with Educational Attainment: Less than high school',\n",
       " 'Number of jobs for workers with Educational Attainment: High school or equivalent, no college',\n",
       " 'Number of jobs for workers with Educational Attainment: Some college or Associate degree',\n",
       " \"Number of jobs for workers with Educational Attainment: Bachelor's degree or advanced degree\",\n",
       " 'Number of jobs for workers with Sex: Male',\n",
       " 'Number of jobs for workers with Sex: Female',\n",
       " 'Number of jobs for workers at firms with Firm Age: 0-1 Years',\n",
       " 'Number of jobs for workers at firms with Firm Age: 2-3 Years',\n",
       " 'Number of jobs for workers at firms with Firm Age: 4-5 Years',\n",
       " 'Number of jobs for workers at firms with Firm Age: 6-10 Years',\n",
       " 'Number of jobs for workers at firms with Firm Age: 11+ Years',\n",
       " 'Number of jobs for workers at firms with Firm Size: 0-19 Employees',\n",
       " 'Number of jobs for workers at firms with Firm Size: 20-49 Employees',\n",
       " 'Number of jobs for workers at firms with Firm Size: 50-249 Employees',\n",
       " 'Number of jobs for workers at firms with Firm Size: 250-499 Employees',\n",
       " 'Number of jobs for workers at firms with Firm Size: 500+ Employees',\n",
       " 'nLoans1_per_sbjob',\n",
       " 'amtLoans1_per_sbjob',\n",
       " 'nLoans100k_per_sbjob',\n",
       " 'amtLoans100k_per_sbjob',\n",
       " 'nLoans250k_per_sbjob',\n",
       " 'amtLoans250k_per_sbjob',\n",
       " 'nLoansToSmallest_per_sbjob',\n",
       " 'amtLoansToSmallest_per_sbjob',\n",
       " 'nLoansTotal_per_sbjob',\n",
       " 'amtLoansTotal_per_sbjob',\n",
       " 'nWorkingLoans_per_sbjob',\n",
       " 'amtWorkingLoans_per_sbjob',\n",
       " 'amtLoans1_adj',\n",
       " 'amtLoans100k_adj',\n",
       " 'amtLoans250k_adj',\n",
       " 'amtLoansToSmallest_adj',\n",
       " 'amtLoansTotal_adj',\n",
       " 'amtWorkingLoans_adj',\n",
       " 'mfi_adj',\n",
       " 'median_home_value_adj',\n",
       " 'amtLoans1_per_sbjob_adj',\n",
       " 'amtLoans100k_per_sbjob_adj',\n",
       " 'amtLoans250k_per_sbjob_adj',\n",
       " 'amtLoansToSmallest_per_sbjob_adj',\n",
       " 'amtLoansTotal_per_sbjob_adj',\n",
       " 'amtWorkingLoans_per_sbjob_adj']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(outdir+'reinvestment_by_census_tract_for_smallest_businesses.csv', encoding='utf-8', index_col=['census_tract', 'activity_year'])\n",
    "#df = df.set_index(['census_tract', 'activity_year'])\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read some other datasets useful for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading city boundary...')\n",
    "outline_filename = shapefile_basedir + 'baltimore_city_polygon/baltimore_city_polygon.shp'\n",
    "city_outline_gdf = geopandas.read_file(outline_filename)\n",
    "city_outline_gdf = city_outline_gdf.to_crs(tract_shapes_gdf.crs)\n",
    "\n",
    "print('Reading water features...')\n",
    "water_filename = shapefile_basedir + 'water/water.shp'\n",
    "water_gdf = geopandas.read_file(water_filename)\n",
    "water_gdf = water_gdf.set_index('OBJECTID')\n",
    "water_gdf = water_gdf.to_crs(tract_shapes_gdf.crs)\n",
    "\n",
    "\n",
    "print('Finding location of JHU...')\n",
    "businesses = []\n",
    "biz1dict = {'name': 'Johns Hopkins University', 'address': '3400 N. Charles St. Baltimore, MD'}\n",
    "#businesses.append(biz1dict)\n",
    "#biz2dict = {'name': 'Refereshing Life Ministries', 'address': '2603 Baker St. Baltimore, MD'}\n",
    "#businesses.append(biz2dict)\n",
    "g = geocoder.bing(biz1dict['address'], key='Agrc_VFxa6iK3mVYNIC1Mcao2TwVTPG5tDbok7UbDcCYf5PRGmnaeLF_Wm_znHeo')\n",
    "thegeometry = Point(g.latlng)\n",
    "g_df = pandas.DataFrame(data=g.latlng)\n",
    "g_df = g_df.T\n",
    "g_df = g_df.rename(columns={0: 'lat', 1: 'long'})\n",
    "g_df = g_df.assign(geometry=Point(g_df['long'], g_df['lat']))\n",
    "g_gdf = geopandas.GeoDataFrame(data=g_df, geometry='geometry')\n",
    "g_gdf.crs = {'init': 'epsg:4326'}\n",
    "g_gdf = g_gdf.to_crs(tract_shapes_gdf.crs)\n",
    "\n",
    "print('Reading streets...')\n",
    "s = time.time()\n",
    "streets_filename = shapefile_basedir + 'streets/streetcl.shp'\n",
    "streets_gdf = geopandas.read_file(streets_filename)\n",
    "streets_gdf = streets_gdf.set_index('OBJECTID')\n",
    "streets_gdf = streets_gdf.to_crs(tract_shapes_gdf.crs)\n",
    "e = time.time()\n",
    "print('Read {0:,.0f} street centerlines in {1:,.1f} seconds.'.format(len(streets_gdf), e-s))\n",
    "\n",
    "print('Done!')\n",
    "#g_gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "scale = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(48*scale,48*scale))\n",
    "\n",
    "\n",
    "xdf = df.xs(thisyear, level=1).reset_index().merge(tract_shapes_gdf, how='left', on='census_tract').set_index('census_tract')\n",
    "\n",
    "xgdf = geopandas.GeoDataFrame(xdf)\n",
    "xgdf.crs = tract_shapes_gdf.crs    \n",
    "\n",
    "xgdf.plot(column='amtWorkingLoans_per_job_adj', ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "ax.set_title(thisyear, fontsize=14*scale)\n",
    "#reinvestment_df_temp = pandas.concat((reinvestment_df_temp, xdf), axis=0, sort=False)\n",
    "\n",
    "#plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False))\n",
    "#reinvestment_2017_d\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs(thisyear, level=1).reset_index().merge(tract_shapes_gdf, how='left', on='census_tract').set_index('census_tract')['amtWorkingLoans_per_job_adj'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to show each year on a single big-ass page of maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "fig, axs = plt.subplots(1,7, figsize=(24,12))\n",
    "\n",
    "thisyear = 2017\n",
    "\n",
    "cnt = 0\n",
    "for i in range(2017, 2010, -1):\n",
    "    if (debug > 0):\n",
    "        print('joining shapefiles for {0:.0f}...'.format(i))\n",
    "    tract_shapes_gdf = geopandas.read_file(census_shapefile_tiger_basedir +'{0:.0f}/TRACT/tl_{0:.0f}_24_tract.shp'.format(thisyear))    \n",
    "    tract_shapes_gdf = tract_shapes_gdf[tract_shapes_gdf['COUNTYFP'] == '510']\n",
    "    tract_shapes_gdf.loc[:, 'NAME'] = pandas.to_numeric(tract_shapes_gdf['NAME'], errors='coerce')\n",
    "    tract_shapes_gdf = tract_shapes_gdf.assign(census_tract = pandas.to_numeric(tract_shapes_gdf['GEOID'].apply(lambda x: x[5:9]+'.'+x[9:]), errors='coerce'))\n",
    "\n",
    "    xdf = reinvestment_df.xs(i, level=1).reset_index().merge(tract_shapes_gdf, how='left', on='census_tract').set_index('census_tract')\n",
    "\n",
    "    xgdf = geopandas.GeoDataFrame(xdf)\n",
    "    xgdf.crs = tract_shapes_gdf.crs    \n",
    "    xgdf.plot(column='amtWorkingLoans_per_job_adj', ax=axs[cnt])\n",
    "    axs[cnt].set_aspect('equal')\n",
    "    axs[cnt].tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "    axs[cnt].set_title(i, fontsize=14)\n",
    "    cnt = cnt + 1    \n",
    "#reinvestment_df_temp = pandas.concat((reinvestment_df_temp, xdf), axis=0, sort=False)\n",
    "\n",
    "#plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False))\n",
    "#reinvestment_2017_d\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('getting from backup...')\n",
    "reinvestment_df = reinvestment_df_bk\n",
    "\n",
    "\n",
    "#levels_show_df = reinvestment_df.groupby('cra_level')[['amtWorkingLoans_per_job_adj']].sum()\n",
    "levels_show_index = pandas.Index(reinvestment_df['cra_level'].drop_duplicates().values)\n",
    "levels_show_df = pandas.DataFrame(data=None, columns=None, index=levels_show_index)\n",
    "levels_show_df = levels_show_df.reindex(['low', 'moderate', 'middle', 'upper', 'unknown'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
