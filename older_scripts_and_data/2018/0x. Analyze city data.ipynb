{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import geopandas\n",
    "import scipy.stats\n",
    "from pprint import pprint\n",
    "\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "data_dir = thisdir + 'final_data/'\n",
    "figdir = thisdir + 'figures_final/'\n",
    "\n",
    "baltimore_shapefile_basedir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "\n",
    "# ANALYSIS OPTIONS\n",
    "sb_jobs_lower_limit = 10\n",
    "pop_lower_limit = 1000\n",
    "tol = 8100  # Tolerance for declaring a tract is contained in a city council district\n",
    "summary = {}\n",
    "\n",
    "\n",
    "# MAPPING OPTIONS\n",
    "scale = 1\n",
    "thecolormap = 'viridis'\n",
    "show_tract_labels = True\n",
    "show_plot_labels = True\n",
    "\n",
    "g = 0\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Baltimore!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "city = 'Baltimore'\n",
    "\n",
    "if (city == 'Cleveland'):\n",
    "    projection = {'init': 'EPSG:3734'}\n",
    "elif (city == 'Baltimore' or city == 'Washington DC'):\n",
    "    projection = {'init': 'EPSG:6487'}\n",
    "elif (city == 'Detroit'):\n",
    "    projection = {'init': 'EPSG:2253'}\n",
    "elif (city == 'Newark'):\n",
    "    projection = {'init': 'EPSG:3424'}\n",
    "    \n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Selected {0:}!'.format(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 400 rows and 185 columns in 0 minutes 2 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "raw_data_gdf = geopandas.read_file(data_dir+'{0:}_alldata.shp'.format(city.lower().replace(' ', '_')))\n",
    "colnames_df = pandas.read_csv(data_dir+'column_names.csv', encoding='utf-8', low_memory=False, index_col=\"variable_name\")\n",
    "\n",
    "column_names = colnames_df.index.tolist()\n",
    "for i in range(0, len(raw_data_gdf.columns)-1, 1):\n",
    "    raw_data_gdf = raw_data_gdf.rename(columns = {str(i): column_names[i]})\n",
    "\n",
    "raw_data_gdf = raw_data_gdf.rename(columns={'COUNTYFP': 'county', 'NAME': 'census_tract'})\n",
    "raw_data_gdf = raw_data_gdf.set_index(['county', 'census_tract', 'year'])\n",
    "#raw_data_gdf.sample(1).T\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Read {0:,.0f} rows and {1:,.0f} columns in {2:,.0f} minutes {3:.0f} seconds!'.format(raw_data_gdf.shape[0], raw_data_gdf.shape[1], np.floor((e-s)/60), (e-s)%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: amtLoans1_adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fa24c3f1a040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthiscol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msum_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'census_tract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthiscol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#raw_data_gdf#xs(2017, le#vel='year')#.groupby(['county'])[sum_columns].sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mraw_data_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: amtLoans1_adj'"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "data_df = pandas.DataFrame()\n",
    "\n",
    "sum_columns = []\n",
    "#sum_columns += ['county', 'census_tract']\n",
    "sum_columns += ['nLoans1', 'amtLoans1_adj', 'nLoans100k', 'amtLoans100k_adj', 'nLoans250k', 'amtLoans250k_adj']\n",
    "sum_columns += ['nLoansToSmallest', 'amtLoansToSmallest_adj', 'nLoans', 'amtLoans_adj']\n",
    "sum_columns += ['nWorkingLoans', 'amtWorkingLoans_adj']\n",
    "sum_columns += ['nLoans1_per_totaljob', 'amtLoans1_per_totaljob_adj']\n",
    "sum_columns += ['nLoans100k_per_totaljob', 'amtLoans100k_per_totaljob_adj']\n",
    "sum_columns += ['nLoans250k_per_totaljob', 'amtLoans250k_per_totaljob_adj']\n",
    "sum_columns += ['nLoansToSmallest_per_totaljob', 'amtLoansToSmallest_per_totaljob_adj']\n",
    "sum_columns += ['nLoans_per_totaljob', 'amtLoans_per_totaljob_adj']\n",
    "sum_columns += ['nWorkingLoans_per_totaljob', 'amtWorkingLoans_per_totaljob_adj']\n",
    "sum_columns += ['nLoans1_per_sbjob', 'amtLoans1_per_sbjob_adj']\n",
    "sum_columns += ['nLoans100k_per_sbjob', 'amtLoans100k_per_sbjob_adj']\n",
    "sum_columns += ['nLoans250k_per_sbjob', 'amtLoans250k_per_sbjob_adj']\n",
    "sum_columns += ['nLoansToSmallest_per_sbjob', 'amtLoansToSmallest_per_sbjob_adj']\n",
    "sum_columns += ['nLoans_per_sbjob', 'amtLoans_per_sbjob_adj']\n",
    "sum_columns += ['nWorkingLoans_per_sbjob', 'amtWorkingLoans_per_sbjob_adj']\n",
    "\n",
    "for thiscol in sum_columns:\n",
    "    data_df = pandas.concat((data_df, raw_data_gdf.reset_index().groupby(['county', 'census_tract'])[thiscol].sum()), axis=1)\n",
    "#raw_data_gdf#xs(2017, le#vel='year')#.groupby(['county'])[sum_columns].sum()\n",
    "raw_data_gdf.columns.tolist()\n",
    "\n",
    "cra_info_columns = ['income_group_code', 'income_group', 'cra_level']\n",
    "\n",
    "for thiscol in cra_info_columns:\n",
    "    data_df = pandas.concat((data_df, raw_data_gdf.reset_index()[raw_data_gdf.reset_index()['year'] == 2017].groupby(['county', 'census_tract'])[thiscol].sum()), axis=1)\n",
    "    data_df = data_df.rename(columns = {thiscol: thiscol+'_2017'})\n",
    "\n",
    "\n",
    "jobs_columns = []\n",
    "jobs_columns += ['total_jobs', 'sb_jobs', 'C000', 'CA01', 'CA02', 'CA03']\n",
    "jobs_columns += ['CE01', 'CE02', 'CE03', 'CNS01', 'CNS02', 'CNS03', 'CNS04', 'CNS05']\n",
    "jobs_columns += ['CNS06', 'CNS07', 'CNS08', 'CNS09', 'CNS10', 'CNS11', 'CNS12']\n",
    "jobs_columns += ['CNS13', 'CNS14', 'CNS15', 'CNS16', 'CNS17', 'CNS18', 'CNS19', 'CNS20']\n",
    "jobs_columns += ['CR01', 'CR02', 'CR03', 'CR04', 'CR05', 'CR07', 'CT01', 'CT02']\n",
    "jobs_columns += ['CD01', 'CD02', 'CD03', 'CD04', 'CS01', 'CS02']\n",
    "jobs_columns += ['CFA01', 'CFA02', 'CFA03', 'CFA04', 'CFA05']\n",
    "jobs_columns += ['CFS01', 'CFS02', 'CFS03', 'CFS04', 'CFS05']\n",
    "\n",
    "for thiscol in jobs_columns:\n",
    "    data_df = pandas.concat((data_df, raw_data_gdf.reset_index()[raw_data_gdf.reset_index()['year'] == 2015].groupby(['county', 'census_tract'])[thiscol].sum()), axis=1)\n",
    "    data_df = data_df.rename(columns = {thiscol: thiscol+'_2015'})\n",
    "\n",
    "\n",
    "demographics_columns = []\n",
    "demographics_columns += ['pop_total', 'pop_white', 'pop_black']\n",
    "demographics_columns += ['white_householder', 'black_householder', 'female_householder']\n",
    "demographics_columns += ['hs_grad_25plus', 'unemployed_16plus', 'poverty_past_12_months']\n",
    "demographics_columns += ['mfi_adj', 'median_home_value_adj', 'median_year_built']\n",
    "demographics_columns += ['total_householders', 'pop_25plus', 'labor_force_16plus', 'poverty_status_known']\n",
    "demographics_columns += ['pop_total_err', 'pop_white_err', 'pop_black_err']\n",
    "demographics_columns += ['black_householder_err', 'white_householder_err', 'female_householder_err']\n",
    "demographics_columns += ['hs_grad_25plus_serr', 'unemployed_16plus_err', 'poverty_past_12_months_err']\n",
    "demographics_columns += ['mfi_err_adj', 'median_home_value_err_adj', 'median_year_built_err']\n",
    "demographics_columns += ['total_householders_serr', 'pop_25plus_serr', 'labor_force_16plus_err', 'poverty_status_known_err']\n",
    "demographics_columns += ['pct_white', 'pct_black']\n",
    "demographics_columns += ['pct_white_householders', 'pct_black_householders', 'pct_female_householders']\n",
    "demographics_columns += ['pct_hs_grad', 'pct_unemployed', 'pct_poverty']\n",
    "demographics_columns += ['pct_white_serr', 'pct_black_serr']\n",
    "demographics_columns += ['pct_white_householders_serr', 'pct_black_householders_serr', 'pct_female_householders_serr']\n",
    "demographics_columns += ['pct_hs_grad_serr', 'pct_unemployed_serr', 'pct_poverty_serr']\n",
    "\n",
    "for thiscol in demographics_columns:\n",
    "    data_df = pandas.concat((data_df, raw_data_gdf.reset_index()[raw_data_gdf.reset_index()['year'] == 2017].groupby(['county', 'census_tract'])[thiscol].sum()), axis=1)\n",
    "    data_df = data_df.rename(columns = {thiscol: thiscol+'_2017'})\n",
    "    \n",
    "    \n",
    "geo_info_columns = []\n",
    "geo_info_columns += ['split_county_indicator', 'population_classification', 'CSA2010']\n",
    "geo_info_columns += ['STATEFP', 'TRACTCE', 'NAMELSAD', 'MTFCC', 'FUNCSTAT']\n",
    "geo_info_columns += ['ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON']\n",
    "\n",
    "for thiscol in geo_info_columns:\n",
    "    data_df = pandas.concat((data_df, raw_data_gdf.reset_index()[raw_data_gdf.reset_index()['year'] == 2017].groupby(['county', 'census_tract'])[thiscol].sum()), axis=1)\n",
    "\n",
    "data_df = data_df.reset_index().merge(raw_data_gdf.reset_index()[['county', 'census_tract', 'geometry']][raw_data_gdf.reset_index()['year'] == 2017], how='inner', on=['county', 'census_tract']).set_index(['county', 'census_tract'])\n",
    "\n",
    "all_tracts_gdf = geopandas.GeoDataFrame(data_df, crs=raw_data_gdf.crs, geometry='geometry')\n",
    "\n",
    "# convert to best map projection for this state\n",
    "all_tracts_gdf = all_tracts_gdf.to_crs(projection)\n",
    "    \n",
    "\n",
    "# If this is Baltimore, cut out the harbor\n",
    "if (city == 'Baltimore'):\n",
    "    print('getting city council districts...')\n",
    "    council_districts_gdf = geopandas.read_file(baltimore_shapefile_basedir+'council_districts/council_districts.shp')\n",
    "    council_districts_gdf = council_districts_gdf.to_crs(all_tracts_gdf.crs)\n",
    "    council_districts_gdf.loc[:, 'area_name'] = pandas.to_numeric(council_districts_gdf['area_name'], errors='coerce')\n",
    "    council_districts_gdf = council_districts_gdf.set_index('area_name')\n",
    "    council_districts_gdf = council_districts_gdf.sort_index()\n",
    "    print('cutting out harbor...')\n",
    "    water_gdf = geopandas.read_file(baltimore_shapefile_basedir+'water/water.shp')\n",
    "    water_gdf = water_gdf.to_crs(all_tracts_gdf.crs)\n",
    "    all_tracts_gdf = geopandas.overlay(all_tracts_gdf, water_gdf[water_gdf['NAME'] == 'Harbor'], how='difference')\n",
    "    #council_districts_gdf = geopandas.overlay(council_districts_gdf, water_gdf[water_gdf['NAME'] == 'Harbor'], how='difference')\n",
    "    \n",
    "# If CSA was blank, make it N/A (it's only useful in Baltimore)\n",
    "all_tracts_gdf.loc[all_tracts_gdf['CSA2010'] == 0, 'CSA2010'] = 'N/A'\n",
    "\n",
    "tracts_included_gdf = all_tracts_gdf[\n",
    "    (all_tracts_gdf['sb_jobs_2015'] >= sb_jobs_lower_limit)\n",
    "    & (all_tracts_gdf['pop_total_2017'] >= pop_lower_limit)\n",
    "]\n",
    "\n",
    "summary['pop_all_tracts_2017'] = all_tracts_gdf['pop_total_2017'].sum()\n",
    "summary['pop_included_in_study_2017'] = tracts_included_gdf['pop_total_2017'].sum()\n",
    "summary['sb_jobs_included_in_study_2015'] = tracts_included_gdf['sb_jobs_2015'].sum()\n",
    "\n",
    "summary['tracts_included'] = tracts_included_gdf.shape[0]\n",
    "summary['nWorkingLoans'] = tracts_included_gdf['nWorkingLoans'].sum()\n",
    "summary['amtWorkingLoans_adj'] = tracts_included_gdf['amtWorkingLoans_adj'].sum()\n",
    "\n",
    "print('With limits of {0:,.0f} jobs and {1:,.0f} population, including {2:,.0f} of {3:,.0f} census tracts...'.format(\n",
    "    sb_jobs_lower_limit, pop_lower_limit, len(tracts_included_gdf), len(all_tracts_gdf)\n",
    "))\n",
    "\n",
    "all_tracts_gdf_bk = all_tracts_gdf\n",
    "tracts_included_gdf_bk = tracts_included_gdf\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Created graphable dataframe with {0:,.0f} rows and {1:,.0f} columns in {2:,.0f} minutes {3:,.0f} seconds!'.format(\n",
    "    tracts_included_gdf.shape[0], tracts_included_gdf.shape[1], np.floor((e-s)/60), (e-s)%60)\n",
    "     )\n",
    "#pprint(summary)\n",
    "#print(council_districts_gdf.head(1).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "print('making basic map...')\n",
    "\n",
    "fig1, ax = plt.subplots(1,1, figsize=(48*scale, 48*scale))\n",
    "\n",
    "all_tracts_gdf.plot(ax=ax, color='pink')\n",
    "tracts_included_gdf.plot(ax=ax, column='amtWorkingLoans_per_sbjob_adj', cmap=thecolormap, edgecolor='white', linewidth=2*scale)\n",
    "if (city == 'Baltimore'):\n",
    "    council_districts_gdf.plot(ax=ax, color='none', edgecolor='red', linewidth=3*scale, alpha=0.5)\n",
    "\n",
    "print('setting options...')\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\n",
    "plt.title('{0:} census tracts (n = {1:,.0f})'.format(city, len(tracts_included_gdf)), fontsize=64*scale, y=1.04)\n",
    "\n",
    "pink_patch = mpatches.Patch(color='pink', label='Insufficient data')\n",
    "plt.legend(handles=[pink_patch], fontsize=52*scale, loc='upper left')\n",
    "\n",
    "print('adding colorbar...')\n",
    "\n",
    "cax = fig1.add_axes([0.125, 0.08, 0.775, 0.03])\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=thecolormap, norm=plt.Normalize(\n",
    "    vmin=0, \n",
    "    vmax=tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'].max()\n",
    "))\n",
    "## fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "\n",
    "cbar = fig1.colorbar(sm, cax=cax, format='$%.0f', \n",
    "                    ticks=np.arange(0, \n",
    "                                    tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'].max(),\n",
    "                                    25000), \n",
    "                    orientation='horizontal')\n",
    "\n",
    "cax.set_xticklabels(['${:,.0f}'.format(x/1000) for x in np.arange(0, tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'].max(), 25000)], fontsize=56*scale)\n",
    "cbar.set_label('Total working loans per job (Thousand 2017USD)', fontsize=68*scale)\n",
    "\n",
    "\n",
    "for ix, thisrow in council_districts_gdf.iterrows():\n",
    "    annotator = ''\n",
    "    annotator += 'DISTRICT '+str(ix)\n",
    "    xypos = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "    if (int(ix) == 11):\n",
    "        print('Moving label for District 11 for better readability...')\n",
    "        xypos = (thisrow.geometry.centroid.x + 200, thisrow.geometry.centroid.y - 1000)\n",
    "    ax.annotate(annotator, \n",
    "                xy=xypos, \n",
    "                xytext=xypos, \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=36*scale, \n",
    "                color='red',\n",
    "                backgroundcolor='white'\n",
    "               )\n",
    "#show_tract_labels = True\n",
    "if (show_tract_labels):\n",
    "    print('adding tract labels...')\n",
    "    for ix, thisrow in tracts_included_gdf.iterrows():\n",
    "        #if (ix[1] in [1803.0, 1003.0, 2603.02, 2005.0, 2008.0, 2803.02, 2709.03, 1502.0, 401.0, 1902.0, 904.0, 2802.0, 1607.0, 2102.0, 2711.01, 1602.0, 902.0, 1703.0]):#, 1510.0, 801.02, 2602.02, 1308.03, 903.0, 1903.0, 1601.0, 1308.05, 2715.03, 2715.01, 1402.0, 105.0, 2701.01, 1605.0, 2007.02, 1506.0, 2706.0, 1201.0, 1206.0, 2709.01, 2709.02, 2718.01, 804.0, 1501.0, 1308.04, 1604.0, 2602.01, 2710.01, 1202.02, 1513.0, 2602.03, 2708.02, 1303.0, 2604.02, 2404.0, 2007.01, 1603.0]):\n",
    "        annotator = ''\n",
    "        annotator += str(ix[1])\n",
    "        #annotator += '\\n'\n",
    "        #annotator += '${0:,.0f}k'.format(thisrow['amtWorkingLoans_per_sbjob_adj']/1000)\n",
    "        ax.annotate(annotator, \n",
    "                    xy=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    xytext=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    backgroundcolor = 'white',\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=24*scale)\n",
    "    map_outfile_name = figdir+'{0:}_map_labeled.jpg'.format(city.lower())\n",
    "else:\n",
    "    map_outfile_name = figdir+'{0:}_map_unlabeled.jpg'.format(city.lower())\n",
    "\n",
    "plt.savefig(map_outfile_name, format='jpg', dpi=300*scale)\n",
    "plt.show()\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the right tolerance to declare that a census tract covers 2 or more council districts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracts_gdf = all_tracts_gdf_bk\n",
    "print('thinking...')\n",
    "check_overlaps_dict = {}\n",
    "\n",
    "for ix, thisrow in all_tracts_gdf.iterrows():\n",
    "    this_tract_overlaps_list = []\n",
    "    total_overlap = 0\n",
    "    for cdix, thatrow in council_districts_gdf.iterrows():\n",
    "        if (thatrow.geometry.covers(thisrow.geometry)):\n",
    "            pass\n",
    "        elif (thisrow.geometry.intersects(thatrow.geometry)):\n",
    "            this_overlap_dict = {}\n",
    "            x = thisrow.geometry.intersection(thatrow.geometry)\n",
    "            this_overlap_dict[cdix] = x.area\n",
    "            this_tract_overlaps_list.append(x.area)\n",
    "        else:\n",
    "            pass\n",
    "    this_tract_overlaps_list = sorted(this_tract_overlaps_list, reverse=True)\n",
    "    if (len(this_tract_overlaps_list) > 1):\n",
    "        for i in range(1, len(this_tract_overlaps_list)):\n",
    "            total_overlap = total_overlap + this_tract_overlaps_list[i]\n",
    "    if (total_overlap > 0):\n",
    "        check_overlaps_dict[ix[1]] = total_overlap\n",
    "\n",
    "overlap_df = pandas.DataFrame(data=None, columns=['area'])\n",
    "for k,v in check_overlaps_dict.items():\n",
    "    overlap_df.loc[k] = v\n",
    "overlap_df = overlap_df.sort_values(by='area')\n",
    "\n",
    "test_tol = 8100 #90**2\n",
    "figx, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "nbins1 = int(np.floor(len(overlap_df)))\n",
    "print('Graph {0:} has {1:.0f} bins...'.format(1, nbins1))\n",
    "overlap_df.hist(ax=ax1, bins=nbins1)\n",
    "#ax1.set_xlim([0, 30000])\n",
    "\n",
    "nbins2 = int(np.floor(len(overlap_df[overlap_df['area'] <= 3*test_tol])))\n",
    "print('Graph {0:} has {1:.0f} bins...'.format(2, nbins2))\n",
    "overlap_df[overlap_df['area'] <= 3*test_tol].hist(ax=ax2, bins=nbins2)\n",
    "ax2.set_xlim([0, 3*test_tol])\n",
    "\n",
    "plt.show()\n",
    "#print(overlap_df[overlap_df['area'] <= test_tol].sort_values(by='area', ascending=False))\n",
    "print('BEST TOLERANCE: OVERLAP OF {0:,.0f} SQUARE METERS!!!!'.format(test_tol))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGN COUNCIL DISTRICTS TO TRACTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_tracts_gdf = all_tracts_gdf_bk\n",
    "print('assigning city council districts with overlap tolerance <= {0:,.0f} square meters...'.format(tol))\n",
    "all_tracts_gdf = all_tracts_gdf.assign(council_district = -1)\n",
    "\n",
    "for ix, thisrow in all_tracts_gdf.iterrows():\n",
    "    districts_it_intersects = []\n",
    "    #print('Tract {0:} intersects:'.format(ix[1]))\n",
    "    for cdix, thatrow in council_districts_gdf.iterrows():\n",
    "        intersects_maybe = thisrow.geometry.intersects(thatrow.geometry)\n",
    "        if (intersects_maybe == True):\n",
    "            this_intersection = {}\n",
    "            this_intersection['census_tract'] = ix[1]\n",
    "            this_intersection['district'] = cdix\n",
    "            this_intersection['area'] = thisrow.geometry.intersection(thatrow.geometry).area\n",
    "            districts_it_intersects.append(this_intersection)    \n",
    "    #print('   District {0:}...'.format(thiscd))\n",
    "    if (len(districts_it_intersects) == 1):\n",
    "        all_tracts_gdf.loc[ix, 'council_district'] = districts_it_intersects[0]['district']\n",
    "    else:\n",
    "        df = pandas.DataFrame(districts_it_intersects)\n",
    "        excess_area = df.sort_values(by='area', ascending=False)[1:]['area'].sum()\n",
    "        if (excess_area < tol):\n",
    "            #\n",
    "            all_tracts_gdf.loc[ix, 'council_district'] = df.sort_values(by='area', ascending=False)[1:2]['district'].values[0]\n",
    "            #print(ix[1])\n",
    "        \n",
    "        #all_tracts_gdf.loc[ix, 'council_district'] = df.sort_values(by='area', ascending=False).head(1)['district'].values[0]\n",
    "        \n",
    "        #print(ix[1], this_intersection['district'])\n",
    "    #print(len(districts_it_intersects))\n",
    "    #for thiscd in districts_it_intersects:\n",
    "#        print(thiscd)\n",
    "all_tracts_gdf.groupby('council_district').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('making basic map...')\n",
    "\n",
    "fig1b, ax = plt.subplots(1,1, figsize=(48*scale, 48*scale))\n",
    "\n",
    "all_tracts_gdf.plot(ax=ax, color='pink')\n",
    "#all_tracts_gdf[all_tracts_gdf['council_district'] != -1].plot(ax=ax, column='amtWorkingLoans_per_sbjob_adj', cmap=thecolormap, edgecolor='white', linewidth=2*scale)\n",
    "all_tracts_gdf[all_tracts_gdf['council_district'] != -1].plot(ax=ax, column='amtWorkingLoans_per_sbjob_adj', cmap=thecolormap, edgecolor='white', linewidth=2*scale)\n",
    "if (city == 'Baltimore'):\n",
    "    council_districts_gdf.plot(ax=ax, color='none', edgecolor='red', linewidth=8*scale, alpha=0.5)\n",
    "\n",
    "print('setting options...')\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\n",
    "plt.title('{0:} census tracts ({1:,.0f} total, {2:,.0f} fully within council districts)'.format(city, len(all_tracts_gdf), len(all_tracts_gdf[all_tracts_gdf['council_district'] != -1])), fontsize=64*scale, y=1.04)\n",
    "\n",
    "pink_patch = mpatches.Patch(color='pink', label='Multiple city council districts')\n",
    "plt.legend(handles=[pink_patch], fontsize=52*scale, loc='upper left')\n",
    "\n",
    "print('adding colorbar...')\n",
    "\n",
    "cax = fig1b.add_axes([0.125, 0.08, 0.775, 0.03])\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=thecolormap, norm=plt.Normalize(\n",
    "    vmin=0, \n",
    "    vmax=all_tracts_gdf['amtWorkingLoans_per_sbjob_adj'].max()\n",
    "))\n",
    "## fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "\n",
    "cbar = fig1b.colorbar(sm, cax=cax, format='$%.0f', \n",
    "                    ticks=np.arange(0, \n",
    "                                    all_tracts_gdf['amtWorkingLoans_per_sbjob_adj'].max(),\n",
    "                                    25000), \n",
    "                    orientation='horizontal')\n",
    "\n",
    "cax.set_xticklabels(['${:,.0f}'.format(x/1000) for x in np.arange(0, all_tracts_gdf['amtWorkingLoans_per_sbjob_adj'].max(), 25000)], fontsize=56*scale)\n",
    "cbar.set_label('Total working loans per job (Thousand 2017USD)', fontsize=68*scale)\n",
    "\n",
    "    \n",
    "show_tract_labels = False\n",
    "if (show_tract_labels):\n",
    "    print('adding tract labels...')\n",
    "    for ix, thisrow in tracts_included_gdf.iterrows():\n",
    "        annotator = ''\n",
    "        annotator += str(ix[1])\n",
    "        #annotator += '\\n'\n",
    "        #annotator += '${0:,.0f}k'.format(thisrow['amtWorkingLoans_per_sbjob_adj']/1000)\n",
    "        ax.annotate(annotator, \n",
    "                    xy=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    xytext=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    backgroundcolor = 'white',\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=24*scale)    \n",
    "        \n",
    "\n",
    "for ix, thisrow in council_districts_gdf.iterrows():\n",
    "    annotator = ''\n",
    "    annotator += 'DISTRICT '+str(ix)\n",
    "    xypos = (thisrow.geometry.centroid.x, thisrow.geometry.centroid.y)\n",
    "    if (int(ix) == 11):\n",
    "        print('Moving label for District 11 for better readability...')\n",
    "        xypos = (thisrow.geometry.centroid.x + 200, thisrow.geometry.centroid.y - 1000)\n",
    "    ax.annotate(annotator, \n",
    "                xy=xypos, \n",
    "                xytext=xypos, \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=36*scale, \n",
    "                color='red',\n",
    "                backgroundcolor='white'\n",
    "               )\n",
    "    \n",
    "plt.savefig(figdir+'tracts_council_districts_unlabeled.jpg', format='jpg', dpi=300)\n",
    "plt.show()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show_tract_labels = True\n",
    "if (show_tract_labels):\n",
    "    print('adding tract labels...')\n",
    "    #for ix, thisrow in all_tracts_gdf[all_tracts_gdf['council_district'] != -1].iterrows():\n",
    "    for ix, thisrow in all_tracts_gdf[all_tracts_gdf['council_district'] == -1].iterrows():\n",
    "        #if (ix[1] in [1803.0, 1003.0, 2603.02, 2005.0, 2008.0, 2803.02, 2709.03, 1502.0, 401.0, 1902.0, 904.0, 2802.0, 1607.0, 2102.0, 2711.01, 1602.0, 902.0, 1703.0]):#, 1510.0, 801.02, 2602.02, 1308.03, 903.0, 1903.0, 1601.0, 1308.05, 2715.03, 2715.01, 1402.0, 105.0, 2701.01, 1605.0, 2007.02, 1506.0, 2706.0, 1201.0, 1206.0, 2709.01, 2709.02, 2718.01, 804.0, 1501.0, 1308.04, 1604.0, 2602.01, 2710.01, 1202.02, 1513.0, 2602.03, 2708.02, 1303.0, 2604.02, 2404.0, 2007.01, 1603.0]):\n",
    "        annotator = ''\n",
    "        annotator += str(ix[1])\n",
    "        #annotator += '\\n'\n",
    "        #annotator += '${0:,.0f}k'.format(thisrow['amtWorkingLoans_per_sbjob_adj']/1000)\n",
    "        ax.annotate(annotator, \n",
    "                    xy=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    xytext=(thisrow.geometry.centroid.x, thisrow.geometry.centroid.y), \n",
    "                    backgroundcolor = 'white',\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=24*scale)\n",
    "    map_outfile_name = figdir+'{0:}_map_labeled.jpg'.format(city.lower())\n",
    "else:\n",
    "    map_outfile_name = figdir+'{0:}_map_unlabeled.jpg'.format(city.lower())\n",
    "\n",
    "#plt.savefig(map_outfile_name, format='jpg', dpi=300*scale)\n",
    "plt.show()\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide tracts into categories by poverty and race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print('identifying tracts by poverty rate...')\n",
    "tracts_included_gdf = tracts_included_gdf.assign(poverty_class_2017 = np.nan)\n",
    "tracts_included_gdf.loc[tracts_included_gdf['pct_poverty_2017'] > 0.3, 'poverty_class_2017'] = 'much'\n",
    "tracts_included_gdf.loc[tracts_included_gdf['pct_poverty_2017'] < 0.1, 'poverty_class_2017'] = 'little'\n",
    "\n",
    "print('identifying tracts with higher-than-average percentages of white and black people...')\n",
    "city_pct_white = tracts_included_gdf['pop_white_2017'].sum() / tracts_included_gdf['pop_total_2017'].sum()\n",
    "city_pct_black = tracts_included_gdf['pop_black_2017'].sum() / tracts_included_gdf['pop_total_2017'].sum()\n",
    "\n",
    "tracts_included_gdf = tracts_included_gdf.assign(excess_race_2017 = np.nan)\n",
    "tracts_included_gdf.loc[tracts_included_gdf['pct_white_2017'] > city_pct_white, 'excess_race_2017'] = 'white'\n",
    "tracts_included_gdf.loc[tracts_included_gdf['pct_black_2017'] > city_pct_black, 'excess_race_2017'] = 'black'\n",
    "\n",
    "summary['city_pct_black'] = city_pct_black\n",
    "\n",
    "cra_level_poverty_df = pandas.DataFrame()\n",
    "cra_level_poverty_df = cra_level_poverty_df.assign(nTracts = tracts_included_gdf[tracts_included_gdf['cra_level_2017'] != 'unknown'].groupby(['poverty_class_2017','cra_level_2017']).size())\n",
    "cra_level_poverty_df = cra_level_poverty_df.assign(mean_amtWorkingLoans_per_sbjob_adj = tracts_included_gdf[tracts_included_gdf['cra_level_2017'] != 'unknown'].groupby(['poverty_class_2017','cra_level_2017'])['amtWorkingLoans_per_sbjob_adj'].mean())\n",
    "cra_level_poverty_df = cra_level_poverty_df.assign(sem_amtWorkingLoans_per_sbjob_adj = tracts_included_gdf[tracts_included_gdf['cra_level_2017'] != 'unknown'].groupby(['poverty_class_2017','cra_level_2017'])['amtWorkingLoans_per_sbjob_adj'].sem())\n",
    "\n",
    "# If any values of cra_level_poverty_df are missing, fill them with nan's\n",
    "for x in ['little', 'much']:\n",
    "    for y in ['low', 'moderate', 'middle', 'upper']:\n",
    "        try:\n",
    "            if (cra_level_poverty_df.loc[(x,y)]['nTracts'] > 0):\n",
    "                pass\n",
    "            else:\n",
    "                print('else',x,y)\n",
    "        except:\n",
    "            cra_level_poverty_df.loc[(x,y), ['nTracts', 'mean_amtWorkingLoans_per_sbjob_adj', 'sem_amtWorkingLoans_per_sbjob_adj']] = [0, np.nan, np.nan]\n",
    "    \n",
    "cra_level_race_df = pandas.DataFrame()\n",
    "\n",
    "cra_level_race_df = cra_level_race_df.assign(nTracts = tracts_included_gdf[(tracts_included_gdf['cra_level_2017'] != 'unknown')].groupby(['excess_race_2017','cra_level_2017']).size())\n",
    "cra_level_race_df = cra_level_race_df.assign(mean_amtWorkingLoans_per_sbjob_adj = tracts_included_gdf[(tracts_included_gdf['cra_level_2017'] != 'unknown')].groupby(['excess_race_2017','cra_level_2017'])['amtWorkingLoans_per_sbjob_adj'].mean())\n",
    "cra_level_race_df = cra_level_race_df.assign(sem_amtWorkingLoans_per_sbjob_adj = tracts_included_gdf[(tracts_included_gdf['cra_level_2017'] != 'unknown')].groupby(['excess_race_2017','cra_level_2017'])['amtWorkingLoans_per_sbjob_adj'].sem())\n",
    "\n",
    "# If any values of cra_level_race_df are missing, fill them with nan's\n",
    "for x in ['black', 'white']:\n",
    "    for y in ['low', 'moderate', 'middle', 'upper']:\n",
    "        try:\n",
    "            if (cra_level_race_df.loc[(x,y)]['nTracts'] > 0):\n",
    "                pass\n",
    "            else:\n",
    "                print('else',x,y)\n",
    "        except:\n",
    "            cra_level_race_df.loc[(x,y), ['nTracts', 'mean_amtWorkingLoans_per_sbjob_adj', 'sem_amtWorkingLoans_per_sbjob_adj']] = [0, np.nan, np.nan]\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:,.2f} seconds!'.format(e-s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "bar_chart_df = pandas.DataFrame(data=None, columns=['mean_amtWorkingLoans_adj_per_sbjob'])\n",
    "bar_chart_df.loc[\n",
    "    'little poverty / much poverty', 'mean_amtWorkingLoans_adj_per_sbjob'\n",
    "] = tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][\n",
    "    (tracts_included_gdf['poverty_class_2017'] == 'little') & (tracts_included_gdf['cra_level_2017'] != 'unknown')\n",
    "].mean() / tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][\n",
    "    (tracts_included_gdf['poverty_class_2017'] == 'much') & (tracts_included_gdf['cra_level_2017'] != 'unknown')\n",
    "].mean()\n",
    "\n",
    "bar_chart_df.loc[\n",
    "    'excess white / excess black', 'mean_amtWorkingLoans_adj_per_sbjob'\n",
    "] = tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][\n",
    "    (tracts_included_gdf['excess_race_2017'] == 'white') & (tracts_included_gdf['cra_level_2017'] != 'unknown')\n",
    "].mean() / tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][\n",
    "    (tracts_included_gdf['excess_race_2017'] == 'black') & (tracts_included_gdf['cra_level_2017'] != 'unknown')\n",
    "].mean()\n",
    "#bar_chart_df.loc['excess white / excess black', 'mean_amtWorkingLoans_adj_per_sbjob'] = tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][tracts_included_gdf['excess_race_2017'] == 'white'].mean() / tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][tracts_included_gdf['excess_race_2017'] == 'black'].mean()\n",
    "\n",
    "fig2, ax = plt.subplots(1,1, figsize=(36*scale, 24*scale))\n",
    "bar_chart_df.plot.bar(ax=ax, color='gold')\n",
    "\n",
    "plt.xticks(np.arange(0,2), bar_chart_df.index.values, rotation='horizontal', fontsize=48*scale)\n",
    "\n",
    "plt.ylabel('Ratio of mean lending per tract', fontsize=56*scale)\n",
    "plt.yticks(np.arange(0, 2, 0.25), np.arange(0, 2, 0.25), fontsize=48*scale)\n",
    "\n",
    "plt.title('{0:}: Ratios of per-tract lending by poverty and race'.format(city), fontsize=56*scale, y=1.02)\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig(figdir+'{0:}_lending_ratios.jpg'.format(city.lower().replace(' ','_')), format='jpg', dpi=300*scale)\n",
    "\n",
    "summary['lending_ratio_race'] = tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][tracts_included_gdf['excess_race_2017'] == 'white'].mean() / tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][tracts_included_gdf['excess_race_2017'] == 'black'].mean()\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:.2f} seconds!'.format(e-s))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "label_sorter = np.arange(4).tolist()\n",
    "width = 0.35\n",
    "\n",
    "white_means = cra_level_race_df.xs('white')['mean_amtWorkingLoans_per_sbjob_adj'].tolist()\n",
    "black_means = cra_level_race_df.xs('black')['mean_amtWorkingLoans_per_sbjob_adj'].tolist()\n",
    "white_sems = cra_level_race_df.xs('white')['sem_amtWorkingLoans_per_sbjob_adj'].tolist()\n",
    "black_sems = cra_level_race_df.xs('black')['sem_amtWorkingLoans_per_sbjob_adj'].tolist()\n",
    "\n",
    "fig3, ax = plt.subplots(1,1, figsize=(36*scale, 24*scale))\n",
    "\n",
    "plt.bar(label_sorter, white_means, width, yerr=white_sems, label='White', color='lightgray', error_kw=dict(lw=5*scale, capsize=18*scale, capthick=5*scale))\n",
    "plt.bar([x+width for x in label_sorter], black_means, width, yerr=black_sems, label='Black', color='darkgray', error_kw=dict(lw=5*scale, capsize=18*scale, capthick=5*scale))\n",
    "\n",
    "plt.xticks([x+(width/2) for x in label_sorter], ['low', 'middle', 'moderate', 'upper'], fontsize=48*scale)\n",
    "plt.yticks(fontsize=48*scale)\n",
    "\n",
    "tick_label_list = []\n",
    "for tick in ax.get_yticks():\n",
    "    tick_label_list.append(tick)\n",
    "tick_label_list = ['${0:.0f}'.format(x/1000) for x in tick_label_list]\n",
    "ax.set_yticklabels(tick_label_list)\n",
    "\n",
    "plt.xlabel('CRA income level', fontsize=54*scale)\n",
    "plt.ylabel('Mean loan amount upper SB job\\n(thousands)', fontsize=64*scale)\n",
    "plt.title('{0:}: Loans per job by CRA level and race'.format(city), fontsize=56*scale, y=1.02)\n",
    "\n",
    "plt.savefig(figdir+'{0:}_cra_level_race.jpg'.format(city.lower().replace(' ','_')), format='jpg', dpi=300*scale)\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:.2f} seconds!'.format(e-s))\n",
    "\n",
    "plt.show()\n",
    "#black_means\n",
    "#label_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(\n",
    "    tracts_included_gdf['pct_black_2017'][tracts_included_gdf['pct_black_2017'].notnull()].apply(lambda x: x * 100).values, \n",
    "    tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'][tracts_included_gdf['pct_black_2017'].notnull()].values\n",
    ")\n",
    "\n",
    "summary['race_fit_slope'] = slope\n",
    "summary['race_fit_rsq'] = r_value**2\n",
    "\n",
    "fig3, (ax3) = plt.subplots(1,1, figsize=(36*scale,18*scale))\n",
    "siz = tracts_included_gdf['sb_jobs_2015'].apply(lambda x: (2*x)*(scale**2)).tolist()\n",
    "\n",
    "\n",
    "#mfi_colormap = cm.viridis(np.linspace(0, 1, len(tracts_included_gdf)))\n",
    "\n",
    "ax3.scatter(tracts_included_gdf['pct_black_2017'], \n",
    "            tracts_included_gdf['amtWorkingLoans_per_sbjob_adj'], \n",
    "            s=siz, c=tracts_included_gdf['mfi_adj_2017'], cmap=thecolormap)\n",
    "\n",
    "ax3.plot(tracts_included_gdf['pct_black_2017'], slope*tracts_included_gdf['pct_black_2017'].apply(lambda x: x * 100) + intercept, \n",
    "         color='black', linewidth=8*scale)\n",
    "\n",
    "ax3.set_xlabel('Percent black residents', fontsize=64*scale)\n",
    "ax3.set_ylabel('Total working loans per small\\nbusiness job (thousands)', fontsize=44*scale)\n",
    "\n",
    "xticks = np.arange(0, 1.2, 0.2)\n",
    "xlabels = ['{0:.0%}'.format(x) for x in xticks]\n",
    "plt.xticks(xticks, xlabels, fontsize=48*scale)\n",
    "\n",
    "tick_label_list = []\n",
    "for tick in ax3.get_yticks():\n",
    "    tick_label_list.append(tick)\n",
    "\n",
    "tick_label_list = ['${0:.0f}'.format(x/1000) for x in tick_label_list]\n",
    "ax3.set_yticklabels(tick_label_list, fontsize=36*scale)\n",
    "\n",
    "plt.title('{0:}: Linear model of Loans per job by race'.format(city), fontsize=54*scale, y=1.02)\n",
    "\n",
    "\n",
    "print('adding colorbar...')\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=thecolormap, norm=plt.Normalize(\n",
    "    vmin=tracts_included_gdf['mfi_adj_2017'].min(), \n",
    "    vmax=tracts_included_gdf['mfi_adj_2017'].max()\n",
    "))\n",
    "## fake up the array of the scalar mappable. Urgh...\n",
    "sm._A = []\n",
    "\n",
    "\n",
    "#cax = fig3.add_axes()#[0.85, 0.4, .95, 0.5])\n",
    "\n",
    "cbar = fig3.colorbar(sm)\n",
    "\n",
    "cbarticklabels = []\n",
    "for t in cbar.ax.get_yticks(): \n",
    "    cbarticklabels.append(t)\n",
    "    #t = int(t.get_text()) / 1000#print(t.get_text())\n",
    "cbarticklabels = ['${0:.0f}'.format(x/1000) for x in cbarticklabels]\n",
    "cbar.set_ticks([x for x in cbar.ax.get_yticks()])\n",
    "cbar.set_ticklabels(cbarticklabels)\n",
    "cbar.ax.tick_params(labelsize=28*scale) \n",
    "cbar.set_label('Median family income (thousands)', rotation=90, size=36*scale, labelpad=25)#, y=1.05, rotation=90)\n",
    "\n",
    "plt.savefig(figdir+'{0:}_linear_fit_race.jpg'.format(city.lower().replace(' ','_')), format='jpg', dpi=300*scale)\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Done in {0:.2f} seconds!'.format(e-s))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "if (summary['race_fit_slope'] >= 0):\n",
    "    summary['slopesign'] = ''\n",
    "else:\n",
    "    summary['slopesign'] = '-'\n",
    "    \n",
    "\n",
    "print('Total city population: {0:,.0f}'.format(summary['pop_all_tracts_2017']))\n",
    "print('Population included in study: {0:,.0f}'.format(summary['pop_included_in_study_2017']))\n",
    "print('Small business jobs included in study: {0:,.0f}'.format(summary['sb_jobs_included_in_study_2015']))\n",
    "print('\\n')\n",
    "print('Census tracts included in study: {0:,.0f}'.format(summary['tracts_included']))\n",
    "print('City-wide percent black residents: {0:.1%}'.format(summary['city_pct_black']))\n",
    "print('Number of working loans: {0:,.0f}'.format(summary['nWorkingLoans']))\n",
    "print('Total amount of working loans (2017USD): ${0:,.0f}'.format(summary['amtWorkingLoans_adj']))\n",
    "print('\\n')\n",
    "print('Race lending ratio: {0:.2f}'.format(summary['lending_ratio_race']))\n",
    "print('Slope of best-fit line for lending by race:\\n\\t{0:}${1:,.0f} per SB job per percent black (r^2 = {2:.3f})'.format(summary['slopesign'], np.abs(summary['race_fit_slope']), summary['race_fit_rsq']))\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('\\n')\n",
    "print('Grand total time: {0:.1f} seconds!'.format(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
