{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages...\n",
      "Now in directory: /home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('Importing packages...')\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import time\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "debug = 1\n",
    "\n",
    "# Directories to look in\n",
    "thisdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/'\n",
    "data_dir = '/home/idies/workspace/Temporary/raddick/cra_scratch_final/'\n",
    "jobs_dir = data_dir + 'lodes_wac/'\n",
    "census_dir = data_dir + 'acs5/'\n",
    "#baltimore_dir = thisdir + 'baltimore/'\n",
    "code_lookup_dir = thisdir + 'code_guide_lookups/'\n",
    "inflation_dir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/inflation/'\n",
    "extrasdir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "city_data_dir = thisdir + 'city_data/'\n",
    "\n",
    "g = 0  # keep track of grand total of processing time\n",
    "os.chdir(thisdir)\n",
    "print('Now in directory: {0:}'.format(os.getcwd()))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected St. Louis!\n"
     ]
    }
   ],
   "source": [
    "state_codes_df = pandas.read_csv(extrasdir+'statecodes.csv')\n",
    "state_codes_df = state_codes_df.set_index('STUSAB')\n",
    "states = state_codes_df.index.values.tolist()\n",
    "states = sorted([x.lower() for x in states if x not in ('MD', 'AS', 'GU', 'MP', 'PR', 'UM', 'VI')])\n",
    "\n",
    "city = 'St. Louis'\n",
    "\n",
    "if (city == 'Baltimore'):\n",
    "    thestate = 24\n",
    "    state_abbrev = 'md'\n",
    "    thecounty = 510\n",
    "    shapefile_dir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "    cityname_file = 'baltimore'\n",
    "    print('Selected {0:}!'.format(city))\n",
    "if (city == 'St. Louis'):\n",
    "    thestate = 29\n",
    "    state_abbrev = 'mo'\n",
    "    thecounty = 510\n",
    "    shapefile_dir = '/home/idies/workspace/Storage/raddick/Baltimore/shapefiles/'\n",
    "    cityname_file = 'st_louis'\n",
    "    print('Selected {0:}!'.format(city))\n",
    "else:\n",
    "    print('ERROR: Select city!')\n",
    "#state_codes_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get flatfile loans data for selected city, process, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading nationwide loans data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping only business loan originations in St. Louis...\n",
      "calculating total loans...\n",
      "keeping only respondents with loans...\n",
      "dropping duplicate rows...\n",
      "looking up codes for institution names, income groups, CRA levels...\n",
      "calculating working loans...\n",
      "setting index...\n",
      "correcting for inflation...\n",
      "inflating pre-2017 monetary values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2817: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  raw_cell, store_history, silent, shell_futures)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/city_data/st_louis_loans.csv...\n",
      "Saved 1,652 rows of loan data for St. Louis in 66 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading nationwide loans data...')\n",
    "loans_df = pandas.read_csv(data_dir+'loans.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "\n",
    "#print('   assessment areas...')\n",
    "#assessment_areas_df = pandas.read_csv(data_dir+'assessment_areas.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "#print('   census tracts...')\n",
    "#tracts_df = pandas.read_csv(data_dir+'tracts.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "#print('   assessment areas...')\n",
    "#city_assessment_areas_df = assessment_areas_df[(assessment_areas_df['state'] == thestate) & (assessment_areas_df['county'] == thecounty)]\n",
    "#print('   census tracts...')\n",
    "\n",
    "print('keeping only business loan originations in {0:}...'.format(city))\n",
    "city_loans_df = loans_df[(loans_df['state'] == thestate) & (loans_df['county'] == thecounty)]\n",
    "city_loans_df = city_loans_df[city_loans_df['loan_type'] == 4] # Small business loans only\n",
    "city_loans_df = city_loans_df[city_loans_df['action_taken_type'] == 1] # Originations only\n",
    "\n",
    "print('calculating total loans...')\n",
    "city_loans_df = city_loans_df.assign(nLoans = city_loans_df['nLoans1'] + city_loans_df['nLoans100k'] + city_loans_df['nLoans250k'])\n",
    "city_loans_df = city_loans_df.assign(amtLoans = city_loans_df['amtLoans1'] + city_loans_df['amtLoans100k'] + city_loans_df['amtLoans250k'])\n",
    "\n",
    "print('keeping only respondents with loans...')\n",
    "city_loans_df = city_loans_df[city_loans_df['nLoans'] > 0]\n",
    "\n",
    "# IF NO ASSESSMENT AREA NUMBER, there are 33 problematic areas...\n",
    "### BUT investigation shows they are all duplicates!\n",
    "#city_loans_df[(city_loans_df['nLoans'] > 0) & (city_loans_df['assessment_area_number'].isnull())].groupby(['respondentID', 'activity_year', 'income_group_code']).size().sort_values(ascending=False)[0:33].sort_index()\n",
    "print('dropping duplicate rows...')\n",
    "city_loans_df = city_loans_df[\n",
    "    (city_loans_df['assessment_area_number'].isnull())\n",
    "].drop_duplicates(['respondentID', 'activity_year', 'income_group_total'])\n",
    "\n",
    "print('looking up codes for institution names, income groups, CRA levels...')\n",
    "respondents_df = pandas.read_csv(code_lookup_dir+'respondentid.csv', encoding='utf-8', low_memory=False)\n",
    "city_loans_df = city_loans_df.reset_index().merge(respondents_df, how='left', on='respondentID').set_index('rownumber')\n",
    "\n",
    "city_loans_df = city_loans_df.assign(agency = np.nan)\n",
    "city_loans_df.loc[city_loans_df['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "city_loans_df.loc[city_loans_df['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "city_loans_df.loc[city_loans_df['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "city_loans_df.loc[city_loans_df['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "\n",
    "city_loans_df = city_loans_df.rename(columns = {'income_group_total': 'income_group_code'})\n",
    "city_loans_df = city_loans_df.assign(income_group = np.nan)\n",
    "\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "city_loans_df.loc[city_loans_df['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "city_loans_df = city_loans_df.assign(cra_level = np.nan)\n",
    "city_loans_df.loc[(city_loans_df['income_group_code'] >= 1) & (city_loans_df['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "city_loans_df.loc[(city_loans_df['income_group_code'] >= 6) & (city_loans_df['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "city_loans_df.loc[(city_loans_df['income_group_code'] >= 9) & (city_loans_df['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "city_loans_df.loc[(city_loans_df['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "city_loans_df.loc[(city_loans_df['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "print('calculating working loans...')\n",
    "city_loans_df = city_loans_df.assign(avgSmallLoan = city_loans_df['amtLoans1'] / city_loans_df['nLoans1'])\n",
    "city_loans_df = city_loans_df.assign(nWorkingLoans = np.nan)\n",
    "city_loans_df = city_loans_df.assign(amtWorkingLoans = np.nan)\n",
    "city_loans_df.loc[city_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'nWorkingLoans'] = city_loans_df['nLoans'][city_loans_df['avgSmallLoan'] < 10000] - city_loans_df['nLoans1'][city_loans_df['avgSmallLoan'] < 10000]\n",
    "city_loans_df.loc[city_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'nWorkingLoans'] = city_loans_df['nLoans'][city_loans_df['avgSmallLoan'] >= 10000]\n",
    "city_loans_df.loc[city_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'amtWorkingLoans'] = city_loans_df['amtLoans'][city_loans_df['avgSmallLoan'] < 10000] - city_loans_df['amtLoans1'][city_loans_df['avgSmallLoan'] < 10000]\n",
    "city_loans_df.loc[city_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'amtWorkingLoans'] = city_loans_df['amtLoans'][city_loans_df['avgSmallLoan'] >= 10000]\n",
    "\n",
    "# If lender is American Expres, set working loans to zero\n",
    "city_loans_df.loc[city_loans_df['institution_name'].apply(lambda x: 'american express' in str(x).lower()), 'nWorkingLoans'] = 0\n",
    "city_loans_df.loc[city_loans_df['institution_name'].apply(lambda x: 'american express' in str(x).lower()), 'amtWorkingLoans'] = 0\n",
    "\n",
    "\n",
    "print('setting index...')\n",
    "city_loans_df = city_loans_df.set_index(['respondentID', 'activity_year', 'assessment_area_number', 'income_group_code'])\n",
    "\n",
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest']\n",
    "money_columns += ['amtLoans', 'amtWorkingLoans']\n",
    "\n",
    "print('correcting for inflation...')\n",
    "for x in money_columns:\n",
    "    city_loans_df.loc[:, x] = city_loans_df[x].fillna(0)\n",
    "\n",
    "cpi_1913_2017_df = pandas.read_csv(inflation_dir+'cpi-1913-2017.csv', index_col='Year')\n",
    "cpi_annual_s = cpi_1913_2017_df['Jan']\n",
    "cpi_annual_s.name = 'rawfactor'\n",
    "value_in_2017 = cpi_annual_s.loc[2017]\n",
    "\n",
    "annual_inflator_s = 1 / (cpi_annual_s / value_in_2017)\n",
    "annual_inflator_s.index.name = 'activity_year'\n",
    "\n",
    "print('inflating pre-2017 monetary values...')\n",
    "inflate_these_df = city_loans_df[money_columns]\n",
    "newcolnames = [x+'_adj' for x in inflate_these_df.columns.tolist()]\n",
    "inflate_these_df.columns = newcolnames\n",
    "inflate_these_df = inflate_these_df.reset_index().set_index('activity_year').join(annual_inflator_s).reset_index().set_index(['respondentID', 'activity_year', 'assessment_area_number', 'income_group_code'])\n",
    "for x in newcolnames:\n",
    "    inflate_these_df.loc[:, x] = inflate_these_df[x] * inflate_these_df['rawfactor']\n",
    "inflate_these_df = inflate_these_df.drop('rawfactor', axis=1)\n",
    "city_loans_df = city_loans_df.join(inflate_these_df)\n",
    "\n",
    "writefilename = city_data_dir+'{0:}_loans.csv'.format(cityname_file)\n",
    "print('Saving data to {0:}...'.format(writefilename))\n",
    "city_loans_df.to_csv(writefilename, encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Saved {0:,.0f} rows of loan data for {1:} in {2:,.0f} seconds!'.format(len(city_loans_df), city, e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data aggregated by lenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading nationwide data...\n",
      "read 2,166,112 nationwide lender-years in 6 seconds...\n",
      "selecting originated business loans in St. Louis...\n",
      "looking up institution names from respondentID...\n",
      "looking up agency names from agency_code...\n",
      "setting index to respondent-year...\n",
      "correcting for inflation...\n",
      "inflating pre-2017 monetary values...\n",
      "Saving data to /home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/city_data/st_louis_agg_lenders.csv...\n",
      "Saved 798 lender-years in St. Louis in 1 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading nationwide data...')\n",
    "agg_lenders_df = pandas.read_csv(data_dir+'agg_lenders.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('read {0:,.0f} nationwide lender-years in {1:,.0f} seconds...'.format(len(agg_lenders_df), e-s))\n",
    "\n",
    "s = time.time()\n",
    "print('selecting originated business loans in {0:}...'.format(city))\n",
    "agg_lenders_df = agg_lenders_df[agg_lenders_df['loan_type'] == 4]\n",
    "agg_lenders_df = agg_lenders_df[agg_lenders_df['action_taken_type'] == 1]\n",
    "city_agg_lenders_df = agg_lenders_df[\n",
    "    (agg_lenders_df['state'] == thestate)\n",
    "    & (agg_lenders_df['county'] == thecounty)\n",
    "]\n",
    "\n",
    "print('looking up institution names from respondentID...')\n",
    "respondents_df = pandas.read_csv(code_lookup_dir+'respondentid.csv', encoding='utf-8', low_memory=False)\n",
    "city_agg_lenders_df = city_agg_lenders_df.reset_index().merge(respondents_df, how='left', on='respondentID').set_index('rownumber')\n",
    "\n",
    "print('looking up agency names from agency_code...')\n",
    "city_agg_lenders_df = city_agg_lenders_df.assign(agency = np.nan)\n",
    "city_agg_lenders_df.loc[city_agg_lenders_df['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "city_agg_lenders_df.loc[city_agg_lenders_df['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "city_agg_lenders_df.loc[city_agg_lenders_df['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "city_agg_lenders_df.loc[city_agg_lenders_df['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "\n",
    "print('setting index to respondent-year...')\n",
    "city_agg_lenders_df = city_agg_lenders_df.set_index(['respondentID', 'activity_year'])\n",
    "city_agg_lenders_df = city_agg_lenders_df.sort_index()\n",
    "\n",
    "print('correcting for inflation...')\n",
    "money_columns = ['amtLoans', 'amtLoansToSmallest']\n",
    "\n",
    "for x in money_columns:\n",
    "    city_agg_lenders_df.loc[:, x] = city_agg_lenders_df[x].fillna(0)\n",
    "\n",
    "cpi_1913_2017_df = pandas.read_csv(inflation_dir+'cpi-1913-2017.csv', index_col='Year')\n",
    "cpi_annual_s = cpi_1913_2017_df['Jan']\n",
    "cpi_annual_s.name = 'rawfactor'\n",
    "value_in_2017 = cpi_annual_s.loc[2017]\n",
    "\n",
    "annual_inflator_s = 1 / (cpi_annual_s / value_in_2017)\n",
    "print('inflating pre-2017 monetary values...')\n",
    "inflate_these_df = city_agg_lenders_df[money_columns]\n",
    "newcolnames = [x+'_adj' for x in inflate_these_df.columns.tolist()]\n",
    "inflate_these_df.columns = newcolnames\n",
    "\n",
    "city_agg_lenders_df = city_agg_lenders_df.reset_index().merge(inflate_these_df.reset_index(), how='left', on=['respondentID','activity_year']).set_index(['respondentID','activity_year'])\n",
    "\n",
    "writefilename = city_data_dir+'{0:}_agg_lenders.csv'.format(cityname_file)\n",
    "print('Saving data to {0:}...'.format(writefilename))\n",
    "city_agg_lenders_df.to_csv(writefilename, encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Saved {0:,.0f} lender-years in {1:} in {2:,.0f} seconds!'.format(len(city_agg_lenders_df), city, e-s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data aggregated by census tracts\n",
    "\n",
    "This is the basis for most of our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data for loans aggregated by census tract & year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading nationwide data...\n",
      "read 2,645,400 nationwide tract-years in 11 seconds...\n",
      "selecting originated business loans in St. Louis...\n",
      "looking up income group names from income_group_total...\n",
      "Adding CRA income levels (low/moderate/middle/upper/unknown)...\n",
      "calculating total loans...\n",
      "calculating working loans...\n",
      "Kept 1,540 tract-years in St. Louis in 0.93 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loan_type</th>\n",
       "      <th>action_taken_type</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>msa</th>\n",
       "      <th>split_county_indicator</th>\n",
       "      <th>population_classification</th>\n",
       "      <th>income_group_code</th>\n",
       "      <th>nLoans1</th>\n",
       "      <th>amtLoans1</th>\n",
       "      <th>...</th>\n",
       "      <th>amtLoans250k</th>\n",
       "      <th>nLoansToSmallest</th>\n",
       "      <th>amtLoansToSmallest</th>\n",
       "      <th>income_group</th>\n",
       "      <th>cra_level</th>\n",
       "      <th>nLoans</th>\n",
       "      <th>amtLoans</th>\n",
       "      <th>avgSmallLoan</th>\n",
       "      <th>nWorkingLoans</th>\n",
       "      <th>amtWorkingLoans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>census_tract</th>\n",
       "      <th>activity_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011.0</th>\n",
       "      <th>2004</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>510</td>\n",
       "      <td>41180.0</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>103</td>\n",
       "      <td>25</td>\n",
       "      <td>128000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>24000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>303000</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            loan_type  action_taken_type  state  county  \\\n",
       "census_tract activity_year                                                \n",
       "1011.0       2004           4          1                  29     510      \n",
       "\n",
       "                                msa split_county_indicator  \\\n",
       "census_tract activity_year                                   \n",
       "1011.0       2004           41180.0  N                       \n",
       "\n",
       "                           population_classification  income_group_code  \\\n",
       "census_tract activity_year                                                \n",
       "1011.0       2004           S                         103                 \n",
       "\n",
       "                            nLoans1  amtLoans1       ...         amtLoans250k  \\\n",
       "census_tract activity_year                           ...                        \n",
       "1011.0       2004           25       128000          ...         0              \n",
       "\n",
       "                            nLoansToSmallest  amtLoansToSmallest  \\\n",
       "census_tract activity_year                                         \n",
       "1011.0       2004           6                 24000                \n",
       "\n",
       "                            income_group  cra_level  nLoans amtLoans  \\\n",
       "census_tract activity_year                                             \n",
       "1011.0       2004           NaN           NaN        26      303000    \n",
       "\n",
       "                           avgSmallLoan  nWorkingLoans  amtWorkingLoans  \n",
       "census_tract activity_year                                               \n",
       "1011.0       2004           5120.0       1.0            175000.0         \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('reading nationwide data...')\n",
    "agg_loans_df = pandas.read_csv(data_dir+'agg_loans.csv', encoding='utf-8', low_memory=False, index_col='rownumber')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('read {0:,.0f} nationwide tract-years in {1:,.0f} seconds...'.format(len(agg_loans_df), e-s))\n",
    "\n",
    "s = time.time()\n",
    "print('selecting originated business loans in {0:}...'.format(city))\n",
    "# Keep only business loans\n",
    "agg_loans_df = agg_loans_df[agg_loans_df['loan_type'] == 4]\n",
    "# Keep only loan originations\n",
    "agg_loans_df = agg_loans_df[agg_loans_df['action_taken_type'] == 1]\n",
    "\n",
    "# Keep only loans in the city of interest\n",
    "city_agg_loans_df = agg_loans_df[\n",
    "    (agg_loans_df['state'] == thestate)\n",
    "    & (agg_loans_df['county'] == thecounty)\n",
    "]\n",
    "\n",
    "print('looking up income group names from income_group_total...')\n",
    "city_agg_loans_df = city_agg_loans_df.rename(columns = {'income_group_total': 'income_group_code'})\n",
    "city_agg_loans_df = city_agg_loans_df.assign(income_group = np.nan)\n",
    "\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "city_agg_loans_df.loc[city_agg_loans_df['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "\n",
    "print('Adding CRA income levels (low/moderate/middle/upper/unknown)...')\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "city_agg_loans_df = city_agg_loans_df.assign(cra_level = np.nan)\n",
    "city_agg_loans_df.loc[(city_agg_loans_df['income_group_code'] >= 1) & (city_agg_loans_df['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "city_agg_loans_df.loc[(city_agg_loans_df['income_group_code'] >= 6) & (city_agg_loans_df['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "city_agg_loans_df.loc[(city_agg_loans_df['income_group_code'] >= 9) & (city_agg_loans_df['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "city_agg_loans_df.loc[(city_agg_loans_df['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "city_agg_loans_df.loc[(city_agg_loans_df['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "print('calculating total loans...')\n",
    "city_agg_loans_df = city_agg_loans_df.assign(nLoans = city_agg_loans_df['nLoans1'] + city_agg_loans_df['nLoans100k'] + city_agg_loans_df['nLoans250k'])\n",
    "city_agg_loans_df = city_agg_loans_df.assign(amtLoans = city_agg_loans_df['amtLoans1'] + city_agg_loans_df['amtLoans100k'] + city_agg_loans_df['amtLoans250k'])\n",
    "\n",
    "print('calculating working loans...')\n",
    "city_agg_loans_df = city_agg_loans_df.assign(avgSmallLoan = city_agg_loans_df['amtLoans1'] / city_agg_loans_df['nLoans1'])\n",
    "\n",
    "city_agg_loans_df = city_agg_loans_df.assign(nWorkingLoans = np.nan)\n",
    "city_agg_loans_df.loc[city_agg_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'nWorkingLoans'] = city_agg_loans_df['nLoans'][city_agg_loans_df['avgSmallLoan'] < 10000] - city_agg_loans_df['nLoans1'][city_agg_loans_df['avgSmallLoan'] < 10000]\n",
    "city_agg_loans_df.loc[city_agg_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'nWorkingLoans'] = city_agg_loans_df['nLoans'][city_agg_loans_df['avgSmallLoan'] >= 10000]\n",
    "\n",
    "city_agg_loans_df = city_agg_loans_df.assign(amtWorkingLoans = np.nan)\n",
    "city_agg_loans_df.loc[city_agg_loans_df['avgSmallLoan'] < 10000, \n",
    "                           'amtWorkingLoans'] = city_agg_loans_df['amtLoans'][city_agg_loans_df['avgSmallLoan'] < 10000] - city_agg_loans_df['amtLoans1'][city_agg_loans_df['avgSmallLoan'] < 10000]\n",
    "city_agg_loans_df.loc[city_agg_loans_df['avgSmallLoan'] >= 10000, \n",
    "                           'amtWorkingLoans'] = city_agg_loans_df['amtLoans'][city_agg_loans_df['avgSmallLoan'] >= 10000]\n",
    "\n",
    "city_agg_loans_df.sample(1).T#.groupby('population_classification').size()\n",
    "\n",
    "\n",
    "# Each row is unique to census-tract and year, so set that as the index\n",
    "city_agg_loans_df = city_agg_loans_df.set_index(['census_tract', 'activity_year'])\n",
    "city_agg_loans_df = city_agg_loans_df.sort_index()\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "\n",
    "print('Kept {0:,.0f} tract-years in {1:} in {2:,.2f} seconds!'.format(len(city_agg_loans_df), city, e-s))\n",
    "city_agg_loans_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's connect geographic aggregates to other geographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get jobs data for this state and keep city jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading state jobs data for MO...\n",
      "Read 21,579,712 rows in 158 seconds...\n",
      "Kept 1,458,186 rows in 103 seconds!\n"
     ]
    }
   ],
   "source": [
    "print('reading state jobs data for {0:}...'.format(state_abbrev.upper()))\n",
    "s = time.time()\n",
    "state_raw_jobs_df = pandas.read_csv(jobs_dir+'jobs_data_{0:}.csv'.format(state_abbrev), index_col='rownumber')\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Read {0:,.0f} rows in {1:,.0f} seconds...'.format(len(state_raw_jobs_df), e-s))\n",
    "s = time.time()\n",
    "city_raw_jobs_df = state_raw_jobs_df[\n",
    "    (state_raw_jobs_df['w_geocode'].apply(lambda x: int(str(x)[0:2]) == thestate))\n",
    "    & (state_raw_jobs_df['w_geocode'].apply(lambda x: int(str(x)[2:5]) == thecounty))\n",
    " ]\n",
    "\n",
    "e = time.time()\n",
    "g = g + (e-s)\n",
    "print('Kept {0:,.0f} rows in {1:,.0f} seconds!'.format(len(city_raw_jobs_df), e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting census tracts from GEOIDs...\n",
      "joining jobs data onto loans data from 2011 to 2017...\n",
      "Processed 749 rows in 10.2 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "print('getting census tracts from GEOIDs...')\n",
    "# GeoID format is STATE+COUNTY+TRACT+BLOCK (2+3+6+4 = 15 characters)\n",
    "city_raw_jobs_df = city_raw_jobs_df.assign(census_tract = pandas.to_numeric(city_raw_jobs_df['w_geocode'].apply(lambda x: str(x)[5:9] + '.' + str(x)[9:11]), errors='coerce'))\n",
    "\n",
    "sum_columns = [x for x in city_raw_jobs_df.columns.tolist() if x not in ('w_geocode', 'createdate', 'year')]\n",
    "\n",
    "\n",
    "city_jobs_df = pandas.DataFrame()\n",
    "\n",
    "for i in range(2017, 2010, -1):\n",
    "    city_jobs_i_df = city_raw_jobs_df[sum_columns][city_raw_jobs_df['year'] == i].groupby('census_tract', as_index=False).sum()\n",
    "    if (i >= 2016):\n",
    "        city_jobs_i_df = city_raw_jobs_df[sum_columns][city_raw_jobs_df['year'] == 2015].groupby('census_tract', as_index=False).sum()\n",
    "    city_jobs_i_df = city_jobs_i_df.assign(year = i)\n",
    "    city_jobs_df = pandas.concat((city_jobs_df, city_jobs_i_df), axis=0)\n",
    "\n",
    "city_jobs_df = city_jobs_df.rename(columns={'year': 'activity_year'})\n",
    "city_jobs_df = city_jobs_df.set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('joining jobs data onto loans data from 2011 to 2017...')\n",
    "city_tracts_years_df = city_agg_loans_df.reset_index()[city_agg_loans_df.reset_index()['activity_year'] >= 2011].set_index(['census_tract', 'activity_year'])\n",
    "city_tracts_years_df = city_tracts_years_df.join(city_jobs_df)\n",
    "\n",
    "e = time.time()\n",
    "print('Processed {0:,.0f} rows in {1:,.1f} seconds!'.format(len(city_tracts_years_df), e-s))\n",
    "#city_tracts_years_df.sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What jobs columns do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable: C000\t\tdescription:Total number of jobs\n",
      "variable: CFS01\t\tdescription:Number of jobs for workers at firms with Firm Size: 0-19 Employees\n"
     ]
    }
   ],
   "source": [
    "jobs_metadata_df = pandas.read_csv(code_lookup_dir+'wac_jobs_metadata.csv', encoding='utf-8', index_col='varnum')\n",
    "jobs_metadata_df = jobs_metadata_df.set_index('variable')\n",
    "\n",
    "jobs_columns = ['C000', 'CA01', 'CA02', 'CA03', 'CE01', 'CE02', 'CE03', 'CNS01']\n",
    "jobs_columns += ['CNS02', 'CNS03', 'CNS04', 'CNS05', 'CNS06', 'CNS07', 'CNS08']\n",
    "jobs_columns += ['CNS09', 'CNS10', 'CNS11', 'CNS12', 'CNS13', 'CNS14', 'CNS15']\n",
    "jobs_columns += ['CNS16', 'CNS17', 'CNS18', 'CNS19', 'CNS20', 'CR01', 'CR02']\n",
    "jobs_columns += ['CR03', 'CR04', 'CR05', 'CR07', 'CT01', 'CT02', 'CD01', 'CD02']\n",
    "jobs_columns += ['CD03', 'CD04', 'CS01', 'CS02', 'CFA01', 'CFA02', 'CFA03']\n",
    "jobs_columns += ['CFA04', 'CFA05', 'CFS01', 'CFS02', 'CFS03', 'CFS04', 'CFS05']\n",
    "\n",
    "#for x in baltimore_agg_loans_df[jobs_columns].columns:\n",
    "#    print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n",
    "    \n",
    "jobs_columns_we_want = ['C000', 'CFS01']\n",
    "for x in city_tracts_years_df[jobs_columns_we_want].columns:\n",
    "    print('variable: {0:}\\t\\tdescription:{1:}'.format(x, jobs_metadata_df['description'][jobs_metadata_df.index == x].tolist()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get loans per job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calulating loans per job (total and with firm size 0-19)...\n",
      "recoding infinite values to NaN...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#sbjobs_column = jobs_varnames_df[jobs_varnames_df['description'].apply(lambda x: '0-19' in x)].index.values[0]\n",
    "#loans_columns = []\n",
    "#city_tracts_years_df[sbjobs_column]\n",
    "print('Calulating loans per job (total and with firm size 0-19)...')\n",
    "\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans1_per_totaljob = city_tracts_years_df['nLoans1'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans1_per_totaljob = city_tracts_years_df['amtLoans1'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans100k_per_totaljob = city_tracts_years_df['nLoans100k'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans100k_per_totaljob = city_tracts_years_df['amtLoans100k'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans250k_per_totaljob = city_tracts_years_df['nLoans250k'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans250k_per_totaljob = city_tracts_years_df['amtLoans250k'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoansToSmallest_per_totaljob = city_tracts_years_df['nLoansToSmallest'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoansToSmallest_per_totaljob = city_tracts_years_df['amtLoansToSmallest'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans_per_totaljob = city_tracts_years_df['nLoans'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans_per_totaljob = city_tracts_years_df['amtLoans'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nWorkingLoans_per_totaljob = city_tracts_years_df['nWorkingLoans'] / city_tracts_years_df['C000'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtWorkingLoans_per_totaljob = city_tracts_years_df['amtWorkingLoans'] / city_tracts_years_df['C000'])\n",
    "\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans1_per_sbjob = city_tracts_years_df['nLoans1'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans1_per_sbjob = city_tracts_years_df['amtLoans1'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans100k_per_sbjob = city_tracts_years_df['nLoans100k'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans100k_per_sbjob = city_tracts_years_df['amtLoans100k'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans250k_per_sbjob = city_tracts_years_df['nLoans250k'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans250k_per_sbjob = city_tracts_years_df['amtLoans250k'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoansToSmallest_per_sbjob = city_tracts_years_df['nLoansToSmallest'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoansToSmallest_per_sbjob = city_tracts_years_df['amtLoansToSmallest'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nLoans_per_sbjob = city_tracts_years_df['nLoans'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtLoans_per_sbjob = city_tracts_years_df['amtLoans'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(nWorkingLoans_per_sbjob = city_tracts_years_df['nWorkingLoans'] / city_tracts_years_df['CFS01'])\n",
    "city_tracts_years_df = city_tracts_years_df.assign(amtWorkingLoans_per_sbjob = city_tracts_years_df['amtWorkingLoans'] / city_tracts_years_df['CFS01'])\n",
    "\n",
    "print('recoding infinite values to NaN...')\n",
    "\n",
    "per_job_columns = ['nLoans1_per_totaljob', 'amtLoans1_per_totaljob', 'nLoans100k_per_totaljob']\n",
    "per_job_columns += ['amtLoans100k_per_totaljob', 'nLoans250k_per_totaljob', 'amtLoans250k_per_totaljob']\n",
    "per_job_columns += ['nLoansToSmallest_per_totaljob', 'amtLoansToSmallest_per_totaljob']\n",
    "per_job_columns += ['nLoans_per_totaljob', 'amtLoans_per_totaljob', 'nWorkingLoans_per_totaljob']\n",
    "per_job_columns += ['amtWorkingLoans_per_totaljob', 'nLoans1_per_sbjob', 'amtLoans1_per_sbjob']\n",
    "per_job_columns += ['nLoans100k_per_sbjob', 'amtLoans100k_per_sbjob', 'nLoans250k_per_sbjob']\n",
    "per_job_columns += ['amtLoans250k_per_sbjob', 'nLoansToSmallest_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "per_job_columns += ['nLoans_per_sbjob', 'amtLoans_per_sbjob', 'nWorkingLoans_per_sbjob']\n",
    "per_job_columns += ['amtWorkingLoans_per_sbjob']\n",
    "\n",
    "for x in city_tracts_years_df[per_job_columns]:\n",
    "    city_tracts_years_df.loc[city_tracts_years_df[x] == np.inf, x] = np.nan\n",
    "\n",
    "print('Done!')\n",
    "#city_tracts_years_df.sample(2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping only Baltimore City tracts...\n",
      "converting to numeric...\n",
      "calculating census tract numbers...\n",
      "keeping 2011-2017...\n",
      "dropping block groups to avoid double-counting...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "md_acs5_df = pandas.DataFrame()\n",
    "datafiles = [census_dir+x for x in os.listdir(census_dir) if (('tracts' in x) and ('{0:}'.format(state_abbrev) in x) and ('alldata' not in x))]\n",
    "\n",
    "for thisfile in datafiles:\n",
    "    xdf = pandas.read_csv(thisfile, encoding='utf-8', low_memory=False)\n",
    "    xdf = xdf.assign(year = int(thisfile[-10:-6]))\n",
    "    md_acs5_df = md_acs5_df.append(xdf)\n",
    "\n",
    "column_order = md_acs5_df.columns[0:1].tolist()\n",
    "column_order += md_acs5_df.columns[-1:].tolist()\n",
    "column_order += md_acs5_df.columns[1:-1].tolist()\n",
    "###column_order += md_acs5_df.columns[-3:].tolist()\n",
    "\n",
    "md_acs5_df = md_acs5_df[column_order]\n",
    "print('keeping only Baltimore City tracts...')\n",
    "md_acs5_df = md_acs5_df[md_acs5_df['GEOID'].apply(lambda x: 'US24510' in x)]\n",
    "\n",
    "print('converting to numeric...')\n",
    "for x in md_acs5_df.columns[4:-2]:\n",
    "    md_acs5_df.loc[:, x] = pandas.to_numeric(md_acs5_df[x], errors='coerce')\n",
    "\n",
    "print('calculating census tract numbers...')\n",
    "md_acs5_df.loc[:, 'census_tract'] = md_acs5_df['GEOID'].apply(lambda x: x[12:18])\n",
    "md_acs5_df.loc[:, 'census_tract'] = pandas.to_numeric(md_acs5_df['census_tract'], errors='coerce')\n",
    "md_acs5_df.loc[:, 'census_tract'] = md_acs5_df['census_tract'].apply(lambda x: x/100) # get right decimalization of census tracts\n",
    "md_acs5_df = md_acs5_df.assign(block_group = np.nan)\n",
    "md_acs5_df.loc[md_acs5_df['GEOID'].apply(lambda x:len(x)) == 19, \n",
    "            'block_group'] = md_acs5_df['GEOID'][md_acs5_df['GEOID'].apply(lambda x:len(x)) == 19].apply(lambda x: x[18])\n",
    "md_acs5_df.loc[:, 'block_group'] = pandas.to_numeric(md_acs5_df['block_group'], errors='coerce')\n",
    "\n",
    "print('keeping 2011-2017...')\n",
    "md_acs5_df = md_acs5_df[md_acs5_df['year'] >= 2011]\n",
    "\n",
    "print('dropping block groups to avoid double-counting...')\n",
    "md_acs5_df = md_acs5_df[md_acs5_df['block_group'].isnull()]  # select only census tracts (ignore block groups) to avoid double-counting\n",
    "md_acs5_df = md_acs5_df.drop('block_group', axis=1)\n",
    "\n",
    "md_acs5_df = md_acs5_df.rename(columns={'year': 'activity_year'})\n",
    "md_acs5_df = md_acs5_df.set_index(['census_tract', 'activity_year'])\n",
    "md_acs5_df = md_acs5_df.sort_index()\n",
    "#md_acs5_df.reset_index()\n",
    "#baltimore_agg_loans_df.reset_index()\n",
    "city_tracts_years_df = city_tracts_years_df.reset_index().merge(md_acs5_df.reset_index(), how='left', on=['census_tract', 'activity_year']).set_index(['census_tract', 'activity_year'])\n",
    "print('ok')\n",
    "#city_tracts_years_df.sample(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate composite demographic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating and renaming estimates columns for IVs...\n",
      "...high school graduates or higher 25 years and older...\n",
      "...householder sex & race, unempoyment, poverty, home value, home age...\n",
      "...total householders...\n",
      "...race, owner-occupied units, mfi...\n",
      "....comparison variables: total population, total households, poverty status...\n",
      "...population 25plus...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('\\ncalculating and renaming estimates columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...high school graduates or higher 25 years and older...')\n",
    "h = city_tracts_years_df['B15002_011'] + city_tracts_years_df['B15002_012'] + city_tracts_years_df['B15002_013'] \n",
    "h += city_tracts_years_df['B15002_014'] + city_tracts_years_df['B15002_015'] + city_tracts_years_df['B15002_016']\n",
    "h += city_tracts_years_df['B15002_017'] + city_tracts_years_df['B15002_018']\n",
    "h += city_tracts_years_df['B15002_028'] + city_tracts_years_df['B15002_029'] + city_tracts_years_df['B15002_030'] \n",
    "h += city_tracts_years_df['B15002_031'] + city_tracts_years_df['B15002_032'] + city_tracts_years_df['B15002_033'] \n",
    "h += city_tracts_years_df['B15002_034'] + city_tracts_years_df['B15002_035']\n",
    "city_tracts_years_df = city_tracts_years_df.assign(hs_grad_25plus = pandas.to_numeric(h, errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {     \n",
    "    'B11001_006': 'female_householder',\n",
    "    'B11001A_001': 'white_householder',\n",
    "    'B11001B_001': 'black_householder',\n",
    "    'B23025_005': 'unemployed_16plus',\n",
    "    'B17001_002': 'poverty_past_12_months',\n",
    "    'B25077_001': 'median_home_value',\n",
    "    'B25035_001': 'median_year_built'\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...total householders...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(total_householders = pandas.to_numeric(\n",
    "                                             (city_tracts_years_df['B11001_002'] + city_tracts_years_df['B11001_007']\n",
    "                                             ), errors='coerce'\n",
    "                                         )\n",
    "                                        )\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {\n",
    "    'B02001_002': 'pop_white',\n",
    "    'B02001_003': 'pop_black',\n",
    "    'B25003_002': 'owner_occ_housing_units',\n",
    "    'B19113_001': 'mfi'    \n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('....comparison variables: total population, total households, poverty status...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {\n",
    "    'B01001_001': 'pop_total',\n",
    "    'B23025_002': 'labor_force_16plus',\n",
    "    'B17001_001': 'poverty_status_known'\n",
    "})\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pop_25plus = pandas.to_numeric(\n",
    "                                             (city_tracts_years_df['B01001_011'] + city_tracts_years_df['B01001_012'] + city_tracts_years_df['B01001_013'] \n",
    "                                              + city_tracts_years_df['B01001_014'] + city_tracts_years_df['B01001_015'] + city_tracts_years_df['B01001_016']\n",
    "                                              + city_tracts_years_df['B01001_017'] + city_tracts_years_df['B01001_018'] + city_tracts_years_df['B01001_019']\n",
    "                                              + city_tracts_years_df['B01001_020'] + city_tracts_years_df['B01001_021'] + city_tracts_years_df['B01001_022']\n",
    "                                              + city_tracts_years_df['B01001_023'] + city_tracts_years_df['B01001_024'] + city_tracts_years_df['B01001_025']\n",
    "                                              + city_tracts_years_df['B01001_035'] + city_tracts_years_df['B01001_036'] + city_tracts_years_df['B01001_037']\n",
    "                                              + city_tracts_years_df['B01001_038'] + city_tracts_years_df['B01001_039'] + city_tracts_years_df['B01001_040']\n",
    "                                              + city_tracts_years_df['B01001_041'] + city_tracts_years_df['B01001_042'] + city_tracts_years_df['B01001_043']\n",
    "                                              + city_tracts_years_df['B01001_044'] + city_tracts_years_df['B01001_045'] + city_tracts_years_df['B01001_046']\n",
    "                                              + city_tracts_years_df['B01001_047'] + city_tracts_years_df['B01001_048'] + city_tracts_years_df['B01001_049']\n",
    "                                             ), errors='coerce'\n",
    "                                         )\n",
    "                                        )\n",
    "#city_tracts_years_df.sample(1).T\n",
    "\n",
    "print('Done!')\n",
    "#city_tracts_years_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get errors for composite columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined standard-error-calculating functions!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "### Guide on how to calculate errors in percentages:\n",
    "# https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "    \n",
    "## Aggregating Data Across Population Subgroups: add error for each group in quadrature, divide by 1.645 for serr\n",
    "\n",
    "def find_serr_hsgrad25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B15002_011_err']**2 + row['B15002_012_err']**2 + row['B15002_013_err']**2 \n",
    "                                 + row['B15002_014_err']**2 + row['B15002_015_err']**2 + row['B15002_016_err']**2 \n",
    "                                 + row['B15002_017_err']**2 + row['B15002_018_err']**2 + \n",
    "                                 + row['B15002_028_err']**2 + row['B15002_029_err']**2 + row['B15002_030_err']**2 \n",
    "                                 + row['B15002_031_err']**2 + row['B15002_032_err']**2 + row['B15002_033_err']**2 \n",
    "                                 + row['B15002_034_err']**2 + row['B15002_035_err']**2\n",
    "                                ) / 1.645, errors='coerce')\n",
    "\n",
    "def find_serr_householders(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B11001_002_err']**2 + row['B11001_007_err']**2 \n",
    "                                ) / 1.645, errors='coerce')\n",
    "\n",
    "def find_serr_pop25plus(row):\n",
    "    return pandas.to_numeric(np.sqrt(row['B01001_011_err']**2 + row['B01001_012_err']**2 + row['B01001_013_err']**2 \n",
    "                                     + row['B01001_014_err']**2 + row['B01001_015_err']**2 + row['B01001_016_err']**2 \n",
    "                                     + row['B01001_017_err']**2 + row['B01001_018_err']**2 + row['B01001_019_err']**2 \n",
    "                                     + row['B01001_020_err']**2 + row['B01001_021_err']**2 + row['B01001_022_err']**2 \n",
    "                                     + row['B01001_023_err']**2 + row['B01001_024_err']**2 + row['B01001_025_err']**2 \n",
    "                                     + row['B01001_035_err']**2 + row['B01001_036_err']**2 + row['B01001_037_err']**2 \n",
    "                                     + row['B01001_038_err']**2 + row['B01001_039_err']**2 + row['B01001_040_err']**2 \n",
    "                                     + row['B01001_041_err']**2 + row['B01001_042_err']**2 + row['B01001_043_err']**2 \n",
    "                                     + row['B01001_044_err']**2 + row['B01001_045_err']**2 + row['B01001_046_err']**2 \n",
    "                                     + row['B01001_047_err']**2 + row['B01001_048_err']**2 + row['B01001_049_err']**2 \n",
    "                                    ) / 1.645, errors='coerce')\n",
    "print('Defined standard-error-calculating functions!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating and renaming margins of error columns for IVs...\n",
      "...margins for race, owner-occupied units, mfi...\n",
      "...standard errors for hs graduates 25 and older (using custom serr-finding function...\n",
      "...margins of error for householder sex & race, unempoyment, poverty, home value, home age...\n",
      "\n",
      "calculating and renaming margins of error for comparison variables...\n",
      "...race, owner-occupied units, mfi...\n",
      "...population 25plus...\n",
      "...total householders...\n",
      "...labor force, poverty status known...\n",
      "dropping columns we do not care about...\n",
      "Calculated errors for all columns!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('\\ncalculating and renaming margins of error columns for IVs...')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins for race, owner-occupied units, mfi...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {\n",
    "    'B02001_002_err': 'pop_white_err',\n",
    "    'B02001_003_err': 'pop_black_err',\n",
    "    'B25003_002_err': 'owner_occ_housing_units_err',\n",
    "    'B19113_001_err': 'mfi_err'    \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...standard errors for hs graduates 25 and older (using custom serr-finding function...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(hs_grad_25plus_serr = pandas.to_numeric(city_tracts_years_df.apply(lambda row: find_serr_hsgrad25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...margins of error for householder sex & race, unempoyment, poverty, home value, home age...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {     \n",
    "    'B11001_006_err': 'female_householder_err',\n",
    "    'B11001A_001_err': 'black_householder_err',\n",
    "    'B11001B_001_err': 'white_householder_err',\n",
    "    'B23025_005_err': 'unemployed_16plus_err',\n",
    "    'B17001_002_err': 'poverty_past_12_months_err',\n",
    "    'B25077_001_err': 'median_home_value_err',\n",
    "    'B25035_001_err': 'median_year_built_err'\n",
    "})\n",
    "\n",
    "print('\\ncalculating and renaming margins of error for comparison variables...')\n",
    "if (debug >= 1):\n",
    "    print('...race, owner-occupied units, mfi...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {\n",
    "    'B01001_001_err': 'pop_total_err',\n",
    "    'B17001_001_err': 'poverty_status_known_err'\n",
    "})\n",
    "if (debug >= 1):\n",
    "    print('...population 25plus...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pop_25plus_serr = pandas.to_numeric(city_tracts_years_df.apply(lambda row: find_serr_pop25plus(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...total householders...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(total_householders_serr = pandas.to_numeric(city_tracts_years_df.apply(lambda row: find_serr_householders(row), axis=1), errors='coerce'))\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('...labor force, poverty status known...')\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {\n",
    "    'B23025_002_err': 'labor_force_16plus_err',\n",
    "    'B17001_001_err': 'poverty_status_known_err'\n",
    "})\n",
    "\n",
    "\n",
    "print('dropping columns we do not care about...')\n",
    "columns_do_not_care = ['B15002_011','B15002_012','B15002_013','B15002_014','B15002_015']\n",
    "columns_do_not_care += ['B15002_016','B15002_017','B15002_018','B15002_028','B15002_029']\n",
    "columns_do_not_care += ['B15002_030','B15002_031','B15002_032','B15002_033','B15002_034']\n",
    "columns_do_not_care += ['B15002_035','B01001_011','B01001_012','B01001_013','B01001_014']\n",
    "columns_do_not_care += ['B01001_015','B01001_016','B01001_017','B01001_018','B01001_019']\n",
    "columns_do_not_care += ['B01001_020','B01001_021','B01001_022','B01001_023','B01001_024']\n",
    "columns_do_not_care += ['B01001_025','B01001_035','B01001_036','B01001_037','B01001_038']\n",
    "columns_do_not_care += ['B01001_039','B01001_040','B01001_041','B01001_042','B01001_043']\n",
    "columns_do_not_care += ['B01001_044','B01001_045','B01001_046','B01001_047','B01001_048']\n",
    "columns_do_not_care += ['B01001_049', 'B11001_002', 'B11001_007']\n",
    "columns_do_not_care += ['B15002_011_err','B15002_012_err','B15002_013_err']\n",
    "columns_do_not_care += ['B15002_014_err','B15002_015_err','B15002_016_err']\n",
    "columns_do_not_care += ['B15002_017_err','B15002_018_err','B15002_028_err']\n",
    "columns_do_not_care += ['B15002_029_err','B15002_030_err','B15002_031_err']\n",
    "columns_do_not_care += ['B15002_032_err','B15002_033_err','B15002_034_err']\n",
    "columns_do_not_care += ['B15002_035_err','B15002_011_err','B15002_012_err']\n",
    "columns_do_not_care += ['B15002_013_err','B15002_014_err','B15002_015_err']\n",
    "columns_do_not_care += ['B15002_016_err','B15002_017_err','B15002_018_err']\n",
    "columns_do_not_care += ['B15002_028_err','B15002_029_err','B15002_030_err']\n",
    "columns_do_not_care += ['B15002_031_err','B15002_032_err','B15002_033_err']\n",
    "columns_do_not_care += ['B15002_034_err','B15002_035_err','B01001_011_err']\n",
    "columns_do_not_care += ['B01001_012_err','B01001_013_err','B01001_014_err']\n",
    "columns_do_not_care += ['B01001_015_err','B01001_016_err','B01001_017_err']\n",
    "columns_do_not_care += ['B01001_018_err','B01001_019_err','B01001_020_err']\n",
    "columns_do_not_care += ['B01001_021_err','B01001_022_err','B01001_023_err']\n",
    "columns_do_not_care += ['B01001_024_err','B01001_025_err','B01001_035_err']\n",
    "columns_do_not_care += ['B01001_036_err','B01001_037_err','B01001_038_err']\n",
    "columns_do_not_care += ['B01001_039_err','B01001_040_err','B01001_041_err']\n",
    "columns_do_not_care += ['B01001_042_err','B01001_043_err','B01001_044_err']\n",
    "columns_do_not_care += ['B01001_045_err','B01001_046_err','B01001_047_err']\n",
    "columns_do_not_care += ['B11001_002_err','B11001_007_err']\n",
    "\n",
    "columns_do_not_care += ['B01001_048_err','B01001_049_err','STATE']\n",
    "city_tracts_years_df = city_tracts_years_df.drop(columns_do_not_care, axis=1)\n",
    "\n",
    "\n",
    "print('Calculated errors for all columns!')\n",
    "\n",
    "#city_tracts_years_df.sample(2)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "vars_for_percentification = ['pop_white', 'pop_black', 'black_householder', 'white_householder']\n",
    "vars_for_percentification += ['owner_occ_housing_units', 'hs_grad_25plus', 'female_householder']\n",
    "vars_for_percentification += ['unemployed_16plus', 'poverty_past_12_months']\n",
    "\n",
    "vars_for_percentification += ['pop_white_err', 'pop_black_err', 'black_householder_err', 'white_householder_err']\n",
    "vars_for_percentification += ['owner_occ_housing_units_err', 'hs_grad_25plus_serr', 'female_householder_err']\n",
    "vars_for_percentification += ['unemployed_16plus_err', 'poverty_past_12_months_err']\n",
    "\n",
    "vars_for_percentification += ['pop_total', 'total_householders', 'pop_25plus', 'labor_force_16plus']\n",
    "vars_for_percentification += ['poverty_status_known']\n",
    "\n",
    "vars_for_percentification += ['pop_total_err', 'total_householders_serr', 'pop_25plus_serr', 'labor_force_16plus_err']\n",
    "vars_for_percentification += ['poverty_status_known_err']\n",
    "vars_for_percentification\n",
    "#city_tracts_years_df[vars_for_percentification].columns.tolist()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate percentages for needed demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#[x for x in vars_for_percentification if \"_err\" not in x]\n",
    "\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_white = pandas.to_numeric((city_tracts_years_df['pop_white'] / city_tracts_years_df['pop_total']), errors='coerce'))\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_black = pandas.to_numeric((city_tracts_years_df['pop_black'] / city_tracts_years_df['pop_total']), errors='coerce'))\n",
    "\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_white_householders = pandas.to_numeric((city_tracts_years_df['white_householder'] / city_tracts_years_df['total_householders']), errors='coerce'))\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_black_householders = pandas.to_numeric((city_tracts_years_df['black_householder'] / city_tracts_years_df['total_householders']), errors='coerce'))\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_female_householders = pandas.to_numeric((city_tracts_years_df['female_householder'] / city_tracts_years_df['total_householders']), errors='coerce'))\n",
    "\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_hs_grad = pandas.to_numeric(city_tracts_years_df['hs_grad_25plus'], errors='coerce') / pandas.to_numeric(city_tracts_years_df['pop_25plus'], errors='coerce'))\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_unemployed = pandas.to_numeric(city_tracts_years_df['unemployed_16plus'], errors='coerce') / pandas.to_numeric(city_tracts_years_df['labor_force_16plus'], errors='coerce'))\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_unemployed = pandas.to_numeric(city_tracts_years_df['poverty_past_12_months'], errors='coerce') / pandas.to_numeric(city_tracts_years_df['poverty_status_known'], errors='coerce'))\n",
    "\n",
    "print('ok')\n",
    "#city_tracts_years_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate errors in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined functions to calculate standard errors in percentages!\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Guide on how to do this:\n",
    "#### https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch08.pdf\n",
    "\n",
    "# X and Y are the measured values (not the errors) - X for the subsgroup and Y for the whole sample\n",
    "# Let P = X/Y  (the proportion we calculated in the last step)\n",
    "# dX and dY are the measured errors\n",
    "# dP = (1/Y) * np.sqrt(dX**2 - (P**2 * dY**2))\n",
    "# Standard error of P is dP/1.645\n",
    "#### this calculation is done verbosely in fnid_pop_white_serr, quickly in other functions\n",
    "\n",
    "def find_errors_in_pct(X, Y, dX, dY, verboselevel = 0):\n",
    "    try:\n",
    "        P = X / Y\n",
    "        oneoverY = 1 / Y\n",
    "        dXsq = dX**2\n",
    "        dYsq = dY**2\n",
    "        Psq = P**2\n",
    "        PsqdYsq = Psq * dYsq\n",
    "        if (PsqdYsq <= dXsq):\n",
    "            underroot = dXsq - PsqdYsq\n",
    "        else:\n",
    "            underroot = dXsq + PsqdYsq\n",
    "        rooty = np.sqrt(underroot)\n",
    "        dP = oneoverY * rooty\n",
    "        SE = dP / 1.645\n",
    "        if (verboselevel >= 2):\n",
    "#            print('X = pop_white, Y = pop_total')\n",
    "            print('X = {0:.0f}, dX = {1:.0f} ({2:.1%} error)'.format(X, dX, dX/X))\n",
    "            print('Y = {0:.0f}, dY = {1:.0f} ({2:.1%} error)'.format(Y, dY, dY/Y))\n",
    "        if (verboselevel >= 3):\n",
    "            print('P = {0:.3f}'.format(P))\n",
    "            print('dXsq = {0:.0f}, dYsq = {1:.0f}, Psq = {2:.3f}'.format(dXsq, dYsq, Psq))\n",
    "            print('PsqdYsq = {0:.0f}, underroot = {1:.0f}, rooty = {2:.3f}'.format(PsqdYsq, underroot, rooty))\n",
    "            print('dP = {0:.3f}'.format(dP))\n",
    "            print('SE = {0:.3f}'.format(SE))\n",
    "        if (verboselevel >= 2):\n",
    "            print('RESULT: {0:.2%} +/- {1:.2%}'.format(P, SE)) \n",
    "            print('\\n')\n",
    "        return pandas.to_numeric(SE, errors='coerce')\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "print('Defined functions to calculate standard errors in percentages!')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate errors in percentage values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating errors in percentages...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "verboselevel = 0\n",
    "\n",
    "print('Calculating errors in percentages...')\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_white_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_black_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_white_householders_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_black_householders_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_female_householders_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_hs_grad_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_unemployed_serr = np.nan)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(pct_poverty_serr = np.nan)\n",
    "\n",
    "#city_tracts_years_df.loc[:, \n",
    "#              'poverty_status_known_last12months_total_err'] = pandas.to_numeric(city_tracts_years_df['poverty_status_known_last12months_total_err'], errors='coerce')\n",
    "\n",
    "\n",
    "for ix, thisrow in city_tracts_years_df.iterrows():\n",
    "    if (verboselevel >= 2):\n",
    "        print('Census tract {0:}...'.format(ix))\n",
    "    #print('pct_white_serr...')\n",
    "    city_tracts_years_df.loc[ix, 'pct_white_serr'] = find_errors_in_pct(thisrow['pop_white'], thisrow['pop_total'], thisrow['pop_white_err'], thisrow['pop_total_err'], verboselevel)\n",
    "    #print('pct_black_serr...')\n",
    "    city_tracts_years_df.loc[ix, 'pct_black_serr'] = find_errors_in_pct(thisrow['pop_black'], thisrow['pop_total'], thisrow['pop_black_err'], thisrow['pop_total_err'], verboselevel)\n",
    "    #print('pct_white_householders_serr...')\n",
    "    city_tracts_years_df.loc[ix, 'pct_white_householders_serr'] = find_errors_in_pct(thisrow['white_householder'], thisrow['total_householders'], thisrow['white_householder_err'], thisrow['total_householders_serr'], verboselevel)\n",
    "    city_tracts_years_df.loc[ix, 'pct_black_householders_serr'] = find_errors_in_pct(thisrow['white_householder'], thisrow['total_householders'], thisrow['white_householder_err'], thisrow['total_householders_serr'], verboselevel)\n",
    "    city_tracts_years_df.loc[ix, 'pct_female_householders_serr'] = find_errors_in_pct(thisrow['white_householder'], thisrow['total_householders'], thisrow['white_householder_err'], thisrow['total_householders_serr'], verboselevel)\n",
    "    \n",
    "    city_tracts_years_df.loc[ix, 'pct_hs_grad_serr'] = find_errors_in_pct(thisrow['hs_grad_25plus'], thisrow['pop_25plus'], thisrow['hs_grad_25plus_serr'], thisrow['pop_25plus_serr'], verboselevel)\n",
    "    city_tracts_years_df.loc[ix, 'pct_unemployed_serr'] = find_errors_in_pct(thisrow['unemployed_16plus'], thisrow['labor_force_16plus'], thisrow['hs_grad_25plus_serr'], thisrow['labor_force_16plus_err'], verboselevel)\n",
    "    city_tracts_years_df.loc[ix, 'pct_poverty_serr'] = find_errors_in_pct(thisrow['poverty_past_12_months'], thisrow['poverty_status_known'], thisrow['poverty_past_12_months_err'], thisrow['poverty_status_known_err'], verboselevel)\n",
    "\n",
    "if (verboselevel >= 1):\n",
    "    for ix, thisrow in city_tracts_years_df.iterrows():\n",
    "        print('Census tract {0:,.0f}'.format(ix))\n",
    "        print('{0:,.0f} +/- {1:,.0f} white'.format(\n",
    "            thisrow['pop_white'], thisrow['pop_white_err']\n",
    "        ))\n",
    "        print('{0:,.0f} +/- {1:,.0f} total'.format(\n",
    "            thisrow['pop_total'], thisrow['pop_total_err']\n",
    "        ))\n",
    "        print('{0:.1%} +/- {1:.1%}'.format(\n",
    "            thisrow['pct_white'], thisrow['pct_white_serr']\n",
    "        ))\n",
    "        print('\\n')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting inflation data...\n",
      "inflating pre-2017 monetary values...\n",
      "joining inflated money columns to the rest of the columns...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "money_columns = ['amtLoans1', 'amtLoans100k', 'amtLoans250k', 'amtLoansToSmallest']\n",
    "money_columns += ['amtLoans', 'amtWorkingLoans']\n",
    "money_columns += ['mfi', 'median_home_value']\n",
    "money_columns += ['amtLoans1_per_totaljob', 'amtLoans100k_per_totaljob']\n",
    "money_columns += ['amtLoans250k_per_totaljob', 'amtLoansToSmallest_per_totaljob']\n",
    "money_columns += ['amtLoans_per_totaljob', 'amtWorkingLoans_per_totaljob']\n",
    "money_columns += ['amtLoans1_per_sbjob', 'amtLoans100k_per_sbjob']\n",
    "money_columns += ['amtLoans250k_per_sbjob', 'amtLoansToSmallest_per_sbjob']\n",
    "money_columns += ['amtLoans_per_sbjob', 'amtWorkingLoans_per_sbjob']\n",
    "\n",
    "print('getting inflation data...')\n",
    "cpi_1913_2017_df = pandas.read_csv(inflation_dir+'cpi-1913-2017.csv', index_col='Year')\n",
    "cpi_annual_s = cpi_1913_2017_df['Jan']\n",
    "cpi_annual_s.name = 'rawfactor'\n",
    "value_in_2017 = cpi_annual_s.loc[2017]\n",
    "\n",
    "annual_inflator_s = 1 / (cpi_annual_s / value_in_2017)\n",
    "print('inflating pre-2017 monetary values...')\n",
    "inflate_these_df = city_tracts_years_df[money_columns]\n",
    "newcolnames = [x+'_adj' for x in inflate_these_df.columns.tolist()]\n",
    "inflate_these_df.columns = newcolnames\n",
    "\n",
    "inflated_df = pandas.DataFrame()\n",
    "for i in inflate_these_df.index.get_level_values(1).drop_duplicates().tolist():\n",
    "    inflated_df_i = inflate_these_df.xs(i, level=1).apply(lambda x: x * annual_inflator_s.loc[i])\n",
    "    inflated_df_i['activity_year'] = i\n",
    "    inflated_df = pandas.concat((inflated_df, inflated_df_i), axis=0)\n",
    "inflated_df = inflated_df.reset_index().set_index(['census_tract', 'activity_year'])\n",
    "\n",
    "print('joining inflated money columns to the rest of the columns...')\n",
    "city_tracts_years_df = city_tracts_years_df.join(inflated_df, how='left')\n",
    "\n",
    "print('Done!')\n",
    "#baltimore_tracts_years_df[['amtWorkingLoans_per_sbjob', 'amtWorkingLoans_per_sbjob_adj', 'mfi', 'mfi_adj']].sample(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add codes (e.g. CSA, income group...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching community statistical areas...\n",
      "Decoding income group names...\n",
      "Decoding income levels (low/moderate/middle/upper/unknown)...\n",
      "Writing out...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Add community statistical area names\n",
    "print('Matching community statistical areas...')\n",
    "if (city == 'Baltimore'):\n",
    "    tract_to_csa_df = pandas.read_csv(code_lookup_dir+'census_tract_to_neighborhood.csv', index_col='NAME10')\n",
    "    city_tracts_years_df = city_tracts_years_df.reset_index().merge(tract_to_csa_df.reset_index(), how='left', left_on='census_tract', right_on='NAME10').set_index(['census_tract', 'activity_year'])\n",
    "    city_tracts_years_df = city_tracts_years_df.drop(['NAME10', 'TRACTCE10', 'GEOID10'], axis=1)\n",
    "\n",
    "print('Decoding income group names...')\n",
    "# Get income group names\n",
    "city_tracts_years_df = city_tracts_years_df.rename(columns = {'income_group_total': 'income_group_code'})\n",
    "city_tracts_years_df = city_tracts_years_df.assign(income_group = np.nan)\n",
    "\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "city_tracts_years_df.loc[city_tracts_years_df['income_group_code'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "\n",
    "print('Decoding income levels (low/moderate/middle/upper/unknown)...')\n",
    "# Get levels (low, moderate, middle, upper)\n",
    "city_tracts_years_df = city_tracts_years_df.assign(cra_level = np.nan)\n",
    "city_tracts_years_df.loc[(city_tracts_years_df['income_group_code'] >= 1) & (city_tracts_years_df['income_group_code'] <= 5), 'cra_level'] = 'low'\n",
    "city_tracts_years_df.loc[(city_tracts_years_df['income_group_code'] >= 6) & (city_tracts_years_df['income_group_code'] <= 8), 'cra_level'] = 'moderate'\n",
    "city_tracts_years_df.loc[(city_tracts_years_df['income_group_code'] >= 9) & (city_tracts_years_df['income_group_code'] <= 12), 'cra_level'] = 'middle'\n",
    "city_tracts_years_df.loc[(city_tracts_years_df['income_group_code'] == 13), 'cra_level'] = 'upper'\n",
    "city_tracts_years_df.loc[(city_tracts_years_df['income_group_code'] == 14), 'cra_level'] = 'unknown'\n",
    "\n",
    "print('Writing out...')\n",
    "city_tracts_years_df.to_csv(city_data_dir+'{0:}_alldata.csv'.format(cityname_file), encoding='utf-8')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
