{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up HTTPS pool for downloading...\n",
      "\n",
      "In directory: /home/idies/workspace/21cc/Data/Census/Shapefiles/TIGER\n"
     ]
    }
   ],
   "source": [
    "thisyear = 2012\n",
    "do_these_states = ['06', '11', '24', '26', '29', '34', '39', '42', '51'\n",
    "    #'01', '02', '04', '05']\n",
    "#    '24'#,\n",
    "    #'01', '02', '04', '05', #, \n",
    "    #'06' #,\n",
    "     #'08', '09', '10', '11', '12' #, \n",
    "     #'13', '15', '16', '17', '18' #, \n",
    "     #'19', '20', '21', '22', '23' #, \n",
    "#     '25', '26', '27', '28' #, \n",
    "#      '29', '30', '31', '32', '33' #, \n",
    "#      '34', '35', '36', '37', '38' #, \n",
    "#      '39', '40', '41', '42', '44' #, \n",
    "#      '45', '46', '47' #, \n",
    "#.     '48' #, \n",
    "#      '49', '50', '51', '53' #, \n",
    "#      '54', '55', '56', '60', '66', '69', '72', '78'\n",
    " ]\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import pandas \n",
    "import geopandas\n",
    "#import gzip\n",
    "import numpy as np\n",
    "import urllib3\n",
    "import certifi\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "\n",
    "script_dir = '/home/idies/workspace/21cc/raddick/'\n",
    "data_dir = '/home/idies/workspace/21cc/Data/Census/'\n",
    "shapefiledir = data_dir + 'Shapefiles/TIGER/'\n",
    "#extras_dir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "if not (os.path.exists(shapefiledir)):\n",
    "    os.makedirs(shapefiledir)\n",
    "os.chdir(shapefiledir)\n",
    "\n",
    "print('setting up HTTPS pool for downloading...\\n')\n",
    "c = urllib3.PoolManager(cert_reqs=\"CERT_REQUIRED\", ca_certs=certifi.where())\n",
    "\n",
    "print('In directory: '+os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create directory structure if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/idies/workspace/21cc/Data/Census/Shapefiles/TIGER/2012'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeardir = shapefiledir + '{0:.0f}/'.format(thisyear)\n",
    "tractdir = yeardir + 'TRACT/'\n",
    "bgdir = yeardir + 'BG/'\n",
    "placedir = yeardir + 'PLACE/'\n",
    "#coastdir = yeardir + 'COASTLINE/'\n",
    "if (thisyear >= 2020):\n",
    "    uacdir = yeardir + 'UAC/'\n",
    "else:\n",
    "    uacdir = yeardir + 'CBSA/'\n",
    "areawaterdir = yeardir + 'AREAWATER/'\n",
    "#linearwaterdir = yeardir + 'LINEARWATER/'\n",
    "roaddir = yeardir + 'ROADS/'\n",
    "#pumadir = yeardir + 'PUMA/'\n",
    "cddir = yeardir + 'CD/'\n",
    "zcta5dir = yeardir + 'ZCTA5/'\n",
    "\n",
    "if not(os.path.exists(tractdir)):\n",
    "    os.makedirs(tractdir)  \n",
    "# if not(os.path.exists(bgdir)):\n",
    "#     os.makedirs(bgdir)\n",
    "if not(os.path.exists(placedir)):\n",
    "    os.makedirs(placedir)\n",
    "# if not(os.path.exists(coastdir)):\n",
    "#     os.makedirs(coastdir)\n",
    "# if not(os.path.exists(uacdir)):\n",
    "#     os.makedirs(uacdir)\n",
    "if not(os.path.exists(areawaterdir)):\n",
    "    os.makedirs(areawaterdir)\n",
    "# if not(os.path.exists(linearwaterdir)):\n",
    "#     os.makedirs(linearwaterdir)\n",
    "if not(os.path.exists(roaddir)):\n",
    "    os.makedirs(roaddir)\n",
    "# if not(os.path.exists(pumadir)):\n",
    "#     os.makedirs(pumadir)\n",
    "# if not(os.path.exists(cddir)):\n",
    "#     os.makedirs(cddir)\n",
    "# if not(os.path.exists(zcta5dir)):\n",
    "#     os.makedirs(zcta5dir)\n",
    "\n",
    "g = 0\n",
    "\n",
    "os.chdir(yeardir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What shapefile levels are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/'.format(thisyear)\n",
    "\n",
    "# resp = c.request(\"GET\", listurl)\n",
    "# soup = bs(resp.data, 'html.parser')\n",
    "# thetable = soup.find('table')\n",
    "# for i in range(0, len(thetable)):\n",
    "#     if (len(thetable.contents[i]) > 1):\n",
    "#         tdlist = thetable.contents[i].findAll('td')\n",
    "#         if (len(tdlist) > 1):\n",
    "#             print(tdlist[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get state and county shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get from www2.census.gov and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting state shapefiles...\n",
      "getting county shapefiles...\n",
      "Extracting state shapes zipfile...\n",
      "Extracting county shapes zipfile...\n",
      "Reading state names...\n",
      "Done in 0 minutes 6 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print('getting state shapefiles...')\n",
    "theurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/STATE/tl_{0:.0f}_us_state.zip'.format(thisyear)\n",
    "outfile = '{0:}tl_{1:.0f}_us_state.zip'.format(yeardir, thisyear)\n",
    "\n",
    "r = c.request('GET', theurl, preload_content=False)\n",
    "with open(outfile, 'wb') as out:\n",
    "    while True:\n",
    "        data = r.read()\n",
    "        if not data:\n",
    "            break\n",
    "        out.write(data)\n",
    "\n",
    "r.release_conn()\n",
    "\n",
    "\n",
    "print('getting county shapefiles...')\n",
    "theurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/COUNTY/tl_{0:.0f}_us_county.zip'.format(thisyear)\n",
    "outfile = '{0:}tl_{1:.0f}_us_county.zip'.format(yeardir, thisyear)\n",
    "\n",
    "r = c.request('GET', theurl, preload_content=False)\n",
    "\n",
    "with open(outfile, 'wb') as out:\n",
    "    while True:\n",
    "        data = r.read()\n",
    "        if not data:\n",
    "            break\n",
    "        out.write(data)\n",
    "\n",
    "r.release_conn()\n",
    "\n",
    "os.chdir(yeardir)\n",
    "\n",
    "print('Extracting state shapes zipfile...')\n",
    "thezipfile = zipfile.ZipFile(yeardir+'tl_{0:.0f}_us_state.zip'.format(thisyear))\n",
    "thezipfile.extractall()\n",
    "thezipfile.close()\n",
    "\n",
    "print('Extracting county shapes zipfile...')\n",
    "thezipfile = zipfile.ZipFile(yeardir+'tl_{0:.0f}_us_county.zip'.format(thisyear))\n",
    "thezipfile.extractall()\n",
    "thezipfile.close()\n",
    "\n",
    "os.remove(yeardir+'tl_{0:.0f}_us_state.zip'.format(thisyear))\n",
    "os.remove(yeardir+'tl_{0:.0f}_us_county.zip'.format(thisyear))\n",
    "\n",
    "print('Reading state names...')\n",
    "statefile = yeardir+'tl_{0:.0f}_us_state.shp'.format(thisyear)\n",
    "state_gdf = geopandas.read_file(statefile)\n",
    "state_gdf = state_gdf.set_index('STATEFP')\n",
    "state_gdf = state_gdf.sort_index()\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "print('Done in {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tract shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "os.chdir(tractdir)\n",
    "\n",
    "print('Downloading tract shapefiles...')\n",
    "#totalfilesize = 0\n",
    "for ix in sorted(state_gdf.index.tolist()):\n",
    "    si = time.time()\n",
    "    thisfilename = 'tl_{0:.0f}_{1:}_tract.zip'.format(thisyear, ix)\n",
    "    thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/TRACT/{1:}'.format(thisyear, thisfilename)\n",
    "    print('\\tGetting {0:}...'.format(thisfilename))\n",
    "    \n",
    "    r = c.request('GET', thisurl, preload_content=False)\n",
    "\n",
    "    with open(thisfilename, 'wb') as out:\n",
    "        while True:\n",
    "            data = r.read()\n",
    "            if not data:\n",
    "                break\n",
    "            out.write(data)\n",
    "            \n",
    "    thisfilesize = os.stat(thisfilename).st_size\n",
    "    ei = time.time()\n",
    "    #print('\\t{0:,.1f} MB in {1:,.0f} minutes {2:,.0f} seconds ({3:.1f} MB/s)...'.format(thisfilesize / (1024 * 1024), np.floor((ei-si)/60), (ei-si)%60, thisfilesize/(ei-si)))\n",
    "    #totalfilesize += thisfilesize\n",
    "\n",
    "r.release_conn()\n",
    "\n",
    "print('\\n')\n",
    "print('Unzipping all files...')\n",
    "\n",
    "for thefilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "    print('\\tExtracting zipfile {0:}...'.format(thefilename))\n",
    "    thezipfile = zipfile.ZipFile(thefilename)\n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    os.remove(thefilename)\n",
    "\n",
    "print('Calculating size of all files...')\n",
    "totalfilesize = 0\n",
    "for path, dirs, files in os.walk(os.getcwd()):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n",
    "\n",
    "# *_06_tract* *_11_tract* *_24_tract* *_26_tract* *_29_tract* *_34_tract* *39_tract* *_42_tract* *_51_tract*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# os.chdir(bgdir)\n",
    "# #os.listdir()\n",
    "\n",
    "# print('Downloading block group shapefiles...')\n",
    "# #totalfilesize = 0\n",
    "# for ix in sorted(state_gdf.index.tolist()):\n",
    "# #    si = time.time()\n",
    "#     thisfilename = 'tl_{0:.0f}_{1:}_bg.zip'.format(thisyear, ix)\n",
    "#     thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/BG/{1:}'.format(thisyear, thisfilename)\n",
    "#     print('\\tGetting {0:}...'.format(thisfilename))\n",
    "    \n",
    "#     r = c.request('GET', thisurl, preload_content=False)\n",
    "\n",
    "#     with open(thisfilename, 'wb') as out:\n",
    "#         while True:\n",
    "#             data = r.read()\n",
    "#             if not data:\n",
    "#                 break\n",
    "#             out.write(data)\n",
    "            \n",
    "# #    thisfilesize = os.stat(thisfilename).st_size\n",
    "# #    ei = time.time()\n",
    "# #    print('\\t{0:,.1f} MB in {1:,.0f} minutes {2:,.0f} seconds ({3:.1f} MB/s)...'.format(thisfilesize / (1024 * 1024), np.floor((ei-si)/60), (ei-si)%60, thisfilesize/(ei-si)))\n",
    "# #    totalfilesize += thisfilesize\n",
    "\n",
    "# r.release_conn()\n",
    "\n",
    "# print('\\n')\n",
    "# print('Unzipping all files...')\n",
    "\n",
    "# for thefilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "#     print('\\tExtracting zipfile {0:}...'.format(thefilename))\n",
    "#     thezipfile = zipfile.ZipFile(thefilename)\n",
    "#     thezipfile.extractall()\n",
    "#     thezipfile.close()\n",
    "#     os.remove(thefilename)\n",
    "\n",
    "# print('Calculating size of all files...')\n",
    "# totalfilesize = 0\n",
    "# for path, dirs, files in os.walk(os.getcwd()):\n",
    "#     for f in files:\n",
    "#         fp = os.path.join(path, f)\n",
    "#         totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "# e = time.time()\n",
    "# g += e-s\n",
    "# print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "os.chdir(placedir)\n",
    "\n",
    "print('Downloading place shapefiles...')\n",
    "# totalfilesize = 0\n",
    "for ix in sorted(state_gdf.index.tolist()):\n",
    "#     si = time.time()\n",
    "    thisfilename = 'tl_{0:.0f}_{1:}_place.zip'.format(thisyear, ix)\n",
    "    thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/PLACE/{1:}'.format(thisyear, thisfilename)\n",
    "    print('\\tGetting {0:}...'.format(thisfilename))\n",
    "    \n",
    "    r = c.request('GET', thisurl, preload_content=False)\n",
    "\n",
    "    with open(thisfilename, 'wb') as out:\n",
    "        while True:\n",
    "            data = r.read()\n",
    "            if not data:\n",
    "                break\n",
    "            out.write(data)\n",
    "            \n",
    "#     thisfilesize = (os.stat(thisfilename).st_size)/(1024*1024)\n",
    "#     ei = time.time()\n",
    "#     print('\\t\\t{0:,.1f} MB in {1:,.0f} minutes {2:,.0f} seconds ({3:.1f} MB/s)...'.format(thisfilesize, np.floor((ei-si)/60), (ei-si)%60, thisfilesize / (ei-si)))\n",
    "#     totalfilesize += thisfilesize\n",
    "\n",
    "r.release_conn()\n",
    "\n",
    "print('\\n')\n",
    "print('Unzipping all files...')\n",
    "\n",
    "for thefilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "#    print('Extracting zipfile {0:}...'.format(thefilename))\n",
    "    thezipfile = zipfile.ZipFile(thefilename)\n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    os.remove(thefilename)\n",
    "\n",
    "print('Calculating size of all files...')\n",
    "totalfilesize = 0\n",
    "for path, dirs, files in os.walk(os.getcwd()):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n",
    "# *_06_place* *_11_place* *_24_place* *_26_place* *_29_place* *_34_place* *39_place* *_42_place* *_51_place*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get urban area data\n",
    "\n",
    "Known as community-based statistical area (CBSA) data in 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# os.chdir(uacdir)\n",
    "# os.getcwd()\n",
    "\n",
    "\n",
    "# print('Downloading urban area shapefiles...')\n",
    "# print('\\n')\n",
    "# if (thisyear <= 2010):\n",
    "#     print('NEED CODE FOR 2010!')\n",
    "# else:\n",
    "#     possible_filenames_list = ['tl_{0:.0f}_us_cbsa00.zip'.format(thisyear), 'tl_{0:.0f}_us_uac10.zip'.format(thisyear), 'tl_{0:.0f}_us_uac20.zip'.format(thisyear)]\n",
    "\n",
    "# for thisfilename in possible_filenames_list:\n",
    "#     thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/UAC/{1:}'.format(thisyear, thisfilename)\n",
    "    \n",
    "#     print('Checking for existence of {0:}...'.format(thisfilename))\n",
    "#     r = c.request('GET', thisurl, preload_content=False)\n",
    "    \n",
    "#     if (r.status == 404):\n",
    "#         print('\\tFile does not exist!')\n",
    "#     else:\n",
    "#         print('\\tFile exists - downloading!')\n",
    "#         with open(thisfilename, 'wb') as out:\n",
    "#             while True:\n",
    "#                 data = r.read()\n",
    "#                 if not data:\n",
    "#                     break\n",
    "#                 out.write(data)\n",
    "\n",
    "# r.release_conn()\n",
    "\n",
    "# print('\\n')\n",
    "# print('Unzipping all files...')\n",
    "\n",
    "# for thefilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "# #    print('Extracting zipfile {0:}...'.format(thefilename))\n",
    "#     thezipfile = zipfile.ZipFile(thefilename)\n",
    "#     thezipfile.extractall()\n",
    "#     thezipfile.close()\n",
    "#     os.remove(thefilename)\n",
    "\n",
    "# print('Calculating size of all files...')\n",
    "# totalfilesize = 0\n",
    "# for path, dirs, files in os.walk(os.getcwd()):\n",
    "#     for f in files:\n",
    "#         fp = os.path.join(path, f)\n",
    "#         totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "# e = time.time()\n",
    "# g += e-s\n",
    "# print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congressional districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# os.chdir(cddir)\n",
    "\n",
    "# print('Downloading congressional district shapefiles...')\n",
    "# print('\\n')\n",
    "# congress_numbers = list(range(110,120,1))\n",
    "# possible_filenames_list = ['tl_{0:.0f}_us_cd{1:.0f}.zip'.format(thisyear, x) for x in congress_numbers]\n",
    "# possible_filenames_list\n",
    "\n",
    "# for thisfilename in possible_filenames_list:\n",
    "#     thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/CD/{1:}'.format(thisyear, thisfilename)\n",
    "#     print(thisurl)\n",
    "#     print('Checking for existence of {0:}...'.format(thisfilename))\n",
    "#     r = c.request('GET', thisurl, preload_content=False)\n",
    "    \n",
    "#     if (r.status == 404):\n",
    "#         print('\\tFile does not exist!')\n",
    "#     else:\n",
    "#         print('\\tFile exists - downloading!')\n",
    "#         with open(thisfilename, 'wb') as out:\n",
    "#             while True:\n",
    "#                 data = r.read()\n",
    "#                 if not data:\n",
    "#                     break\n",
    "#                 out.write(data)\n",
    "\n",
    "# r.release_conn()\n",
    "\n",
    "# print('\\n')\n",
    "# print('Unzipping all files...')\n",
    "\n",
    "# for thefilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "# #    print('Extracting zipfile {0:}...'.format(thefilename))\n",
    "#     thezipfile = zipfile.ZipFile(thefilename)\n",
    "#     thezipfile.extractall()\n",
    "#     thezipfile.close()\n",
    "#     os.remove(thefilename)\n",
    "\n",
    "# print('Calculating size of all files...')\n",
    "# totalfilesize = 0\n",
    "# for path, dirs, files in os.walk(os.getcwd()):\n",
    "#     for f in files:\n",
    "#         fp = os.path.join(path, f)\n",
    "#         totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "# e = time.time()\n",
    "# g += e-s\n",
    "# print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip codes (ZCTA5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = time.time()\n",
    "# os.chdir(zcta5dir)\n",
    "\n",
    "# print('Downloading ZIP code (ZCTA5) shapefiles...')\n",
    "# print('\\n')\n",
    "\n",
    "# if (thisyear >= 2020):\n",
    "#     thisfilename = 'tl_{0:.0f}_us_zcta520.zip'.format(thisyear)\n",
    "#     thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/ZCTA520/{1:}'.format(thisyear, thisfilename)\n",
    "# else:\n",
    "#     thisfilename = 'tl_{0:.0f}_us_zcta510.zip'.format(thisyear)\n",
    "#     thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/ZCTA5/{1:}'.format(thisyear, thisfilename)\n",
    "    \n",
    "# print('Getting {0:}...'.format(thisfilename))\n",
    "\n",
    "# r = c.request('GET', thisurl, preload_content=False)\n",
    "# with open(thisfilename, 'wb') as out:\n",
    "#     while True:\n",
    "#         data = r.read()\n",
    "#         if not data:\n",
    "#             break\n",
    "#         out.write(data)\n",
    "# r.release_conn()\n",
    "\n",
    "# print('\\n')\n",
    "# print('Unzipping all files...')\n",
    "# for thisfilename in sorted([x for x in os.listdir() if '.zip' in x]):\n",
    "#     print(thisfilename)\n",
    "#     print('Extracting zipfile {0:}...'.format(thisfilename))\n",
    "#     thezipfile = zipfile.ZipFile(thisfilename)\n",
    "#     thezipfile.extractall()\n",
    "#     thezipfile.close()\n",
    "#     os.remove(thisfilename)\n",
    "\n",
    "# print('Calculating size of all files...')\n",
    "# totalfilesize = 0\n",
    "# for path, dirs, files in os.walk(os.getcwd()):\n",
    "#     for f in files:\n",
    "#         fp = os.path.join(path, f)\n",
    "#         totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "# e = time.time()\n",
    "# g += e-s\n",
    "# print('\\nDownloaded and unzipped {0:,.0f} MB total in {1:,.0f} minutes {2:,.0f} seconds!'.format(totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get water area shapefiles: AREAWATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all downloadable files...\n",
      "Downloading area water shapefiles...\n",
      "\n",
      "\n",
      "Getting areawater files for California (STUSPS = 06)...\n",
      "Getting areawater files for District of Columbia (STUSPS = 11)...\n",
      "Getting areawater files for Maryland (STUSPS = 24)...\n",
      "Getting areawater files for Michigan (STUSPS = 26)...\n",
      "Getting areawater files for Missouri (STUSPS = 29)...\n",
      "Getting areawater files for New Jersey (STUSPS = 34)...\n",
      "Getting areawater files for Ohio (STUSPS = 39)...\n",
      "Getting areawater files for Pennsylvania (STUSPS = 42)...\n",
      "Getting areawater files for Virginia (STUSPS = 51)...\n",
      "Calculating size of zip files...\n",
      "\n",
      "Downloaded 591 files (202 MB total) in 0 minutes 55 seconds!\n",
      "\n",
      "Unzipping areawater files for California (STUSPS = 06)...\n",
      "\tUnzipping 0 of 58...\n",
      "\tUnzipping 10 of 58...\n",
      "\tUnzipping 20 of 58...\n",
      "\tUnzipping 30 of 58...\n",
      "\tUnzipping 40 of 58...\n",
      "\tUnzipping 50 of 58...\n",
      "\n",
      "Unzipping areawater files for District of Columbia (STUSPS = 11)...\n",
      "\tUnzipping 0 of 1...\n",
      "\n",
      "Unzipping areawater files for Maryland (STUSPS = 24)...\n",
      "\tUnzipping 0 of 24...\n",
      "\tUnzipping 10 of 24...\n",
      "\tUnzipping 20 of 24...\n",
      "\n",
      "Unzipping areawater files for Michigan (STUSPS = 26)...\n",
      "\tUnzipping 0 of 83...\n",
      "\tUnzipping 10 of 83...\n",
      "\tUnzipping 20 of 83...\n",
      "\tUnzipping 30 of 83...\n",
      "\tUnzipping 40 of 83...\n",
      "\tUnzipping 50 of 83...\n",
      "\tUnzipping 60 of 83...\n",
      "\tUnzipping 70 of 83...\n",
      "\tUnzipping 80 of 83...\n",
      "\n",
      "Unzipping areawater files for Missouri (STUSPS = 29)...\n",
      "\tUnzipping 0 of 115...\n",
      "\tUnzipping 10 of 115...\n",
      "\tUnzipping 20 of 115...\n",
      "\tUnzipping 30 of 115...\n",
      "\tUnzipping 40 of 115...\n",
      "\tUnzipping 50 of 115...\n",
      "\tUnzipping 60 of 115...\n",
      "\tUnzipping 70 of 115...\n",
      "\tUnzipping 80 of 115...\n",
      "\tUnzipping 90 of 115...\n",
      "\tUnzipping 100 of 115...\n",
      "\tUnzipping 110 of 115...\n",
      "\n",
      "Unzipping areawater files for New Jersey (STUSPS = 34)...\n",
      "\tUnzipping 0 of 21...\n",
      "\tUnzipping 10 of 21...\n",
      "\tUnzipping 20 of 21...\n",
      "\n",
      "Unzipping areawater files for Ohio (STUSPS = 39)...\n",
      "\tUnzipping 0 of 88...\n",
      "\tUnzipping 10 of 88...\n",
      "\tUnzipping 20 of 88...\n",
      "\tUnzipping 30 of 88...\n",
      "\tUnzipping 40 of 88...\n",
      "\tUnzipping 50 of 88...\n",
      "\tUnzipping 60 of 88...\n",
      "\tUnzipping 70 of 88...\n",
      "\tUnzipping 80 of 88...\n",
      "\n",
      "Unzipping areawater files for Pennsylvania (STUSPS = 42)...\n",
      "\tUnzipping 0 of 67...\n",
      "\tUnzipping 10 of 67...\n",
      "\tUnzipping 20 of 67...\n",
      "\tUnzipping 30 of 67...\n",
      "\tUnzipping 40 of 67...\n",
      "\tUnzipping 50 of 67...\n",
      "\tUnzipping 60 of 67...\n",
      "\n",
      "Unzipping areawater files for Virginia (STUSPS = 51)...\n",
      "\tUnzipping 0 of 134...\n",
      "\tUnzipping 10 of 134...\n",
      "\tUnzipping 20 of 134...\n",
      "\tUnzipping 30 of 134...\n",
      "\tUnzipping 40 of 134...\n",
      "\tUnzipping 50 of 134...\n",
      "\tUnzipping 60 of 134...\n",
      "\tUnzipping 70 of 134...\n",
      "\tUnzipping 80 of 134...\n",
      "\tUnzipping 90 of 134...\n",
      "\tUnzipping 100 of 134...\n",
      "\tUnzipping 110 of 134...\n",
      "\tUnzipping 120 of 134...\n",
      "\tUnzipping 130 of 134...\n",
      "\n",
      "\n",
      "Calculating size of unzipped files...\n",
      "\n",
      "Unzipped 2,955 files with 408 MB total in 1 minutes 17 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "# do_these_states = ['06', '11', '24', '26', '29', '34', '39', '42'\n",
    "# #      '01', '02', '04', '05',\n",
    "# #      '06',\n",
    "# #     '08', '09', '10', '11', '12' , \n",
    "# #      '13', '15', '16', '17', '18', \n",
    "# #      '19', '20', '21', '22', '23', '24',\n",
    "# #      '25', '26', '27', '28', \n",
    "# #      '29', '30', '31', '32', '33', \n",
    "# #      '34', '35', '36', '37', '38', \n",
    "# #      '39', '40', '41', '42', '44', \n",
    "# #      '45', '46', '47', \n",
    "# #     '48', \n",
    "# #    '49', '50', '51', '53', \n",
    "# #      '54', '55', '56', '60', '66', '69', '72', '78'\n",
    "#     ]\n",
    "\n",
    "\n",
    "os.chdir(areawaterdir)\n",
    "\n",
    "print('Finding all downloadable files...')\n",
    "listurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/AREAWATER/'.format(thisyear)\n",
    "\n",
    "resp = c.request(\"GET\", listurl)\n",
    "soup = bs(resp.data, 'html.parser')\n",
    "thetable = soup.find('table')\n",
    "all_file_names = []\n",
    "for i in range(0, len(thetable)):\n",
    "    if (len(thetable.contents[i]) > 1):\n",
    "        tdlist = thetable.contents[i].findAll('td')\n",
    "        if (len(tdlist) > 1):\n",
    "            all_file_names.append(tdlist[1].get_text())\n",
    "\n",
    "print('Downloading area water shapefiles...')\n",
    "print('\\n')\n",
    "for ix in do_these_states:\n",
    "    print('Getting areawater files for {0:} (STUSPS = {1:})...'.format(state_gdf.loc[ix]['NAME'], ix))\n",
    "    #print('\\tCreating directory...')\n",
    "    statedirname = areawaterdir+state_gdf.loc[ix]['STUSPS'].lower()\n",
    "    if (os.path.exists(statedirname)):\n",
    "        os.chdir(statedirname)\n",
    "        for x in os.listdir():\n",
    "            os.remove(x)\n",
    "        os.chdir(areawaterdir)\n",
    "        os.rmdir(statedirname)\n",
    "    os.makedirs(statedirname)\n",
    "    os.chdir(statedirname)\n",
    "    #print('\\tGetting files...')\n",
    "    for thisfilename in [x for x in all_file_names if 'tl_{0:.0f}_{1:}'.format(thisyear, ix) in x]:\n",
    "        thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/AREAWATER/{1:}'.format(thisyear, thisfilename)\n",
    "        #print('\\t\\t{0:}'.format(thisfilename))\n",
    "        r = c.request('GET', thisurl, preload_content=False)\n",
    "        with open(thisfilename, 'wb') as out:\n",
    "            while True:\n",
    "                data = r.read()\n",
    "                if not data:\n",
    "                    break\n",
    "                out.write(data)\n",
    "    os.chdir(areawaterdir)\n",
    "r.release_conn()\n",
    "\n",
    "print('Calculating size of zip files...')\n",
    "nfiles = 0\n",
    "totalfilesize = 0\n",
    "for path, dirs, files in os.walk(areawaterdir):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        nfiles += 1\n",
    "        totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "print('\\nDownloaded {0:,.0f} files ({1:,.0f} MB total) in {2:,.0f} minutes {3:,.0f} seconds!'.format(nfiles, totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n",
    "\n",
    "for ix in do_these_states:\n",
    "    print('\\nUnzipping areawater files for {0:} (STUSPS = {1:})...'.format(state_gdf.loc[ix]['NAME'], ix))\n",
    "    \n",
    "    dirname = '{0:}{1:}'.format(areawaterdir, state_gdf.loc[ix]['STUSPS'].lower())\n",
    "    os.chdir(dirname)\n",
    "    zipfiles = [x for x in os.listdir(dirname) if x[-4:] == '.zip']\n",
    "    for i in range(0, len(zipfiles)):\n",
    "        if (np.mod(i,10) == 0):\n",
    "            print('\\tUnzipping {0:,.0f} of {1:,.0f}...'.format(i, len(zipfiles)))\n",
    "        thezipfile = zipfile.ZipFile(zipfiles[i])\n",
    "        thezipfile.extractall()\n",
    "        thezipfile.close()\n",
    "        os.remove(zipfiles[i])\n",
    "    os.chdir(areawaterdir)\n",
    "print('\\n')\n",
    "print('Calculating size of unzipped files...')\n",
    "nfiles = 0\n",
    "totalfilesize = 0\n",
    "for path, dirs, files in os.walk(areawaterdir):\n",
    "    for f in files:\n",
    "        fp = os.path.join(path, f)\n",
    "        nfiles += 1\n",
    "        totalfilesize += os.path.getsize(fp)\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "print('\\nUnzipped {0:,.0f} files with {1:,.0f} MB total in {2:,.0f} minutes {3:,.0f} seconds!'.format(nfiles, totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n",
    "# 01-24: Unzipped 8,533 files with 910 MB total in 4 minutes 0 seconds!\n",
    "# 25-47: Unzipped 17,675 files with 1,743 MB total in 4 minutes 14 seconds!\n",
    "# 48: Unzipped 19,453 files with 2,020 MB total in 1 minutes 5 seconds!\n",
    "# 49-78: Unzipped 22,645 files with 2,285 MB total in 1 minutes 28 seconds!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all downloadable files...\n",
      "Downloading road shapefiles...\n",
      "\n",
      "\n",
      "Getting road files for California (STUSPS = 06)...\n",
      "Getting road files for District of Columbia (STUSPS = 11)...\n",
      "Getting road files for Maryland (STUSPS = 24)...\n",
      "Getting road files for Michigan (STUSPS = 26)...\n",
      "Getting road files for Missouri (STUSPS = 29)...\n",
      "Getting road files for New Jersey (STUSPS = 34)...\n",
      "Getting road files for Ohio (STUSPS = 39)...\n",
      "Getting road files for Pennsylvania (STUSPS = 42)...\n",
      "Getting road files for Virginia (STUSPS = 51)...\n",
      "\n",
      "\n",
      "Unzipping...\n",
      "Unzipping road files for California (STUSPS = 06)...\n",
      "\tUnzipping 0 of 58...\n",
      "\tUnzipping 10 of 58...\n",
      "\tUnzipping 20 of 58...\n",
      "\tUnzipping 30 of 58...\n",
      "\tUnzipping 40 of 58...\n",
      "\tUnzipping 50 of 58...\n",
      "Unzipping road files for District of Columbia (STUSPS = 11)...\n",
      "\tUnzipping 0 of 1...\n",
      "Unzipping road files for Maryland (STUSPS = 24)...\n",
      "\tUnzipping 0 of 24...\n",
      "\tUnzipping 10 of 24...\n",
      "\tUnzipping 20 of 24...\n",
      "Unzipping road files for Michigan (STUSPS = 26)...\n",
      "\tUnzipping 0 of 83...\n",
      "\tUnzipping 10 of 83...\n",
      "\tUnzipping 20 of 83...\n",
      "\tUnzipping 30 of 83...\n",
      "\tUnzipping 40 of 83...\n",
      "\tUnzipping 50 of 83...\n",
      "\tUnzipping 60 of 83...\n",
      "\tUnzipping 70 of 83...\n",
      "\tUnzipping 80 of 83...\n",
      "Unzipping road files for Missouri (STUSPS = 29)...\n",
      "\tUnzipping 0 of 115...\n",
      "\tUnzipping 10 of 115...\n",
      "\tUnzipping 20 of 115...\n",
      "\tUnzipping 30 of 115...\n",
      "\tUnzipping 40 of 115...\n",
      "\tUnzipping 50 of 115...\n",
      "\tUnzipping 60 of 115...\n",
      "\tUnzipping 70 of 115...\n",
      "\tUnzipping 80 of 115...\n",
      "\tUnzipping 90 of 115...\n",
      "\tUnzipping 100 of 115...\n",
      "\tUnzipping 110 of 115...\n",
      "Unzipping road files for New Jersey (STUSPS = 34)...\n",
      "\tUnzipping 0 of 21...\n",
      "\tUnzipping 10 of 21...\n",
      "\tUnzipping 20 of 21...\n",
      "Unzipping road files for Ohio (STUSPS = 39)...\n",
      "\tUnzipping 0 of 88...\n",
      "\tUnzipping 10 of 88...\n",
      "\tUnzipping 20 of 88...\n",
      "\tUnzipping 30 of 88...\n",
      "\tUnzipping 40 of 88...\n",
      "\tUnzipping 50 of 88...\n",
      "\tUnzipping 60 of 88...\n",
      "\tUnzipping 70 of 88...\n",
      "\tUnzipping 80 of 88...\n",
      "Unzipping road files for Pennsylvania (STUSPS = 42)...\n",
      "\tUnzipping 0 of 67...\n",
      "\tUnzipping 10 of 67...\n",
      "\tUnzipping 20 of 67...\n",
      "\tUnzipping 30 of 67...\n",
      "\tUnzipping 40 of 67...\n",
      "\tUnzipping 50 of 67...\n",
      "\tUnzipping 60 of 67...\n",
      "Unzipping road files for Virginia (STUSPS = 51)...\n",
      "\tUnzipping 0 of 134...\n",
      "\tUnzipping 10 of 134...\n",
      "\tUnzipping 20 of 134...\n",
      "\tUnzipping 30 of 134...\n",
      "\tUnzipping 40 of 134...\n",
      "\tUnzipping 50 of 134...\n",
      "\tUnzipping 60 of 134...\n",
      "\tUnzipping 70 of 134...\n",
      "\tUnzipping 80 of 134...\n",
      "\tUnzipping 90 of 134...\n",
      "\tUnzipping 100 of 134...\n",
      "\tUnzipping 110 of 134...\n",
      "\tUnzipping 120 of 134...\n",
      "\tUnzipping 130 of 134...\n",
      "\n",
      "Done in 3 minutes 37 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "os.chdir(roaddir)\n",
    "\n",
    "\n",
    "# do_these_states = ['06', '11', '24', '26', '29', '34', '39', '42'    \n",
    "# #      '01', '02', '04', '05',\n",
    "# #      '06',\n",
    "# #     '08', '09', '10', '11', '12' , \n",
    "# #      '13', '15', '16', '17', '18', \n",
    "# #      '19', '20', '21', '22', '23', '24',\n",
    "# #      '25', '26', '27', '28', \n",
    "# #      '29', '30', '31', '32', '33', \n",
    "# #      '34', '35', '36', '37', '38', \n",
    "# #      '39', '40', '41', '42', '44', \n",
    "# #      '45', '46', '47', \n",
    "# #    '48', \n",
    "# #    '49', '50', '51', '53', \n",
    "# #      '54', '55', '56', '60', '66', '69', '72', '78'\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Finding all downloadable files...')\n",
    "listurl = 'https://www2.census.gov/geo/tiger/TIGER{0:.0f}/ROADS/'.format(thisyear)\n",
    "\n",
    "resp = c.request(\"GET\", listurl)\n",
    "soup = bs(resp.data, 'html.parser')\n",
    "thetable = soup.find('table')\n",
    "all_file_names = []\n",
    "for i in range(0, len(thetable)):\n",
    "    if (len(thetable.contents[i]) > 1):\n",
    "        tdlist = thetable.contents[i].findAll('td')\n",
    "        if (len(tdlist) > 1):\n",
    "            all_file_names.append(tdlist[1].get_text())\n",
    "\n",
    "print('Downloading road shapefiles...')\n",
    "print('\\n')\n",
    "\n",
    "for ix in do_these_states:\n",
    "    print('Getting road files for {0:} (STUSPS = {1:})...'.format(state_gdf.loc[ix]['NAME'], ix))\n",
    "    statedirname = roaddir+state_gdf.loc[ix]['STUSPS'].lower()\n",
    "    if (os.path.exists(statedirname)):\n",
    "        os.chdir(statedirname)\n",
    "        for x in os.listdir():\n",
    "            os.remove(x)\n",
    "        os.chdir(roaddir)\n",
    "        os.rmdir(statedirname)\n",
    "    os.makedirs(statedirname)\n",
    "    os.chdir(statedirname)\n",
    "    #print('\\tGetting files...')\n",
    "    for thisfilename in [x for x in all_file_names if 'tl_{0:.0f}_{1:}'.format(thisyear, ix) in x]:\n",
    "        thisurl = 'https://www2.census.gov/geo/tiger/TIGER{0:}/ROADS/{1:}'.format(thisyear, thisfilename)\n",
    "        #print(thisurl)\n",
    "#        print('\\t\\t{0:}'.format(thisfilename))\n",
    "        r = c.request('GET', thisurl, preload_content=False)\n",
    "        with open(thisfilename, 'wb') as out:\n",
    "            while True:\n",
    "                data = r.read()\n",
    "                if not data:\n",
    "                    break\n",
    "                out.write(data)\n",
    "    os.chdir(roaddir)\n",
    "r.release_conn()\n",
    "print('\\n')\n",
    "print('Unzipping...')\n",
    "nfiles = 0\n",
    "totalfilesize = 0\n",
    "for ix in do_these_states:\n",
    "    print('Unzipping road files for {0:} (STUSPS = {1:})...'.format(state_gdf.loc[ix]['NAME'], ix))\n",
    "    \n",
    "    dirname = '{0:}{1:}'.format(roaddir, state_gdf.loc[ix]['STUSPS'].lower())\n",
    "    os.chdir(dirname)\n",
    "    zipfiles = [x for x in os.listdir(dirname) if x[-4:] == '.zip']\n",
    "    for i in range(0, len(zipfiles)):\n",
    "        if (np.mod(i,10) == 0):\n",
    "            print('\\tUnzipping {0:,.0f} of {1:,.0f}...'.format(i, len(zipfiles)))\n",
    "        thezipfile = zipfile.ZipFile(zipfiles[i])\n",
    "        thezipfile.extractall()\n",
    "        thezipfile.close()\n",
    "        os.remove(zipfiles[i])\n",
    "    os.chdir(roaddir)\n",
    "\n",
    "e = time.time()\n",
    "g += e-s\n",
    "#print('\\nUnzipped {0:,.0f} files with {1:,.0f} MB total in {2:,.0f} minutes {3:,.0f} seconds!'.format(nfiles, totalfilesize/(1024 * 1024), np.floor((e-s)/60), (e-s)%60))\n",
    "print('\\nDone in {0:,.0f} minutes {1:,.0f} seconds!'.format(np.floor((e-s)/60), (e-s)%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(pumadir)\n",
    "\n",
    "# if (thisyear == 2011):\n",
    "#     print('No PUMA shapefiles for 2011!')\n",
    "# else:\n",
    "#     print('FTP-ing...')\n",
    "#     ftp = FTP('ftp2.census.gov')\n",
    "#     ftp.login()\n",
    "#     print(ftp.getwelcome())\n",
    "#     if (thisyear == 2010):\n",
    "#         ftp.cwd('geo/tiger/TIGER{0:.0f}/PUMA5/{0:.0f}'.format(thisyear))\n",
    "#         print(ftp.nlst())\n",
    "#     else:\n",
    "#         ftp.cwd('geo/tiger/TIGER{0:.0f}/PUMA/'.format(thisyear))\n",
    "#     for i in range(0,100):    \n",
    "#         statefiles = [x for x in ftp.nlst() if 'tl_{0:.0f}_{1:02d}'.format(thisyear, i) in x]\n",
    "#         if len(statefiles) > 0:\n",
    "#             print('Getting PUMA shapefiles for state {0:02d}...'.format(i))\n",
    "#             for thisfile in statefiles:\n",
    "#                 with open(thisfile, 'wb') as f:\n",
    "#                     ftp.retrbinary('RETR {0:}'.format(thisfile), f.write)\n",
    "#     ftp.close()\n",
    "\n",
    "\n",
    "# os.chdir(pumadir)\n",
    "# allzipfiles = sorted([x for x in os.listdir() if '.zip' in x])\n",
    "\n",
    "# for thisfile in allzipfiles:\n",
    "#     thezipfile = zipfile.ZipFile(thisfile)\n",
    "#     thezipfile.extractall()\n",
    "#     thezipfile.close()\n",
    "\n",
    "# for thiszip in [x for x in os.listdir() if '.zip' in x]:\n",
    "#     os.remove(thiszip)\n",
    "# print('Done!')\n",
    "# # print(os.getcwd())\n",
    "# # os.listdir()\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
