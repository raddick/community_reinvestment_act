{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd\n",
    "debug = 2\n",
    "import numpy as np\n",
    "import pandas\n",
    "import time\n",
    "import geopandas\n",
    "import os\n",
    "import re\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data for one year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "thisyear = 2011\n",
    "\n",
    "basedir = '/home/idies/workspace/Temporary/raddick/census_scratch/acs5/'\n",
    "yeardir = basedir + str(thisyear) + '/'\n",
    "if (thisyear == 2017):\n",
    "    rawdatadir = yeardir + 'rawdata/'\n",
    "    metadir = yeardir + 'metadata/xls_temp/'\n",
    "elif (thisyear == 2016):\n",
    "    rawdatadir = yeardir + 'rawdata/data/tab4/sumfile/prod/2012thru2016/group2/'\n",
    "    metadir = yeardir + 'metadata/templates/'\n",
    "elif (thisyear == 2015):\n",
    "    rawdatadir = yeardir + 'rawdata/group2/'\n",
    "    metadir = yeardir + 'metadata/'\n",
    "elif (thisyear == 2014):\n",
    "    rawdatadir = yeardir + 'rawdata/tab4/sumfile/prod/2010thru2014/group2/'\n",
    "    metadir = yeardir + 'metadata/seq/'\n",
    "elif (thisyear == 2013):\n",
    "    rawdatadir = yeardir + 'rawdata/group2/'\n",
    "    metadir = yeardir + 'metadata/'\n",
    "elif (thisyear == 2012):\n",
    "    rawdatadir = yeardir + 'rawdata/tab4/sumfile/prod/2008thru2012/group2/'\n",
    "    metadir = yeardir + 'metadata/'\n",
    "elif (thisyear == 2011):\n",
    "    rawdatadir = yeardir + 'rawdata/group2/'\n",
    "    metadir = yeardir + 'metadata/'\n",
    "elif (thisyear == 2010):\n",
    "    rawdatadir = yeardir + 'rawdata/tab4/sumfile/prod/2006thru2010/group2/'\n",
    "    metadir = yeardir + 'metadata/'\n",
    "    \n",
    "    \n",
    "estimates_dir = yeardir + 'estimates/'\n",
    "margin_of_error_dir = yeardir + 'margin_of_error/'\n",
    "vardir = yeardir + 'variables/'\n",
    "\n",
    "geodir = yeardir + 'geography/'\n",
    "\n",
    "extrasdir = '/home/idies/workspace/Storage/raddick/census/extras/'\n",
    "\n",
    "outdir = '/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/acs5/'\n",
    "outfile = outdir + 'acs5_md_{0:.0f}.csv'.format(thisyear)\n",
    "metaoutfile = outdir + 'acs5_metadata_md_{0:.0f}.csv'.format(thisyear)\n",
    "\n",
    "for thisdir in [estimates_dir, margin_of_error_dir, vardir, geodir]:#[datadir, errordir, vardir, geodir]:\n",
    "    #print(thisdir)\n",
    "    if not(os.path.exists(thisdir)):\n",
    "        os.makedirs(thisdir)\n",
    "print('Done!')\n",
    "#os.chdir(rawdatadir)\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse metadata\n",
    "\n",
    "Let's see what columns are available for us to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing metadata for sequence 25...\n",
      "Parsing metadata for sequence 50...\n",
      "Parsing metadata for sequence 75...\n",
      "Parsing metadata for sequence 100...\n",
      "Parsing metadata for sequence 113...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "os.chdir(metadir)\n",
    "themetafiles = [x for x in os.listdir() if 'seq' in x.lower()]\n",
    "lastfilenum = len(themetafiles)\n",
    "#os.chdir(metadir)\n",
    "\n",
    "metadata_df = pandas.DataFrame()\n",
    "\n",
    "state_codes_df = pandas.read_csv(extrasdir+'statecodes.csv')\n",
    "state_codes_df = state_codes_df.set_index('STUSAB')\n",
    "states = state_codes_df.index.values.tolist()\n",
    "states = [x.lower() for x in states if x not in ('AS', 'GU', 'MP', 'PR', 'UM', 'VI')]\n",
    "states = ['md']\n",
    "#os.chdir(metadir)\n",
    "metadata_df = pandas.DataFrame()\n",
    "\n",
    "i = 1\n",
    "if (thisyear == 2017):\n",
    "    this_seq_metadata_cols_df = pandas.read_excel(metadir+'seq{0:.0f}.xlsx'.format(i))\n",
    "elif (thisyear == 2011):\n",
    "    this_seq_metadata_cols_df = pandas.read_excel(metadir+'Seq{0:04d}.xls'.format(i))\n",
    "else:\n",
    "    this_seq_metadata_cols_df = pandas.read_excel(metadir+'Seq{0:.0f}.xls'.format(i))\n",
    "this_seq_metadata_df = this_seq_metadata_cols_df.T\n",
    "this_seq_metadata_df.index.name = 'variable'\n",
    "this_seq_metadata_df = this_seq_metadata_df.rename(columns={0: 'description'})\n",
    "this_seq_metadata_df = this_seq_metadata_df.assign(sequence_number = i)\n",
    "this_seq_metadata_df = this_seq_metadata_df.reset_index()\n",
    "#this_seq_metadata_df.index.name = 'varnum'\n",
    "metadata_df = pandas.concat((metadata_df, this_seq_metadata_df))\n",
    "\n",
    "for i in range(2,lastfilenum+1):\n",
    "    if ((np.mod(i,25) == 0) | (i == lastfilenum)):\n",
    "        print('Parsing metadata for sequence {0:.0f}...'.format(i))\n",
    "    if (thisyear == 2017):\n",
    "        this_seq_metadata_cols_df = pandas.read_excel(metadir+'seq{0:.0f}.xlsx'.format(i))\n",
    "    elif (thisyear == 2011):\n",
    "        this_seq_metadata_cols_df = pandas.read_excel(metadir+'Seq{0:04d}.xls'.format(i))\n",
    "    else:\n",
    "        this_seq_metadata_cols_df = pandas.read_excel(metadir+'Seq{0:.0f}.xls'.format(i))\n",
    "    this_seq_metadata_df = this_seq_metadata_cols_df.T\n",
    "    this_seq_metadata_df = this_seq_metadata_df.assign(sequence_number = i)\n",
    "    this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID', 'FILETYPE', 'STUSAB', 'CHARITER', 'SEQUENCE', 'LOGRECNO'], axis=0)\n",
    "    this_seq_metadata_df.index.name = 'variable'\n",
    "    this_seq_metadata_df = this_seq_metadata_df.rename(columns={0: 'description'})\n",
    "    this_seq_metadata_df = this_seq_metadata_df.reset_index()\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df))\n",
    "metadata_df = metadata_df.reset_index(drop=True)\n",
    "metadata_df.index.name = 'varnum'\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out what variables we need, add them to varlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables we actually want for this study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# IV: population by race; owner-occupied units; MFI; hs grad pct (age 25 and older); \n",
    "### female hoh pct; unemployment pct (age 18 and older); poverty pct; median home value;\n",
    "### median home year built\n",
    "\n",
    "varlist = ['STUSAB','LOGRECNO']    # Lookup variables (we always need these): Seq 1 in 2017\n",
    "varlist += ['B01001_001']   # Total population: Seq 2 in 2017\n",
    "varlist += ['B11001_001']  # Total households: Seq 36 in 2017\n",
    "varlist += ['B02001_002', 'B02001_003'] # White-only and black-only population: Seq 4 in 2017\n",
    "\n",
    "# WHITE-ONLY AND BLACK-ONLY HOUSEHOLDER\n",
    "varlist += metadata_df['variable'][\n",
    "    (metadata_df['description'].apply(lambda x: 'household' in str(x).lower()))\n",
    "    & (\n",
    "        (metadata_df['description'].apply(lambda x: 'white alone, not ' in str(x).lower()))\n",
    "        | (metadata_df['description'].apply(lambda x: 'black' in str(x).lower()))\n",
    "    )\n",
    "    & (metadata_df['description'].apply(lambda x: str(x)[-5:] == 'Total'))\n",
    "    & (metadata_df['description'].apply(lambda x: str(x)[0:25] == 'HOUSEHOLD TYPE (INCLUDING'))\n",
    "    #& (metadata_df['sequence_number'].apply(lambda x: ((x >= 36) & (x <= 36))))\n",
    "].tolist()\n",
    "\n",
    "varlist += ['B25003_002'] # Owner-occupied housing units: Seq 103 in 2017\n",
    "varlist += ['B19113_001'] # Median family income: Seq 64 in 2017\n",
    "varlist += ['B15002_011', 'B15002_028'] # High school graduates: Seq 43 in 2017\n",
    "varlist += ['B11001_006'] # Female householder no husband present: Seq 36 in 2017\n",
    "varlist += ['B23025_005'] # Unemployed people age 16 or over: Seq 79 in 2017\n",
    "varlist += ['B17001_002'] # Income in the past 12 months below poverty level: Seq 48 in 2017\n",
    "varlist += ['B25077_001'] # MEDIAN VALUE (DOLLARS)% Owner-occupied housing units%Median value (dollars): Seq 106 in 2017\n",
    "varlist += ['B25035_001'] # MEDIAN YEAR STRUCTURE BUILT% Housing units%Median year structure built: Seq 105 in 2017\n",
    "\n",
    "# ANOTHER OPTION: UNEMPLOYED PEOPLE AGES 22 AND OLDER: Seq 76 in 2017\n",
    "#varlist += metadata_df['variable'][\n",
    "#    (metadata_df['description'].apply(lambda x: 'unemplo' in x.lower()))\n",
    "#    & (metadata_df['description'].apply(lambda x: x[0:31] == 'SEX BY AGE BY EMPLOYMENT STATUS'))\n",
    "#    & (metadata_df['variable'].apply(lambda x: re.search(\"[A-Z]_\", x) == None))  # note: case-sensitive search for varnames\n",
    "#    #& (metadata_df['sequence_number'].apply(lambda x: ((x >= 76) & (x <= 76))))    \n",
    "#].tolist()\n",
    "\n",
    "# Cross-tab variables to come back to later\n",
    "#varlist += ['B11001A_006', 'B11001B_006', 'B17001A_002', 'B17001B_002']\n",
    "#varlist += ['C15002A_004', 'C15002A_009', 'C15002B_004', 'C15002B_009']\n",
    "#varlist += ['B19113A_001', 'B19113B_001', 'B25003A_002', 'B25003B_002']\n",
    "\n",
    "# CHECK!\n",
    "#metadata_df[metadata_df['variable'].apply(lambda x: x in varlist)]\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables we need to calculate percentages later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding variables for men of any race by ages 25 and over...\n",
      "finding variables for women of any race by ages 25 and over...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "### need to calculate percentages: population 25 and older...\n",
    "##### population age 16 and older in labor force, population for whom poverty status determined\n",
    "comparison_vars = []\n",
    "\n",
    "# people over age 25:\n",
    "print('finding variables for men of any race by ages 25 and over...')\n",
    "comparison_vars += metadata_df['variable'][\n",
    "    (metadata_df['sequence_number'].apply(lambda x: ((x >= 2) & (x <= 2))))\n",
    "    & (metadata_df['description'].apply(lambda x: 'age' in str(x).lower()))\n",
    "    & (metadata_df['description'].apply(lambda x: '%male%' in str(x).lower()))\n",
    "    & (metadata_df['variable'].apply(lambda x: re.search(\"[A-Z]_\", str(x)) == None))  # note: case-sensitive search for varnames\n",
    "].tolist()[8:]\n",
    "\n",
    "print('finding variables for women of any race by ages 25 and over...')\n",
    "comparison_vars += metadata_df['variable'][\n",
    "    (metadata_df['sequence_number'].apply(lambda x: ((x >= 2) & (x <= 2))))\n",
    "    & (metadata_df['description'].apply(lambda x: 'age' in str(x).lower()))\n",
    "    & (metadata_df['description'].apply(lambda x: '%female%' in str(x).lower()))\n",
    "    & (metadata_df['variable'].apply(lambda x: re.search(\"[A-Z]_\", str(x)) == None))  # note: case-sensitive search for varnames\n",
    "].tolist()[8:]\n",
    "\n",
    "comparison_vars += ['B23025_002'] # EMPLOYMENT STATUS FOR THE POPULATION 16 YEARS AND OVER%Population 16 years and over%Total%In labor force: Seq 79 in 2017\n",
    "comparison_vars += ['B17001_001'] # POVERTY STATUS IN THE PAST 12 MONTHS BY SEX BY AGE% Population for whom poverty status is determined%Total: Seq 48 in 2017\n",
    "\n",
    "# CHECK!\n",
    "#metadata_df[metadata_df['variable'].apply(lambda x: x in comparison_vars)]\n",
    "\n",
    "if (len(varlist) < len(comparison_vars)):\n",
    "    varlist += comparison_vars\n",
    "\n",
    "# CHECK!\n",
    "#metadata_df[metadata_df['variable'].apply(lambda x: x in varlist)]\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse estimates and margins of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 1...\n",
      "Processing sequence 25...\n",
      "Processing sequence 50...\n",
      "Processing sequence 75...\n",
      "Processing sequence 100...\n",
      "Processing sequence 113...\n",
      "Converting all numeric columns to numeric...\n",
      "\n",
      "\n",
      "Done in 5 minutes 24 seconds!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "states = state_codes_df.index.values.tolist()\n",
    "states = [x.lower() for x in states if x not in ('AS', 'GU', 'MP', 'PR', 'UM', 'VI')]\n",
    "states = ['md']\n",
    "\n",
    "estimates_df = pandas.DataFrame()\n",
    "margins_of_error_df = pandas.DataFrame()\n",
    "for i in range(1, lastfilenum+1):\n",
    "    if ((i == 1) | (np.mod(i,25) == 0) | (i == lastfilenum)):\n",
    "        print('Processing sequence {0:,.0f}...'.format(i))\n",
    "    #print('Parsing estimates and errors...')\n",
    "    this_seq_estimates_df = pandas.DataFrame()\n",
    "    this_seq_margins_of_error_df = pandas.DataFrame()\n",
    "    for onestate in states:\n",
    "        #if (i > 1):\n",
    "        #print('Processing {:}...'.format(onestate))\n",
    "        estimates_statefilename = rawdatadir + 'e{0:.0f}5{1:}{2:04d}000.txt'.format(thisyear, onestate, i)\n",
    "        margins_of_error_statefilename = rawdatadir + 'm{0:.0f}5{1:}{2:04d}000.txt'.format(thisyear, onestate, i)\n",
    "        estimates_onestate_df = pandas.read_csv(estimates_statefilename, header=None, sep=',', encoding='utf-8', low_memory=False)\n",
    "        margins_of_error_onestate_df = pandas.read_csv(margins_of_error_statefilename, header=None, sep=',', encoding='utf-8', low_memory=False)\n",
    "        column_names = metadata_df[metadata_df['sequence_number'] == i].set_index('variable').T.columns.tolist()\n",
    "        if (i > 1):\n",
    "            column_names = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO'] + column_names\n",
    "        estimates_onestate_df.columns = column_names\n",
    "        margins_of_error_onestate_df.columns = column_names\n",
    "        this_seq_estimates_df = this_seq_estimates_df.append(estimates_onestate_df, sort=False)\n",
    "        this_seq_margins_of_error_df = this_seq_margins_of_error_df.append(margins_of_error_onestate_df)\n",
    "        if (i == 1):\n",
    "            estimates_df = this_seq_estimates_df\n",
    "            margins_of_error_df = this_seq_margins_of_error_df\n",
    "        else:\n",
    "            this_seq_estimates_df = this_seq_estimates_df.drop(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], axis=1)\n",
    "            this_seq_margins_of_error_df = this_seq_margins_of_error_df.drop(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], axis=1)\n",
    "            estimates_df = estimates_df.merge(this_seq_estimates_df, how='left', on=['STUSAB','LOGRECNO'], sort=False)\n",
    "            margins_of_error_df = margins_of_error_df.merge(this_seq_margins_of_error_df, how='left', on=['STUSAB','LOGRECNO'], sort=False)\n",
    "\n",
    "print('Converting all numeric columns to numeric...')\n",
    "estimates_df = estimates_df.drop(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], axis=1)\n",
    "margins_of_error_df = margins_of_error_df.drop(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], axis=1)\n",
    "\n",
    "for x in estimates_df.columns[1:].tolist():\n",
    "    #print('{:}...'.format(x))\n",
    "    estimates_df[x] = pandas.to_numeric(estimates_df[x], errors='coerce')\n",
    "\n",
    "for x in margins_of_error_df.columns[1:].tolist():\n",
    "    #print('{:}...'.format(x))\n",
    "    margins_of_error_df[x] = pandas.to_numeric(margins_of_error_df[x], errors='coerce')    \n",
    "\n",
    "e = time.time()\n",
    "print('\\n')\n",
    "print('Done in {0:,.0f} minutes {1:.0f} seconds!'.format((e-s)/60, (e-s) % 60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only the variables we need (see how we found them above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The estimates and margins of error for these variables (get the metadata later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting only the variables we need...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Getting only the variables we need...')\n",
    "estimates_df = estimates_df[varlist]\n",
    "margins_of_error_df = margins_of_error_df[varlist]\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data and error values into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renaming error columns...\n",
      "joining data and error columns...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STUSAB</th>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOGRECNO</th>\n",
       "      <td>7513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01001_001</th>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11001_001</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02001_002</th>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02001_003</th>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25003_002</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B19113_001</th>\n",
       "      <td>89152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B15002_011</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B15002_028</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11001_006</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B23025_005</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B17001_002</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25077_001</th>\n",
       "      <td>417100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25035_001</th>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01001_001_err</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11001_001_err</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02001_002_err</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B02001_003_err</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25003_002_err</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B19113_001_err</th>\n",
       "      <td>37775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B15002_011_err</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B15002_028_err</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11001_006_err</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B23025_005_err</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B17001_002_err</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25077_001_err</th>\n",
       "      <td>104904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B25035_001_err</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  3191\n",
       "STUSAB          md    \n",
       "LOGRECNO        7513  \n",
       "B01001_001      968   \n",
       "B11001_001      476   \n",
       "B02001_002      666   \n",
       "B02001_003      290   \n",
       "B25003_002      403   \n",
       "B19113_001      89152 \n",
       "B15002_011      164   \n",
       "B15002_028      55    \n",
       "B11001_006      35    \n",
       "B23025_005      19    \n",
       "B17001_002      NaN   \n",
       "B25077_001      417100\n",
       "B25035_001      1972  \n",
       "B01001_001_err  211   \n",
       "B11001_001_err  104   \n",
       "B02001_002_err  189   \n",
       "B02001_003_err  169   \n",
       "B25003_002_err  101   \n",
       "B19113_001_err  37775 \n",
       "B15002_011_err  92    \n",
       "B15002_028_err  44    \n",
       "B11001_006_err  35    \n",
       "B23025_005_err  33    \n",
       "B17001_002_err  NaN   \n",
       "B25077_001_err  104904\n",
       "B25035_001_err  13    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('renaming error columns...')\n",
    "error_column_names = margins_of_error_df.columns.tolist()\n",
    "error_column_names = ['STUSAB', 'LOGRECNO'] + [x+'_err' for x in error_column_names if x not in ['STUSAB', 'LOGRECNO'] and '_err' not in x]\n",
    "margins_of_error_df.columns = error_column_names\n",
    "\n",
    "#estimates_df\n",
    "print('joining data and error columns...')\n",
    "\n",
    "acs5_df = estimates_df.merge(margins_of_error_df, how='left', on=['STUSAB', 'LOGRECNO'])\n",
    "acs5_df.sample(1).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and join geography files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading geography files...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#acs5_df = estimates_df\n",
    "s = time.time()\n",
    "geo_df = pandas.DataFrame()\n",
    "\n",
    "states = state_codes_df.index.values.tolist()\n",
    "states = [x.lower() for x in states if x not in ('AS', 'GU', 'MP', 'PR', 'UM', 'VI')]\n",
    "states = ['md']\n",
    "\n",
    "if (debug >= 1):\n",
    "        print('Reading geography files...')\n",
    "for onestate in states:\n",
    "    if (thisyear >= 2016):\n",
    "        filename = geodir+'{0:}.xlsx'.format(onestate)\n",
    "    else:\n",
    "        filename = geodir+'{0:}.xls'.format(onestate)\n",
    "    #if (debug == 2):\n",
    "        #print('Reading geography for {0:}...'.format(onestate))\n",
    "    this_geo_df = pandas.read_excel(filename)\n",
    "    geo_df = pandas.concat((geo_df, this_geo_df), sort=False)\n",
    "\n",
    "if (thisyear == 2017):\n",
    "    geo_df = geo_df.assign(STUSAB = geo_df['State'].apply(lambda x: x.lower()))\n",
    "else:\n",
    "    geo_df = geo_df.assign(STUSAB = geo_df['STATE'].apply(lambda x: x.lower()))\n",
    "\n",
    "geo_df = geo_df.rename(columns={'Geography ID': 'GEOID'})\n",
    "\n",
    "#if (debug >= 1):\n",
    "#    print('Retaining only tract-level geographies...')\n",
    "##    print('Retaining only tract- and block-group-level geographies...')\n",
    "#geo_df = geo_df[(geo_df['GEOID'].apply(lambda x: x[0:3] == '140'))]\n",
    "##geo_df = geo_df[(geo_df['GEOID'].apply(lambda x: x[0:3] == '140')) | (geo_df['GEOID'].apply(lambda x: x[0:3] == '150'))]\n",
    "\n",
    "##geo_df = geo_df.set_index('GEOID')  #We'll set GEOID as index colum AFTER the merge\n",
    "if (thisyear == 2017):\n",
    "    acs5_df = acs5_df.merge(geo_df, how='inner', left_on=['STUSAB', 'LOGRECNO'], right_on=['STUSAB', 'Logical Record Number'])\n",
    "else:\n",
    "    acs5_df = acs5_df.merge(geo_df, how='inner', left_on=['STUSAB', 'LOGRECNO'], right_on=['STUSAB', 'LOGRECNO'])\n",
    "acs5_df = acs5_df.set_index('GEOID')\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written out to:\n",
      "/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/acs5/acs5_md_2011.csv\n",
      "Metadata written out to:\n",
      "/home/idies/workspace/Storage/raddick/Baltimore/community_reinvestment_act/datasets/acs5/acs5_metadata_md_2011.csv\n"
     ]
    }
   ],
   "source": [
    "acs5_df.to_csv(outfile, encoding='utf-8')\n",
    "metadata_df[metadata_df['variable'].apply(lambda x: x in varlist)].to_csv(metaoutfile, encoding='utf-8')\n",
    "\n",
    "print('Data written out to:\\n{0:}\\nMetadata written out to:\\n{1:}'.format(outfile, metaoutfile))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pandas.read_csv(outfile, index_col='GEOID')\n",
    "meta_df = pandas.read_csv(metaoutfile, index_col='varnum')\n",
    "df.sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEQUENCE GUIDE FOR ACS 5-yr in 2017\n",
    "\n",
    "Seq 1: unweighted count\n",
    "\n",
    "Seq 2-3: age-sex\n",
    "\n",
    "Seq 4: race\n",
    "\n",
    "Seq 5: hispanic origin\n",
    "\n",
    "Seq 6-7: ancestry\n",
    "\n",
    "Seq 8-12: foreign birth\n",
    "\n",
    "Seq 13-15: Place of Birth - Native\n",
    "\n",
    "Seq 16-22: Residence Last Year - Migration\n",
    "\n",
    "Seq 23-33: Journey to Work\n",
    "\n",
    "Seq 34: Children - Relationship\n",
    "\n",
    "Seq 35: Grand(Persons) - Age of HH Members\n",
    "\n",
    "Seq 36-37: Households - Families\n",
    "\n",
    "Seq 38-39: Marital Status\n",
    "\n",
    "Seq 40: Fertility\n",
    "\n",
    "Seq 41-42: School Enrollment\n",
    "\n",
    "Seq 43-44: Educational Attainment\n",
    "\n",
    "Seq 45-47: Language\n",
    "\n",
    "Seq 48-56: Poverty\n",
    "\n",
    "Seq 57-58: Disability\n",
    "\n",
    "Seq 59-66: Income\n",
    "\n",
    "Seq 67-72: Earnings\n",
    "\n",
    "Seq 73-74: Veteran Status\n",
    "\n",
    "Seq 75: Transfer Programs\n",
    "\n",
    "Seq 76-79: Employment Status\n",
    "\n",
    "Seq 80-102: Industry-Occupation-Class of Worker\n",
    "\n",
    "Seq 103-112: Housing\n",
    "\n",
    "Seq 113-123: Group Quarters\n",
    "\n",
    "Seq 124-127: Health Insurance\n",
    "\n",
    "Seq 128 Computer and Internet Usage\n",
    "\n",
    "Seq 129: Quality Measures\n",
    "\n",
    "Seq 130-133: Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
